{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load in the specific data needed\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import datetime\n",
    "import hvplot.polars\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.interpolate import bisplrep, bisplev\n",
    "from datetime import timedelta\n",
    "from patsy import dmatrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>T</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>prev2_day_iv</th>\n",
       "      <th>prev_day_iv</th>\n",
       "      <th>5_day_rolling_return_stock</th>\n",
       "      <th>ASK</th>\n",
       "      <th>...</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>HIGH_vix</th>\n",
       "      <th>LOW_vix</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>spread_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36352</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>P</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.622737</td>\n",
       "      <td>-1.977</td>\n",
       "      <td>0.452074</td>\n",
       "      <td>0.404451</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>99.752109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>20.280237</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>21.627287</td>\n",
       "      <td>19.517935</td>\n",
       "      <td>20.380034</td>\n",
       "      <td>676.851764</td>\n",
       "      <td>2.706552</td>\n",
       "      <td>1.849205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36353</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>P</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.598160</td>\n",
       "      <td>-1.835</td>\n",
       "      <td>0.418943</td>\n",
       "      <td>0.383928</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>99.752109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>20.280237</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>21.627287</td>\n",
       "      <td>19.517935</td>\n",
       "      <td>20.380034</td>\n",
       "      <td>676.851764</td>\n",
       "      <td>2.706552</td>\n",
       "      <td>1.849205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36354</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>P</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.570362</td>\n",
       "      <td>-1.694</td>\n",
       "      <td>0.403192</td>\n",
       "      <td>0.374351</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>99.752109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>20.280237</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>21.627287</td>\n",
       "      <td>19.517935</td>\n",
       "      <td>20.380034</td>\n",
       "      <td>676.851764</td>\n",
       "      <td>2.706552</td>\n",
       "      <td>1.849205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36355</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>P</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.549241</td>\n",
       "      <td>-1.554</td>\n",
       "      <td>0.388048</td>\n",
       "      <td>0.365382</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>99.752109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>20.280237</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>21.627287</td>\n",
       "      <td>19.517935</td>\n",
       "      <td>20.380034</td>\n",
       "      <td>676.851764</td>\n",
       "      <td>2.706552</td>\n",
       "      <td>1.849205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36356</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>P</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.526871</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>0.360382</td>\n",
       "      <td>0.349066</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>99.752109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>20.280237</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>21.627287</td>\n",
       "      <td>19.517935</td>\n",
       "      <td>20.380034</td>\n",
       "      <td>676.851764</td>\n",
       "      <td>2.706552</td>\n",
       "      <td>1.849205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36347</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.742669</td>\n",
       "      <td>1.556</td>\n",
       "      <td>0.773147</td>\n",
       "      <td>0.718058</td>\n",
       "      <td>0.292655</td>\n",
       "      <td>822.255303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.706535</td>\n",
       "      <td>12.255009</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>13.997953</td>\n",
       "      <td>11.876221</td>\n",
       "      <td>13.695484</td>\n",
       "      <td>635.297620</td>\n",
       "      <td>-0.271641</td>\n",
       "      <td>1.960845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36348</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.764381</td>\n",
       "      <td>1.658</td>\n",
       "      <td>0.789361</td>\n",
       "      <td>0.735985</td>\n",
       "      <td>0.292655</td>\n",
       "      <td>822.255303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.706535</td>\n",
       "      <td>12.255009</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>13.997953</td>\n",
       "      <td>11.876221</td>\n",
       "      <td>13.695484</td>\n",
       "      <td>635.297620</td>\n",
       "      <td>-0.271641</td>\n",
       "      <td>1.960845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36349</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.786317</td>\n",
       "      <td>1.760</td>\n",
       "      <td>0.807648</td>\n",
       "      <td>0.754168</td>\n",
       "      <td>0.292655</td>\n",
       "      <td>822.255303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.706535</td>\n",
       "      <td>12.255009</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>13.997953</td>\n",
       "      <td>11.876221</td>\n",
       "      <td>13.695484</td>\n",
       "      <td>635.297620</td>\n",
       "      <td>-0.271641</td>\n",
       "      <td>1.960845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36350</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.798978</td>\n",
       "      <td>1.861</td>\n",
       "      <td>0.821686</td>\n",
       "      <td>0.773210</td>\n",
       "      <td>0.292655</td>\n",
       "      <td>822.255303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.706535</td>\n",
       "      <td>12.255009</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>13.997953</td>\n",
       "      <td>11.876221</td>\n",
       "      <td>13.695484</td>\n",
       "      <td>635.297620</td>\n",
       "      <td>-0.271641</td>\n",
       "      <td>1.960845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36351</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.822016</td>\n",
       "      <td>1.961</td>\n",
       "      <td>0.838985</td>\n",
       "      <td>0.791207</td>\n",
       "      <td>0.292655</td>\n",
       "      <td>822.255303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.706535</td>\n",
       "      <td>12.255009</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>13.997953</td>\n",
       "      <td>11.876221</td>\n",
       "      <td>13.695484</td>\n",
       "      <td>635.297620</td>\n",
       "      <td>-0.271641</td>\n",
       "      <td>1.960845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71695 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker       date cp_flag         T  impl_volatility  moneyness  \\\n",
       "36352   AAPL 2021-01-04       P  0.019841         0.622737     -1.977   \n",
       "36353   AAPL 2021-01-04       P  0.019841         0.598160     -1.835   \n",
       "36354   AAPL 2021-01-04       P  0.019841         0.570362     -1.694   \n",
       "36355   AAPL 2021-01-04       P  0.019841         0.549241     -1.554   \n",
       "36356   AAPL 2021-01-04       P  0.019841         0.526871     -1.415   \n",
       "...      ...        ...     ...       ...              ...        ...   \n",
       "36347   TSLA 2021-12-30       C  0.007937         0.742669      1.556   \n",
       "36348   TSLA 2021-12-30       C  0.007937         0.764381      1.658   \n",
       "36349   TSLA 2021-12-30       C  0.007937         0.786317      1.760   \n",
       "36350   TSLA 2021-12-30       C  0.007937         0.798978      1.861   \n",
       "36351   TSLA 2021-12-30       C  0.007937         0.822016      1.961   \n",
       "\n",
       "       prev2_day_iv  prev_day_iv  5_day_rolling_return_stock         ASK  ...  \\\n",
       "36352      0.452074     0.404451                    0.092909   99.752109  ...   \n",
       "36353      0.418943     0.383928                    0.092909   99.752109  ...   \n",
       "36354      0.403192     0.374351                    0.092909   99.752109  ...   \n",
       "36355      0.388048     0.365382                    0.092909   99.752109  ...   \n",
       "36356      0.360382     0.349066                    0.092909   99.752109  ...   \n",
       "...             ...          ...                         ...         ...  ...   \n",
       "36347      0.773147     0.718058                    0.292655  822.255303  ...   \n",
       "36348      0.789361     0.735985                    0.292655  822.255303  ...   \n",
       "36349      0.807648     0.754168                    0.292655  822.255303  ...   \n",
       "36350      0.821686     0.773210                    0.292655  822.255303  ...   \n",
       "36351      0.838985     0.791207                    0.292655  822.255303  ...   \n",
       "\n",
       "        1Y_bond   2Y_bond  CLOSE_vix   FF_rate   HIGH_vix    LOW_vix  \\\n",
       "36352  0.001770  0.032360  20.280237 -0.004600  21.627287  19.517935   \n",
       "36353  0.001770  0.032360  20.280237 -0.004600  21.627287  19.517935   \n",
       "36354  0.001770  0.032360  20.280237 -0.004600  21.627287  19.517935   \n",
       "36355  0.001770  0.032360  20.280237 -0.004600  21.627287  19.517935   \n",
       "36356  0.001770  0.032360  20.280237 -0.004600  21.627287  19.517935   \n",
       "...         ...       ...        ...       ...        ...        ...   \n",
       "36347  0.390523  0.706535  12.255009 -0.005836  13.997953  11.876221   \n",
       "36348  0.390523  0.706535  12.255009 -0.005836  13.997953  11.876221   \n",
       "36349  0.390523  0.706535  12.255009 -0.005836  13.997953  11.876221   \n",
       "36350  0.390523  0.706535  12.255009 -0.005836  13.997953  11.876221   \n",
       "36351  0.390523  0.706535  12.255009 -0.005836  13.997953  11.876221   \n",
       "\n",
       "        OPEN_vix  gold_price  reces_indi  spread_vix  \n",
       "36352  20.380034  676.851764    2.706552    1.849205  \n",
       "36353  20.380034  676.851764    2.706552    1.849205  \n",
       "36354  20.380034  676.851764    2.706552    1.849205  \n",
       "36355  20.380034  676.851764    2.706552    1.849205  \n",
       "36356  20.380034  676.851764    2.706552    1.849205  \n",
       "...          ...         ...         ...         ...  \n",
       "36347  13.695484  635.297620   -0.271641    1.960845  \n",
       "36348  13.695484  635.297620   -0.271641    1.960845  \n",
       "36349  13.695484  635.297620   -0.271641    1.960845  \n",
       "36350  13.695484  635.297620   -0.271641    1.960845  \n",
       "36351  13.695484  635.297620   -0.271641    1.960845  \n",
       "\n",
       "[71695 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_p = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_train_tech_scaled_p.parquet')\n",
    "data_train_c = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_train_tech_scaled_c.parquet')\n",
    "\n",
    "data_val_p = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_val_tech_scaled_p.parquet')\n",
    "data_val_c = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_val_tech_scaled_c.parquet')\n",
    "\n",
    "data_test_p = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_test_tech_scaled_p.parquet')\n",
    "data_test_c = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/updated_standardization/data_set_test_tech_scaled_c.parquet')\n",
    "\n",
    "firm_data = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/Firm_variables/daily_firm_data_median_new.parquet')\n",
    "\n",
    "data_train = pd.concat([data_train_p, data_train_c], axis=0)\n",
    "data_val = pd.concat([data_val_p, data_val_c], axis=0)\n",
    "data_test = pd.concat([data_test_p, data_test_c], axis=0)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['trading_days_till_exp'] + list(firm_data.columns[2:])\n",
    "# columns_to_drop = ['trading_days_till_exp']\n",
    "\n",
    "# Drop columns from datasets if they exist\n",
    "data_train = data_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "data_val = data_val.drop(columns=columns_to_drop, errors='ignore')\n",
    "data_test = data_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Ensure that data_val and data_test have the same column order as data_train\n",
    "data_val = data_val[data_train.columns]\n",
    "data_test = data_test[data_train.columns]\n",
    "\n",
    "data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data_train' and 'data_test' are already defined and loaded\n",
    "\n",
    "# Prepare train data for Call and Put options\n",
    "data_train_c = data_train[data_train['cp_flag'] == 'C']\n",
    "data_train_p = data_train[data_train['cp_flag'] == 'P']\n",
    "\n",
    "# Prepare validation data for Call and Put options\n",
    "data_validate_c = data_val[data_val['cp_flag'] == 'C']\n",
    "data_validate_p = data_val[data_val['cp_flag'] == 'P']\n",
    "\n",
    "# Prepare test data for Call and Put options\n",
    "data_test_c = data_test[data_test['cp_flag'] == 'C']\n",
    "data_test_p = data_test[data_test['cp_flag'] == 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# define the model\n",
    "def create_model(bias, activity):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=32,\n",
    "                  activation='relu',\n",
    "                  input_dim= train_x.shape[1],\n",
    "                  # # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-5),\n",
    "                  bias_regularizer= regularizers.L2(bias),\n",
    "                  activity_regularizer= regularizers.L2(activity)\n",
    "                  ))\n",
    "  model.add(Dense(units=32, activation= 'relu',\n",
    "                  bias_regularizer=regularizers.L2(bias),\n",
    "                  activity_regularizer=regularizers.L2(activity) #activation\n",
    "                  ))\n",
    "  model.add(Dense(units=1, activation= 'linear')) #miss linear\n",
    "\n",
    "  # compile the model\n",
    "  model.compile(optimizer= RMSprop(learning_rate=0.1), #'rmsprop',#Optimizer_trial,\n",
    "                loss= 'mean_squared_error',\n",
    "                metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KerasRegressor' from 'keras_tuner' (/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras_tuner/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'KerasRegressor' from 'keras_tuner' (/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras_tuner/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras_tuner import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from keras_tuner import KerasRegressor\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_model(hidden_layers=1, units=64, activation='relu', learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Function to create a Keras Sequential model with the given hyperparameters.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation=activation, input_dim=X_train.shape[1]))\n",
    "    \n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(units=units, activation=activation))\n",
    "        \n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_data_with_gridsearch_nn(train_data, validate_data, test_data, option_type, verbose=True):\n",
    "    \"\"\"\n",
    "    Prepare the data, perform hyperparameter tuning using Year 1 (train) and Year 2 (validation),\n",
    "    retrain the model on Year 1 + Year 2, and evaluate on Year 3 (test) for Neural Networks.\n",
    "    \n",
    "    Parameters:\n",
    "    train_data (pd.DataFrame): The training dataset (Year 1).\n",
    "    validate_data (pd.DataFrame): The validation dataset (Year 2).\n",
    "    test_data (pd.DataFrame): The testing dataset (Year 3).\n",
    "    option_type (str): Call or Put option type for labeling the print output.\n",
    "    verbose (bool): If True, prints progress information for hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # Prepare the train, validation, and test data\n",
    "    X_train = train_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Training features (Year 1)\n",
    "    y_train = train_data['impl_volatility']  # Training target (Year 1)\n",
    "\n",
    "    X_validate = validate_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Validation features (Year 2)\n",
    "    y_validate = validate_data['impl_volatility']  # Validation target (Year 2)\n",
    "    \n",
    "    X_test = test_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Test features (Year 3)\n",
    "    y_test = test_data['impl_volatility']  # Test target (Year 3)\n",
    "\n",
    "    # Define the hyperparameter grid for NN\n",
    "    param_grid = {\n",
    "        'hidden_layers': [1, 2, 3],                # Number of hidden layers\n",
    "        'units': [32, 64, 128],                    # Number of units per layer\n",
    "        'activation': ['relu', 'tanh'],            # Activation function\n",
    "        'learning_rate': [0.001, 0.01],            # Learning rate for Adam optimizer\n",
    "        'batch_size': [32, 64],                    # Batch size\n",
    "        'epochs': [50, 100],                       # Number of epochs\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    param_combinations = list(itertools.product(\n",
    "        param_grid['hidden_layers'], \n",
    "        param_grid['units'], \n",
    "        param_grid['activation'], \n",
    "        param_grid['learning_rate'], \n",
    "        param_grid['batch_size'], \n",
    "        param_grid['epochs']\n",
    "    ))\n",
    "\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    # Initialize variables to store the best model and best score\n",
    "    best_rmse_val = np.inf\n",
    "    best_params = None\n",
    "    best_nn_model = None\n",
    "\n",
    "    print(f\"Running manual hyperparameter tuning for {option_type} Options with Neural Networks...\")\n",
    "    \n",
    "    # Iterate over all hyperparameter combinations with progress tracking\n",
    "    for i, (hidden_layers, units, activation, learning_rate, batch_size, epochs) in enumerate(param_combinations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create the Keras model with the current set of hyperparameters\n",
    "        model = create_model(hidden_layers=hidden_layers, units=units, activation=activation, learning_rate=learning_rate)\n",
    "\n",
    "        # Early stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the model on the training data (Year 1)\n",
    "        history = model.fit(X_train, y_train, \n",
    "                            validation_data=(X_validate, y_validate),\n",
    "                            batch_size=batch_size, \n",
    "                            epochs=epochs, \n",
    "                            verbose=0, \n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "        # Validate the model on the validation data (Year 2)\n",
    "        y_val_pred = model.predict(X_validate)\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_validate, y_val_pred))\n",
    "\n",
    "        # Track the best performing hyperparameters based on validation RMSE\n",
    "        if rmse_val < best_rmse_val:\n",
    "            best_rmse_val = rmse_val\n",
    "            best_params = {\n",
    "                'hidden_layers': hidden_layers,\n",
    "                'units': units,\n",
    "                'activation': activation,\n",
    "                'learning_rate': learning_rate,\n",
    "                'batch_size': batch_size,\n",
    "                'epochs': epochs\n",
    "            }\n",
    "            best_nn_model = model\n",
    "\n",
    "        # Verbose output to track progress\n",
    "        if verbose:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Combination {i + 1}/{total_combinations} completed in {elapsed_time:.2f} seconds.\")\n",
    "            print(f\"Current RMSE (Validation): {rmse_val:.4f}\")\n",
    "            print(f\"Best RMSE so far: {best_rmse_val:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest Parameters for {option_type} Options with Neural Networks: {best_params}\")\n",
    "    \n",
    "    # Retrain the model on combined Year 1 (train) and Year 2 (validation)\n",
    "    print(\"Retraining the model on Year 1 and Year 2 combined...\")\n",
    "    X_combined = pd.concat([X_train, X_validate])\n",
    "    y_combined = pd.concat([y_train, y_validate])\n",
    "    best_nn_model.fit(X_combined, y_combined, batch_size=best_params['batch_size'], epochs=best_params['epochs'], verbose=0)\n",
    "\n",
    "    # In-sample (combined Year 1 + Year 2) predictions\n",
    "    y_combined_pred = best_nn_model.predict(X_combined)\n",
    "\n",
    "    # Evaluate In-Sample Performance (on combined Year 1 + Year 2)\n",
    "    rmse_combined = np.sqrt(mean_squared_error(y_combined, y_combined_pred))\n",
    "    r2_combined = r2_score(y_combined, y_combined_pred)\n",
    "    \n",
    "    print(f\"\\nIn-Sample Performance for {option_type} Options (Year 1 + Year 2):\")\n",
    "    print(f\"RMSE (Training + Validation): {rmse_combined:.4f}\")\n",
    "    print(f\"R² (Training + Validation): {r2_combined:.4f}\")\n",
    "\n",
    "    # After retraining, evaluate performance on the test data (Year 3)\n",
    "    y_test_pred = best_nn_model.predict(X_test)\n",
    "\n",
    "    # Evaluate Out-of-Sample Performance (on Test Data)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the final results\n",
    "    print(f\"\\nPerformance on Test Data (Year 3) for {option_type} Options:\")\n",
    "    print(f\"Out-of-Sample RMSE (Test): {rmse_test:.4f}\")\n",
    "    print(f\"Out-of-Sample R² (Test): {r2_test:.4f}\")\n",
    "\n",
    "\n",
    "# Call the function for Call options data\n",
    "prepare_data_with_gridsearch_nn(data_train_c, data_validate_c, data_test_c, 'Call')\n",
    "\n",
    "# Call the function for Put options data\n",
    "prepare_data_with_gridsearch_nn(data_train_p, data_validate_p, data_test_p, 'Put')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
