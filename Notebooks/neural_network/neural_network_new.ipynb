{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"d6f71f1f-fd77-4522-be50-22df8fe6a0b3\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"a538452d-e5fc-498e-9834-3915178eea8a\":{\"version\":\"3.4.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"8caed070126d401a918d6184dcfcb379\",\"client_comm_id\":\"af53a53aea344b6897afa084ca6d5b72\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"a538452d-e5fc-498e-9834-3915178eea8a\",\"roots\":{\"p1002\":\"d6f71f1f-fd77-4522-be50-22df8fe6a0b3\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We load in the specific data needed\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import datetime\n",
    "import hvplot.polars\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.interpolate import bisplrep, bisplev\n",
    "from datetime import timedelta\n",
    "from patsy import dmatrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>moneyness_mean</th>\n",
       "      <th>moneyness_std</th>\n",
       "      <th>impl_volatility_mean</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>volume_option_mean</th>\n",
       "      <th>volume_option_std</th>\n",
       "      <th>spread_option_mean</th>\n",
       "      <th>spread_option_std</th>\n",
       "      <th>prc_option_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>10Y_RIR</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>hi-lo_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-1.559693</td>\n",
       "      <td>-0.899796</td>\n",
       "      <td>0.487425</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.892034</td>\n",
       "      <td>-0.775850</td>\n",
       "      <td>1.931987</td>\n",
       "      <td>2.002133</td>\n",
       "      <td>1.143992</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-1.238194</td>\n",
       "      <td>0.280259</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.672816</td>\n",
       "      <td>-0.593749</td>\n",
       "      <td>0.841789</td>\n",
       "      <td>1.048057</td>\n",
       "      <td>0.555735</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.862361</td>\n",
       "      <td>-0.483196</td>\n",
       "      <td>0.484917</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.541080</td>\n",
       "      <td>-0.462838</td>\n",
       "      <td>0.101784</td>\n",
       "      <td>0.096188</td>\n",
       "      <td>0.303572</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.517492</td>\n",
       "      <td>0.095575</td>\n",
       "      <td>0.495387</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.526974</td>\n",
       "      <td>-0.629729</td>\n",
       "      <td>-0.087657</td>\n",
       "      <td>-0.114131</td>\n",
       "      <td>0.039180</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.154267</td>\n",
       "      <td>-0.016268</td>\n",
       "      <td>0.485254</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.392774</td>\n",
       "      <td>-0.166903</td>\n",
       "      <td>-0.229368</td>\n",
       "      <td>-0.170793</td>\n",
       "      <td>-0.190332</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>0.376182</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>4.338761</td>\n",
       "      <td>3.741729</td>\n",
       "      <td>-0.552380</td>\n",
       "      <td>-0.544018</td>\n",
       "      <td>-0.497352</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.514576</td>\n",
       "      <td>0.449081</td>\n",
       "      <td>0.378704</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>4.850644</td>\n",
       "      <td>6.542937</td>\n",
       "      <td>-0.596780</td>\n",
       "      <td>-0.608031</td>\n",
       "      <td>-0.545443</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.858547</td>\n",
       "      <td>-6.472006</td>\n",
       "      <td>0.389960</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>2.451356</td>\n",
       "      <td>2.170486</td>\n",
       "      <td>-0.626380</td>\n",
       "      <td>-0.608329</td>\n",
       "      <td>-0.584979</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.192630</td>\n",
       "      <td>1.742726</td>\n",
       "      <td>0.378551</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>0.689877</td>\n",
       "      <td>0.521470</td>\n",
       "      <td>-0.612320</td>\n",
       "      <td>-0.601425</td>\n",
       "      <td>-0.585851</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.564968</td>\n",
       "      <td>-0.597320</td>\n",
       "      <td>0.395207</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.576701</td>\n",
       "      <td>-0.621200</td>\n",
       "      <td>-0.622706</td>\n",
       "      <td>-0.597199</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5030 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  moneyness_mean  moneyness_std  impl_volatility_mean  \\\n",
       "10   2019-01-02       -1.559693      -0.899796              0.487425   \n",
       "11   2019-01-02       -1.238194       0.280259              0.480363   \n",
       "12   2019-01-02       -0.862361      -0.483196              0.484917   \n",
       "13   2019-01-02       -0.517492       0.095575              0.495387   \n",
       "14   2019-01-02       -0.154267      -0.016268              0.485254   \n",
       "...         ...             ...            ...                   ...   \n",
       "5035 2020-12-31        0.116888       0.118652              0.376182   \n",
       "5036 2020-12-31        0.514576       0.449081              0.378704   \n",
       "5037 2020-12-31        0.858547      -6.472006              0.389960   \n",
       "5038 2020-12-31        1.192630       1.742726              0.378551   \n",
       "5039 2020-12-31        1.564968      -0.597320              0.395207   \n",
       "\n",
       "        T_mean  volume_option_mean  volume_option_std  spread_option_mean  \\\n",
       "10   -0.000623           -0.892034          -0.775850            1.931987   \n",
       "11   -0.000623           -0.672816          -0.593749            0.841789   \n",
       "12   -0.000623           -0.541080          -0.462838            0.101784   \n",
       "13   -0.000623           -0.526974          -0.629729           -0.087657   \n",
       "14   -0.000623           -0.392774          -0.166903           -0.229368   \n",
       "...        ...                 ...                ...                 ...   \n",
       "5035 -1.520941            4.338761           3.741729           -0.552380   \n",
       "5036 -1.520941            4.850644           6.542937           -0.596780   \n",
       "5037 -1.520941            2.451356           2.170486           -0.626380   \n",
       "5038 -1.520941            0.689877           0.521470           -0.612320   \n",
       "5039 -1.520941           -0.365531          -0.576701           -0.621200   \n",
       "\n",
       "      spread_option_std  prc_option_mean  ...  cp_flag   FF_rate  gold_price  \\\n",
       "10             2.002133         1.143992  ...        C  1.126349   -1.357150   \n",
       "11             1.048057         0.555735  ...        C  1.126349   -1.357150   \n",
       "12             0.096188         0.303572  ...        C  1.126349   -1.357150   \n",
       "13            -0.114131         0.039180  ...        C  1.126349   -1.357150   \n",
       "14            -0.170793        -0.190332  ...        C  1.126349   -1.357150   \n",
       "...                 ...              ...  ...      ...       ...         ...   \n",
       "5035          -0.544018        -0.497352  ...        C -1.162816    1.436988   \n",
       "5036          -0.608031        -0.545443  ...        C -1.162816    1.436988   \n",
       "5037          -0.608329        -0.584979  ...        C -1.162816    1.436988   \n",
       "5038          -0.601425        -0.585851  ...        C -1.162816    1.436988   \n",
       "5039          -0.622706        -0.597199  ...        C -1.162816    1.436988   \n",
       "\n",
       "      reces_indi   10Y_RIR   1Y_bond   2Y_bond  OPEN_vix  CLOSE_vix  hi-lo_vix  \n",
       "10     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "11     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "12     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "13     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "14     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "...          ...       ...       ...       ...       ...        ...        ...  \n",
       "5035    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5036    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5037    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5038    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5039    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "\n",
       "[5030 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_data_train_c = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/tech_data/data_set_train_val_tech_scaled_c.parquet')\n",
    "tot_data_train_p = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/tech_data/data_set_train_val_tech_scaled_p.parquet')\n",
    "\n",
    "data_test_p = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/tech_data/data_set_test_tech_scaled_p_total.parquet')\n",
    "data_test_c = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/tech_data/data_set_test_tech_scaled_c_total.parquet')\n",
    "\n",
    "# firm_data = pd.read_parquet('/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Data/Firm_variables/daily_firm_data_median_new.parquet')\n",
    "\n",
    "data_test = pd.concat([data_test_p, data_test_c], axis=0)\n",
    "data_train_tot = pd.concat([tot_data_train_c, tot_data_train_p], axis=0)\n",
    "\n",
    "# # List of columns to drop\n",
    "data_test = pd.concat([data_test_p, data_test_c], axis=0)\n",
    "data_train_tot = pd.concat([tot_data_train_p, tot_data_train_c], axis=0)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['moneyness_squared_mean', 'moneyness_group', 'tau_squared_mean', 'moneyness_tau_mean', 'tau_squared_std', 'moneyness_tau_std', 'T_std', 'impl_volatility_std', 'moneyness_squared_std']\n",
    "# columns_to_drop = ['trading_days_till_exp']\n",
    "\n",
    "# Drop columns from datasets if they exist\n",
    "# data_train = data_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "# data_val = data_val.drop(columns=columns_to_drop, errors='ignore')\n",
    "data_test = data_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "data_train_tot = data_train_tot.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "data_test = data_test[data_test['impl_volatility_mean'] != 0]\n",
    "data_train_tot = data_train_tot[data_train_tot['impl_volatility_mean'] != 0]\n",
    "\n",
    "data_train_tot_c = data_train_tot[data_train_tot['cp_flag'] == 'C']\n",
    "data_train_tot_p = data_train_tot[data_train_tot['cp_flag'] == 'P']\n",
    "\n",
    "# top_features_c = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv', 'BIDLO', 'OPEN_vix','hi-lo_stock','FF_rate', 'gold_price', 'reces_indi', 'cumulative_return','spread_vix', 'vol_stock','5_day_rolling_return_stock','spread_stock','1Y_bond','CLOSE_vix','RET','moneyness','10Y_RIR' ]\n",
    "# top_features_p = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv', 'cumulative_return', 'gold_price', 'reces_indi','FF_rate','hi-lo_stock', 'PRC_actual' , 'CLOSE_vix' ]\n",
    "\n",
    "# data_train_tot_c = tot_data_train[tot_data_train['cp_flag'] == 'C'][top_features_c]\n",
    "# data_train_tot_p = tot_data_train[tot_data_train['cp_flag'] == 'P'][top_features_p]\n",
    "\n",
    "\n",
    "\n",
    "data_train_tot_c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# import pandas as pd\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # Set random seeds for reproducibility\n",
    "# def set_random_seed(seed=42):\n",
    "#     np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "\n",
    "# def build_nn(input_shape, **kwargs):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(64, input_dim=input_shape, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1))  # Single output for regression task\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# def feature_permutation_importance_nn(train_data, verbose=True):\n",
    "#     set_random_seed(42)  # Ensure the seed is set before training\n",
    "    \n",
    "#     X_train = train_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Drop unwanted columns\n",
    "#     y_train = train_data['impl_volatility']  # Target variable (implied volatility)\n",
    "\n",
    "#     # Wrapping the Keras model with KerasRegressor\n",
    "#     nn_model = KerasRegressor(model=build_nn, input_shape=X_train.shape[1], verbose=0)\n",
    "\n",
    "#     if verbose:\n",
    "#         print(\"Training Neural Network model...\")\n",
    "\n",
    "#     # Fit the NN model\n",
    "#     nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "#     # Perform permutation importance\n",
    "#     perm_importance = permutation_importance(\n",
    "#         estimator=nn_model, \n",
    "#         X=X_train, \n",
    "#         y=y_train, \n",
    "#         n_repeats=10, \n",
    "#         random_state=42,  # Ensure random_state for permutation importance is set\n",
    "#         scoring='r2'\n",
    "#     )\n",
    "\n",
    "#     # Create a DataFrame for feature importances\n",
    "#     feature_importances = pd.DataFrame({\n",
    "#         'Feature': X_train.columns,\n",
    "#         'Importance': perm_importance.importances_mean,\n",
    "#         'Importance_std': perm_importance.importances_std\n",
    "#     })\n",
    "\n",
    "#     # Extract and return feature importances\n",
    "#     feature_importances = pd.Series(nn_model.feature_importances_, index=X_train.columns)\n",
    "#     return feature_importances\n",
    "\n",
    "#     # feature_importances = feature_importances.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "#     # return feature_importances\n",
    "\n",
    "# # Call options feature importance\n",
    "# print(\"Evaluating features for Call options (NN model)...\")\n",
    "# feature_importances_call_nn = feature_permutation_importance_nn(data_train_tot_c, verbose=True)\n",
    "# print(feature_importances_call_nn)\n",
    "\n",
    "# # Put options feature importance\n",
    "# print(\"\\nEvaluating features for Put options (NN model)...\")\n",
    "# feature_importances_put_nn = feature_permutation_importance_nn(data_train_tot_p, verbose=True)\n",
    "# print(feature_importances_put_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>moneyness_mean</th>\n",
       "      <th>moneyness_std</th>\n",
       "      <th>impl_volatility_mean</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>volume_option_mean</th>\n",
       "      <th>volume_option_std</th>\n",
       "      <th>spread_option_mean</th>\n",
       "      <th>spread_option_std</th>\n",
       "      <th>prc_option_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>10Y_RIR</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>hi-lo_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-1.559693</td>\n",
       "      <td>-0.899796</td>\n",
       "      <td>0.487425</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.892034</td>\n",
       "      <td>-0.775850</td>\n",
       "      <td>1.931987</td>\n",
       "      <td>2.002133</td>\n",
       "      <td>1.143992</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-1.238194</td>\n",
       "      <td>0.280259</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.672816</td>\n",
       "      <td>-0.593749</td>\n",
       "      <td>0.841789</td>\n",
       "      <td>1.048057</td>\n",
       "      <td>0.555735</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.862361</td>\n",
       "      <td>-0.483196</td>\n",
       "      <td>0.484917</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.541080</td>\n",
       "      <td>-0.462838</td>\n",
       "      <td>0.101784</td>\n",
       "      <td>0.096188</td>\n",
       "      <td>0.303572</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.517492</td>\n",
       "      <td>0.095575</td>\n",
       "      <td>0.495387</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.526974</td>\n",
       "      <td>-0.629729</td>\n",
       "      <td>-0.087657</td>\n",
       "      <td>-0.114131</td>\n",
       "      <td>0.039180</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>-0.154267</td>\n",
       "      <td>-0.016268</td>\n",
       "      <td>0.485254</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.392774</td>\n",
       "      <td>-0.166903</td>\n",
       "      <td>-0.229368</td>\n",
       "      <td>-0.170793</td>\n",
       "      <td>-0.190332</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>-1.357150</td>\n",
       "      <td>-0.709812</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.374613</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>0.677893</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>-0.134139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>0.376182</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>4.338761</td>\n",
       "      <td>3.741729</td>\n",
       "      <td>-0.552380</td>\n",
       "      <td>-0.544018</td>\n",
       "      <td>-0.497352</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.514576</td>\n",
       "      <td>0.449081</td>\n",
       "      <td>0.378704</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>4.850644</td>\n",
       "      <td>6.542937</td>\n",
       "      <td>-0.596780</td>\n",
       "      <td>-0.608031</td>\n",
       "      <td>-0.545443</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.858547</td>\n",
       "      <td>-6.472006</td>\n",
       "      <td>0.389960</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>2.451356</td>\n",
       "      <td>2.170486</td>\n",
       "      <td>-0.626380</td>\n",
       "      <td>-0.608329</td>\n",
       "      <td>-0.584979</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.192630</td>\n",
       "      <td>1.742726</td>\n",
       "      <td>0.378551</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>0.689877</td>\n",
       "      <td>0.521470</td>\n",
       "      <td>-0.612320</td>\n",
       "      <td>-0.601425</td>\n",
       "      <td>-0.585851</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.564968</td>\n",
       "      <td>-0.597320</td>\n",
       "      <td>0.395207</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.576701</td>\n",
       "      <td>-0.621200</td>\n",
       "      <td>-0.622706</td>\n",
       "      <td>-0.597199</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.436988</td>\n",
       "      <td>0.268241</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.215175</td>\n",
       "      <td>-1.208572</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.552581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5030 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  moneyness_mean  moneyness_std  impl_volatility_mean  \\\n",
       "10   2019-01-02       -1.559693      -0.899796              0.487425   \n",
       "11   2019-01-02       -1.238194       0.280259              0.480363   \n",
       "12   2019-01-02       -0.862361      -0.483196              0.484917   \n",
       "13   2019-01-02       -0.517492       0.095575              0.495387   \n",
       "14   2019-01-02       -0.154267      -0.016268              0.485254   \n",
       "...         ...             ...            ...                   ...   \n",
       "5035 2020-12-31        0.116888       0.118652              0.376182   \n",
       "5036 2020-12-31        0.514576       0.449081              0.378704   \n",
       "5037 2020-12-31        0.858547      -6.472006              0.389960   \n",
       "5038 2020-12-31        1.192630       1.742726              0.378551   \n",
       "5039 2020-12-31        1.564968      -0.597320              0.395207   \n",
       "\n",
       "        T_mean  volume_option_mean  volume_option_std  spread_option_mean  \\\n",
       "10   -0.000623           -0.892034          -0.775850            1.931987   \n",
       "11   -0.000623           -0.672816          -0.593749            0.841789   \n",
       "12   -0.000623           -0.541080          -0.462838            0.101784   \n",
       "13   -0.000623           -0.526974          -0.629729           -0.087657   \n",
       "14   -0.000623           -0.392774          -0.166903           -0.229368   \n",
       "...        ...                 ...                ...                 ...   \n",
       "5035 -1.520941            4.338761           3.741729           -0.552380   \n",
       "5036 -1.520941            4.850644           6.542937           -0.596780   \n",
       "5037 -1.520941            2.451356           2.170486           -0.626380   \n",
       "5038 -1.520941            0.689877           0.521470           -0.612320   \n",
       "5039 -1.520941           -0.365531          -0.576701           -0.621200   \n",
       "\n",
       "      spread_option_std  prc_option_mean  ...  cp_flag   FF_rate  gold_price  \\\n",
       "10             2.002133         1.143992  ...        C  1.126349   -1.357150   \n",
       "11             1.048057         0.555735  ...        C  1.126349   -1.357150   \n",
       "12             0.096188         0.303572  ...        C  1.126349   -1.357150   \n",
       "13            -0.114131         0.039180  ...        C  1.126349   -1.357150   \n",
       "14            -0.170793        -0.190332  ...        C  1.126349   -1.357150   \n",
       "...                 ...              ...  ...      ...       ...         ...   \n",
       "5035          -0.544018        -0.497352  ...        C -1.162816    1.436988   \n",
       "5036          -0.608031        -0.545443  ...        C -1.162816    1.436988   \n",
       "5037          -0.608329        -0.584979  ...        C -1.162816    1.436988   \n",
       "5038          -0.601425        -0.585851  ...        C -1.162816    1.436988   \n",
       "5039          -0.622706        -0.597199  ...        C -1.162816    1.436988   \n",
       "\n",
       "      reces_indi   10Y_RIR   1Y_bond   2Y_bond  OPEN_vix  CLOSE_vix  hi-lo_vix  \n",
       "10     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "11     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "12     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "13     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "14     -0.709812  1.566975  1.374613  1.472822  0.677893   0.478375  -0.134139  \n",
       "...          ...       ...       ...       ...       ...        ...        ...  \n",
       "5035    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5036    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5037    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5038    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "5039    0.268241 -0.801314 -1.215175 -1.208572 -0.056028  -0.033654  -0.552581  \n",
       "\n",
       "[5030 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_tot_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# def build_nn(input_dim, **kwargs):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1))  # Single output for regression task\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def feature_permutation_importance_nn(train_data, verbose=True):\n",
    "#     X_train = train_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Drop unwanted columns\n",
    "#     y_train = train_data['impl_volatility']  # Target variable (implied volatility)\n",
    "\n",
    "#     # Wrapping the Keras model with KerasRegressor\n",
    "#     nn_model = KerasRegressor(model=build_nn, input_dim=X_train.shape[1], verbose=0)\n",
    "\n",
    "#     if verbose:\n",
    "#         print(\"Training Neural Network model for Call options...\")\n",
    "\n",
    "#     # Fit the NN model\n",
    "#     nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "#     # Perform permutation importance\n",
    "#     perm_importance = permutation_importance(\n",
    "#         estimator=nn_model, \n",
    "#         X=X_train, \n",
    "#         y=y_train, \n",
    "#         n_repeats=10, \n",
    "#         random_state=42, \n",
    "#         scoring='r2'\n",
    "#     )\n",
    "\n",
    "#     # Create a DataFrame for feature importances\n",
    "#     feature_importances = pd.DataFrame({\n",
    "#         'Feature': X_train.columns,\n",
    "#         'Importance': perm_importance.importances_mean,\n",
    "#         'Importance_std': perm_importance.importances_std\n",
    "#     })\n",
    "\n",
    "#     feature_importances = feature_importances.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "#     return feature_importances\n",
    "\n",
    "# # Call options feature importance\n",
    "# print(\"Evaluating features for Call options (NN model)...\")\n",
    "# feature_importances_call_nn = feature_permutation_importance_nn(data_train_tot_c, verbose=True)\n",
    "# print(feature_importances_call_nn)\n",
    "\n",
    "# # Put options feature importance\n",
    "# print(\"\\nEvaluating features for Put options (NN model)...\")\n",
    "# feature_importances_put_nn = feature_permutation_importance_nn(data_train_tot_p, verbose=True)\n",
    "# print(feature_importances_put_nn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating features for Call options (NN model)...\n",
      "Training Neural Network model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step \n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\n",
      "Evaluating features for Put options (NN model)...\n",
      "Training Neural Network model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def build_nn(input_shape):\n",
    "    \"\"\"\n",
    "    Build a simple Neural Network model using Keras.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape (int): Number of input features.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Compiled Neural Network model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_shape, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Single output for regression task\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def feature_permutation_importance_nn(train_data, verbose=True):\n",
    "    \"\"\"\n",
    "    Perform permutation importance for a Neural Network on the training data to identify the top features.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data (pd.DataFrame): The training dataset.\n",
    "    - verbose (bool): If True, prints progress information.\n",
    "    \n",
    "    Returns:\n",
    "    - feature_importances (pd.DataFrame): A dataframe containing feature names and their importance.\n",
    "    \"\"\"\n",
    "    # Prepare the train data\n",
    "    X_train = train_data.drop(columns=['impl_volatility_mean', 'date', 'cp_flag'])  # Drop unwanted columns\n",
    "    y_train = train_data['impl_volatility_mean']  # Target variable (implied volatility)\n",
    "\n",
    "    # Build and train the Neural Network model\n",
    "    nn_model = build_nn(X_train.shape[1])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training Neural Network model...\")\n",
    "\n",
    "    # Fit the NN model (with verbose = 0 to avoid too much output)\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Perform permutation importance using the custom prediction function\n",
    "    perm_importance = permutation_importance(\n",
    "        estimator=nn_model, \n",
    "        X=X_train, \n",
    "        y=y_train, \n",
    "        n_repeats=10, \n",
    "        random_state=42, \n",
    "        scoring='r2'\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for feature importances\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': perm_importance.importances_mean,\n",
    "        'Importance_std': perm_importance.importances_std\n",
    "    })\n",
    "\n",
    "    # Sort by importance\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return feature_importances\n",
    "\n",
    "# Call options\n",
    "print(\"Evaluating features for Call options (NN model)...\")\n",
    "feature_importances_call_nn = feature_permutation_importance_nn(data_train_tot_c, verbose=True)\n",
    "# selected_features_call_nn = select_top_features(feature_importances_call_nn, threshold=0.85)\n",
    "\n",
    "# Put options\n",
    "print(\"\\nEvaluating features for Put options (NN model)...\")\n",
    "feature_importances_put_nn = feature_permutation_importance_nn(data_train_tot_p, verbose=True)\n",
    "# selected_features_put_nn = select_top_features(feature_importances_put_nn, threshold=0.85)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCMAAAIjCAYAAAA5n9HyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1yV5fvA8c8BzjkyRXDhBMWBluIqFRUXrjQ3KpZg7hypudBkmKaWu3Kl4gI1Z6ZZokKZlVmOStHUJDFzpAIiyDnC8/uDL+fnEVBA8HFc79erV55n3Pf9XDegz8U9NIqiKAghhBBCCCGEEEI8IRZqN0AIIYQQQgghhBAvFklGCCGEEEIIIYQQ4omSZIQQQgghhBBCCCGeKElGCCGEEEIIIYQQ4omSZIQQQgghhBBCCCGeKElGCCGEEEIIIYQQ4omSZIQQQgghhBBCCCGeKElGCCGEEEIIIYQQ4omSZIQQQgghhBBCCCGeKElGCCGEECoJCAjA1dVV7Wbki0ajISQkRO1mPJeOHDlC48aNsbW1RaPRcPz4cbWblGfZfW0/zV8zsbGxaDQaVq9erXZTcpSUlETJkiUJDw9XuymqcnV1JSAgIF/3Pvg1uHTpUipUqEBqamrBNE4IkSeSjBBCCCFy6ffff6dHjx5UrFiRIkWKULZsWXx8fPj444/Vblq2IiIiWLBggWr1Z77gZfdfw4YNC6XOy5cvExIS8ky+wAMYjUZ69uzJzZs3mT9/PuvWraNixYqFXu/Vq1cZN24c1atXx8bGBltbW+rVq8f06dOJj48v9PofdOPGDcaPH0+1atUoUqQITk5OtG3bll27dj1WuWp/TzyOhQsXYm9vT+/evU3HQkJC0Gg0lCpViuTk5Cz3uLq60rFjR7Njmd+Dc+fOzXL96tWr0Wg0/PLLLw9tS3R0tKmc9evXZ3uNl5cXGo2Gl156KTePp4qAgAAMBgPLli1TuylCvJCs1G6AEEII8Sz44YcfaNGiBRUqVGDQoEGULl2auLg4fvrpJxYuXMjIkSPVbmIWERER/PHHH4wePVrVdvTp04cOHTqYHStRokSh1HX58mVCQ0NxdXXF09OzUOooTOfPn+fvv//ms88+Y+DAgU+kziNHjtChQweSkpJ44403qFevHgC//PILs2bN4rvvvmPv3r1PpC0AZ86coVWrVly/fp3+/ftTv3594uPjCQ8Pp1OnTowbN46PPvooX2Xn9D1RsWJFUlJS0Gq1BfAEBc9oNLJw4ULGjBmDpaVllvPXrl1jyZIlvPvuu7ku86OPPmLYsGHY2Njku11FihQhIiKCN954w+x4bGwsP/zwA0WKFMl32U9CkSJF8Pf3Z968eYwcORKNRqN2k4R4oUgyQgghhMiFGTNmULRoUY4cOYKjo6PZuWvXrqnTqGdE3bp1s7ysPGvu3r2LTqfDwqJwB5Vmfi09+DX2OO7cuYOtrW225+Lj4+natSuWlpYcO3aM6tWrm52fMWMGn332WYG15VGMRiM9evTg1q1bfPfdd7z66qumc2PGjKFv377MmTOH+vXr06tXrwKrV6PRPNUvzrt27eL69ev4+vpme97T05OPPvqIt99+G2tr60eW5+npyfHjx1m6dCljx47Nd7s6dOjAzp07+e+//yhevLjpeEREBKVKlaJKlSrcunUr3+U/Cb6+vnz44YdERUXRsmVLtZsjxAtFpmkIIYQQuXD+/Hlq1qyZ7UtiyZIlsxxbv3499erVw9raGicnJ3r37k1cXNwj60lPT2fBggXUrFmTIkWKUKpUKYYMGZLtP+j37NmDt7c39vb2ODg40KBBAyIiIgBo3rw5u3fv5u+//zYNp75/Dn9qairBwcG4u7uj1+spX748EyZMyDJ3OjU1lTFjxlCiRAns7e15/fXXuXTp0iOfIy9Onz5Njx49cHJyokiRItSvX5+dO3eaXXPz5k3GjRvHyy+/jJ2dHQ4ODrRv354TJ06YromOjqZBgwYA9O/f3/TcmesA5DTXvHnz5jRv3tysHI1Gw8aNG3nvvfcoW7YsNjY2JCYmAnD48GHatWtH0aJFsbGxwdvbm0OHDpmVefv2bUaPHo2rqyt6vZ6SJUvi4+PD0aNHc4xDQEAA3t7eAPTs2RONRmPWrgMHDtC0aVNsbW1xdHSkc+fOxMTEmJWROWz/1KlT+Pn5UaxYMZo0aZJjncuWLeOff/5h3rx5WRIRAKVKleK9994zff7iiy947bXXKFOmDHq9nsqVK/P++++TlpaWYx15sXXrVv744w8mTZpklogAsLS0ZNmyZTg6OprN+8/sr02bNjF58mRKly6Nra0tr7/+utn33MO+J3JaMyIvMT937hwBAQE4OjpStGhR+vfvn2XqRGRkJE2aNMHR0RE7OzuqVavG5MmTHxmXHTt24OrqSuXKlbM9HxQUxNWrV1myZMkjy4KMKRQtW7bkww8/JCUlJVf3ZKdz587o9Xo2b95sdjwiIgJfX99sR3Hcu3eP999/n8qVK6PX63F1dWXy5MlZfvYoisL06dMpV64cNjY2tGjRgpMnT2bbjvj4eEaPHk358uXR6/W4u7sze/Zs0tPTH/kM9erVw8nJiS+++CIPTy6EKAgyMkIIIYTIhYoVK/Ljjz/yxx9/PHIO9IwZM5g6dSq+vr4MHDiQ69ev8/HHH9OsWTOOHTv20N96DxkyhNWrV9O/f39GjRrFhQsX+OSTTzh27BiHDh0yDSNfvXo1b731FjVr1iQwMBBHR0eOHTvG119/jZ+fH1OmTCEhIYFLly4xf/58AOzs7ICMhMfrr7/O999/z+DBg/Hw8OD3339n/vz5/Pnnn+zYscPUnoEDB7J+/Xr8/Pxo3LgxBw4c4LXXXstT7JKTk/nvv//MjhUtWhStVsvJkyfx8vKibNmyTJo0CVtbWz7//HO6dOnC1q1b6dq1KwB//fUXO3bsoGfPnri5uXH16lWWLVuGt7c3p06dokyZMnh4eDBt2jSCgoIYPHgwTZs2BaBx48Z5am+m999/H51Ox7hx40hNTUWn03HgwAHat29PvXr1CA4OxsLCgrCwMFq2bMnBgwd55ZVXABg6dChbtmxhxIgR1KhRgxs3bvD9998TExND3bp1s61vyJAhlC1blg8++IBRo0bRoEEDSpUqBcC+ffto3749lSpVIiQkhJSUFD7++GO8vLw4evRolsUie/bsSZUqVfjggw9QFCXHZ9y5cyfW1tb06NEjVzFZvXo1dnZ2jB07Fjs7Ow4cOEBQUBCJiYn5njpxvy+//BKAfv36ZXu+aNGidO7cmTVr1nDu3Dnc3d1N52bMmIFGo2HixIlcu3aNBQsW0Lp1a44fP461tfVDvyeyk9eY+/r64ubmxsyZMzl69CgrVqygZMmSzJ49G4CTJ0/SsWNHatWqxbRp09Dr9Zw7dy5LIis7P/zwQ45fNwBNmzY1JReGDRuWq9ERISEhNGvWjCVLluR7dISNjQ2dO3dmw4YNDBs2DIATJ05w8uRJVqxYwW+//ZblnoEDB7JmzRp69OjBu+++y+HDh5k5cyYxMTFs377ddF1QUBDTp0+nQ4cOdOjQgaNHj9KmTRsMBoNZecnJyXh7e/PPP/8wZMgQKlSowA8//EBgYCD//vtvrtYIqVu3bq76QQhRwBQhhBBCPNLevXsVS0tLxdLSUmnUqJEyYcIE5ZtvvlEMBoPZdbGxsYqlpaUyY8YMs+O///67YmVlZXbc399fqVixounzwYMHFUAJDw83u/frr782Ox4fH6/Y29srr776qpKSkmJ2bXp6uunPr732mln5mdatW6dYWFgoBw8eNDu+dOlSBVAOHTqkKIqiHD9+XAGUt99+2+w6Pz8/BVCCg4OzidT/u3DhggJk+19UVJSiKIrSqlUr5eWXX1bu3r1r9gyNGzdWqlSpYjp29+5dJS0tLUv5er1emTZtmunYkSNHFEAJCwvL0p6KFSsq/v7+WY57e3sr3t7eps9RUVEKoFSqVElJTk42a1eVKlWUtm3bmsU5OTlZcXNzU3x8fEzHihYtqgwfPvyh8clOZt2bN282O+7p6amULFlSuXHjhunYiRMnFAsLC6Vfv36mY8HBwQqg9OnTJ1f1FStWTKldu3au23d/PDINGTJEsbGxMevDB7+2FUXJ1deMp6enUrRo0YdeM2/ePAVQdu7cqSjK/8esbNmySmJioum6zz//XAGUhQsXmo7l9D2R+bV6/9dNXmP+1ltvmZXZtWtXxdnZ2fR5/vz5CqBcv379oc/3IKPRqGg0GuXdd9/Nci6z7uvXryvffvutAijz5s0zna9YsaLy2muvmd0DmL42W7RooZQuXdrUr2FhYQqgHDly5KFtuv/rdNeuXYpGo1EuXryoKIqijB8/XqlUqZKiKBnfWzVr1jTdl/kzZeDAgWbljRs3TgGUAwcOKIqiKNeuXVN0Op3y2muvmX2vTZ48WQHMvo/ff/99xdbWVvnzzz/Nypw0aZJiaWlpalfms2f3NTh48GDF2tr6oc8shCh4Mk1DCCGEyAUfHx9+/PFHXn/9dU6cOMGHH35I27ZtKVu2rNmUgm3btpGeno6vry///fef6b/SpUtTpUoVoqKicqxj8+bNFC1aFB8fH7N769Wrh52dneneyMhIbt++zaRJk7LMc8/NAmybN2/Gw8OD6tWrm9WTOV86s56vvvoKgFGjRpndn9cFMQcPHkxkZKTZf7Vr1+bmzZscOHAAX19fbt++bWrHjRs3aNu2LWfPnuWff/4BQK/Xm9ZrSEtL48aNG6Zh7g+b+vA4/P39zX7DfPz4cc6ePYufnx83btwwtffOnTu0atWK7777zjQs3NHRkcOHD3P58uXHbse///7L8ePHCQgIwMnJyXS8Vq1a+Pj4mPrpfkOHDs1V2YmJidjb2+e6LffHI7PPmjZtSnJyMqdPn851OTm5ffv2I9uTeT5z2kymfv36md3bo0cPXFxcso3PoxREzJs2bcqNGzdM7cwcEfXFF1/kavpApps3b6IoCsWKFXvodc2aNaNFixZ5mnoREhLClStXWLp0aa7b86A2bdrg5OTExo0bURSFjRs30qdPn2yvzYzbgyMxMhfe3L17N5AxKsVgMGRZVDK7nz2bN2+madOmFCtWzOznWevWrUlLS+O777575DMUK1aMlJSUbHckEUIUHpmmIYQQQuRSgwYN2LZtGwaDgRMnTrB9+3bmz59Pjx49OH78ODVq1ODs2bMoikKVKlWyLeNhq/WfPXuWhISEbNeggP9f3PD8+fMA+d4y7+zZs8TExOS4o0VmPX///TcWFhZZ5qlXq1YtT/VVqVKF1q1bZzn+888/oygKU6dOZerUqTm2pWzZsqSnp7Nw4UIWL17MhQsXzNYocHZ2zlN7csvNzc3s89mzZ4GMJEVOEhISKFasGB9++CH+/v6UL1+eevXq0aFDB/r160elSpXy3I6///4byD7uHh4efPPNN1kWqXyw7TlxcHDg9u3buW7LyZMnee+99zhw4ECWZEBCQkKuy8mJvb19lik9D8ps74NJiwe/5zQaDe7u7sTGxua5HfmJeYUKFcyuy0we3Lp1CwcHB3r16sWKFSsYOHAgkyZNolWrVnTr1o0ePXrkamFU5SHTbTKFhITg7e3N0qVLGTNmzCOvvz+BkdsE1oO0Wi09e/YkIiKCV155hbi4OPz8/LK9NvNnyv3TawBKly6No6OjKe6Z/3+wT0uUKJElKXP27Fl+++23R/48e5jM2MpuGkI8WZKMEEIIIfJIp9PRoEEDGjRoQNWqVenfvz+bN28mODiY9PR0NBoNe/bsyXbxtofNUU9PT6dkyZKEh4dne76gtsNMT0/n5ZdfZt68edmeL1++fIHUk5t2AIwbN462bdtme03mS8sHH3zA1KlTeeutt3j//fdxcnLCwsKC0aNH5/q3zDm9aKSlpWXbVw/Ou8+s56OPPspx29DM/vX19aVp06Zs376dvXv38tFHHzF79my2bdtG+/btc9Xex5GbNQMAqlevzvHjxzEYDOh0uodeGx8fj7e3Nw4ODkybNo3KlStTpEgRjh49ysSJE/P02/6ceHh4cPz4cS5evJjl5T5T5joENWrUeOz6ClJ2X0Pw/y+61tbWfPfdd0RFRbF7926+/vprNm3aRMuWLdm7d2+O9zs5OaHRaHK1K0WzZs1o3rx5npILwcHBNG/e3LQ4aH74+fmxdOlSQkJCqF279iP7piBf+tPT0/Hx8WHChAnZnq9ateojy7h16xY2Nja5/r4RQhQMSUYIIYQQj6F+/fpAxrBugMqVK6MoCm5ubrn6R/D9KleuzL59+/Dy8nroP4ozRyr88ccfWX7DeL+c/sFfuXJlTpw4QatWrR76UlCxYkXS09M5f/682W+Iz5w586hHyZXMUQJarTbbkRP327JlCy1atGDlypVmx+Pj4822FHzY8xQrVoz4+Pgsx//+++9cjVjIjLuDg8Mj2wvg4uLC22+/zdtvv821a9eoW7cuM2bMyHMyomLFikD2cT99+jTFixfPcevOR+nUqRM//vgjW7duzXFofabo6Ghu3LjBtm3baNasmen4hQsX8lV3djp27MiGDRtYu3at2S4emRITE/niiy+oXr16lq/9zJErmRRF4dy5c9SqVct0LLcvwYUVcwsLC1q1akWrVq2YN28eH3zwAVOmTCEqKirHrykrKysqV66c6ziHhISYkgu54e3tTfPmzZk9ezZBQUG5fpb7NWnShAoVKhAdHW1asDM7mT9Tzp49i4eHh+n41atXiY+PN8U98/9nz541+968fv16lqRM5cqVSUpKytX3ZE4uXLhg1h4hxJMha0YIIYQQuRAVFZXtMOnMOdCZL+vdunXD0tKS0NDQLNcrisKNGzdyrMPX15e0tDTef//9LOfu3btnepFu06YN9vb2zJw5k7t372apI5OtrW22Q+d9fX35559/+Oyzz7KcS0lJ4c6dOwCml+ZFixaZXZOb1elzo2TJkqaXpsxkzv2uX79u+rOlpWWWeG7evNm0pkSmzBfE7JIOlStX5qeffjJbjX/Xrl252nIVMrYArFy5MnPmzCEpKSnH9qalpWWJe8mSJSlTpkyW7Qtzw8XFBU9PT9asWWP2XH/88Qd79+6lQ4cOeS4z09ChQ3FxceHdd9/lzz//zHL+2rVrTJ8+Hfj/3/zf3w8Gg4HFixfnu/4H9ejRgxo1ajBr1ix++eUXs3Pp6ekMGzaMW7duERwcnOXetWvXmk052bJlC//++69Z8ien74kHFUbMb968meVY5gibR31dNGrUKEs8cnJ/cuHBnw85yVw7Yvny5bm6/kEajYZFixYRHBzMm2++meN1mXF78GdI5iitzJ16WrdujVar5eOPPzb7esvuZ4+vry8//vgj33zzTZZz8fHx3Lt375HtP3r0aL533RFC5J+MjBBCCCFyYeTIkSQnJ9O1a1eqV6+OwWDghx9+YNOmTbi6utK/f38g44V3+vTpBAYGEhsbS5cuXbC3t+fChQts376dwYMHM27cuGzr8Pb2ZsiQIcycOZPjx4/Tpk0btFotZ8+eZfPmzSxcuJAePXrg4ODA/PnzGThwIA0aNMDPz49ixYpx4sQJkpOTWbNmDZDx8rxp0ybGjh1LgwYNsLOzo1OnTrz55pt8/vnnDB06lKioKLy8vEhLS+P06dN8/vnnfPPNN9SvXx9PT0/69OnD4sWLSUhIoHHjxuzfv59z584VWFw//fRTmjRpwssvv8ygQYOoVKkSV69e5ccff+TSpUucOHECyPiN+bRp0+jfvz+NGzfm999/Jzw8PMuIhsqVK+Po6MjSpUuxt7fH1taWV199FTc3NwYOHMiWLVto164dvr6+nD9/nvXr12dZEyMnFhYWrFixgvbt21OzZk369+9P2bJl+eeff4iKisLBwYEvv/yS27dvU65cOXr06EHt2rWxs7Nj3759HDlyhLlz5+YrTh999BHt27enUaNGDBgwwLTNZNGiRQkJCclXmZAxWmT79u106NABT09P3njjDerVqwdkvKBt2LCBRo0aARlbpBYrVgx/f39GjRqFRqNh3bp1uVrLILd0Oh1btmyhVatWNGnShP79+1O/fn3i4+OJiIjg6NGjvPvuu/Tu3TvLvU5OTqZ7rl69yoIFC3B3d2fQoEGma3L6nshOQcd82rRpfPfdd7z22mtUrFiRa9eusXjxYsqVK0eTJk0eem/nzp1Zt24df/75Z65GXAUHB9OiRYtct83b2xtvb2++/fbbXN+TXRs7d+780Gtq166Nv78/y5cvN037+fnnn1mzZg1dunQxtblEiRKMGzeOmTNn0rFjRzp06MCxY8fYs2eP2UgogPHjx7Nz5046duxIQEAA9erV486dO/z+++9s2bKF2NjYLPfc79dff+XmzZuPbLsQohA88f07hBBCiGfQnj17lLfeekupXr26Ymdnp+h0OsXd3V0ZOXKkcvXq1SzXb926VWnSpIlia2ur2NraKtWrV1eGDx+unDlzxnRNdtsfKoqiLF++XKlXr55ibW2t2NvbKy+//LIyYcIE5fLly2bX7dy5U2ncuLFibW2tODg4KK+88oqyYcMG0/mkpCTFz89PcXR0VACzugwGgzJ79mylZs2ail6vV4oVK6bUq1dPCQ0NVRISEkzXpaSkKKNGjVKcnZ0VW1tbpVOnTkpcXFyetvb86KOPHnrd+fPnlX79+imlS5dWtFqtUrZsWaVjx47Kli1bTNfcvXtXeffddxUXFxfF2tpa8fLyUn788ccs23IqiqJ88cUXSo0aNRQrK6ss2zXOnTtXKVu2rKLX6xUvLy/ll19+yXFrzwe318x07NgxpVu3boqzs7Oi1+uVihUrKr6+vsr+/fsVRVGU1NRUZfz48Urt2rUVe3t7xdbWVqldu7ayePHih8bhUXXv27dP8fLyMvV3p06dlFOnTpldc/9Wj3lx+fJlZcyYMUrVqlWVIkWKKDY2Nkq9evWUGTNmmH09HDp0SGnYsKFibW2tlClTxrTFLfdt16oo+d/aM9O1a9eUsWPHKu7u7oper1ccHR2V1q1bm7bzvF9mzDZs2KAEBgYqJUuWVKytrZXXXntN+fvvv82uzel7IrutPRXl8WKeuU3mhQsXFEVRlP379yudO3dWypQpo+h0OqVMmTJKnz59smxJmZ3U1FSlePHiyvvvv5+ruhUlY1tN4KFbe94vM47kcWvPh3lwa09FydiqNDQ0VHFzc1O0Wq1Svnx5JTAw0GxrWEVRlLS0NCU0NNT0Pd+8eXPljz/+yHaL3tu3byuBgYGKu7u7otPplOLFiyuNGzdW5syZY7b9cnZfgxMnTlQqVKhgtoWoEOLJ0ChKAaazhRBCCCGEeIKio6Np0aIFmzdvpkePHmo3p9C8//77hIWFcfbs2RwXuxR5k5qaiqurK5MmTeKdd95RuzlCvHBkzQghhBBCCCGecmPGjCEpKYmNGzeq3ZTnRlhYGFqtNt/bmgohHo+sGSGEEEIIIcRTzs7OjmvXrqndjOfK0KFDJREhhIpkZIQQQgghhBBCCCGeKFkzQgghhBBCCCGEEE+UjIwQQgghhBBCCCHEEyXJCCGEEEIIIYQQQjxRsoClEMIkPT2dy5cvY29vj0ajUbs5QgghhBBCCJUoisLt27cpU6YMFhYFP45BkhFCCJPLly9Tvnx5tZshhBBCCCGEeErExcVRrly5Ai9XkhFCCBN7e3sALly4gJOTk8qteTEZjUb27t1LmzZt0Gq1ajfnhSR9oC6Jv/qkD9Ql8Vef9IH6pA/UlRn/Ro0a4ebmZnpHKGiSjBBCmGROzbC3t8fBwUHl1ryYjEYjNjY2ODg4yF++KpE+UJfEX33SB+qS+KtP+kB90gfqyox/ZhKisKZvywKWQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQgghhBBCCCGEeKIkGSGEEEIIIYQQQognSpIRQjzDAgIC6NKli9rNEEIIIYQQQog8sVK7AUKI/Fu4cCGKohR4uX///Tfx8fEFXq54tLS0NAAuXLiApaWlyq15MUkfqEvirz7pA3VJ/NUnfaC+F7UPHBwcKFGihNrNeGIkGSFEITEYDOh0ukKto2jRooVS7uDBwaSnF0rR4hF0Oi2Bgf706zcJg8GodnNeSNIH6pL4q0/6QF0Sf/VJH6jvRe0DZ2c9ERFLXpiEhCQjhMil5s2b89JLLwGwbt06tFotw4YNY9q0aWg0GlxdXRkwYABnz55lx44ddOvWjdWrV/P9998TGBjIL7/8QvHixenatSszZ87E1taWyZMns3//fg4fPmxWV+3atenevTtBQUEPbVNAQADx8fHs2LGD5cuXExISwqVLl7Cw+P8ZWJ07d8bZ2ZlVq1bl+ln1+iHo9R55iI4oKDpdGhCDo+MsDIYX5zcBTxPpA3VJ/NUnfaAuib/6pA/U9yL2QUpKHDduzCUxMVGSEUKIrNasWcOAAQP4+eef+eWXXxg8eDAVKlRg0KBBAMyZM4egoCCCg4MBOH/+PO3atWP69OmsWrWK69evM2LECEaMGEFYWBh9+/Zl5syZnD9/nsqVKwNw8uRJfvvtN7Zu3ZqntvXs2ZORI0cSFRVFq1atALh58yZff/01X331Vbb3pKamkpqaavqcmJgIgL19KWxsKuQtOKJAaLVGIIaiRcthNGrVbs4LSfpAXRJ/9UkfqEvirz7pA/W9iH2g06URH68lLS0No1Hd0SCZ9Rd2OzRKYUw4F+I51Lx5c65du8bJkyfRaDQATJo0iZ07d3Lq1ClcXV2pU6cO27dvN90zcOBALC0tWbZsmenY999/j7e3N3fu3KFIkSJ4enrSvXt3pk6dCsDkyZM5cOAAP/300yPbdP/ICIAuXbrg7OzMypUrAVi+fDmhoaHExcWZjZbIFBISQmhoaJbjERER2NjY5D44QgghhBBCiOdKcnIyfn5+JCQk4ODgUODly8gIIfKgYcOGpkQEQKNGjZg7d65pkZ369eubXX/ixAl+++03wsPDTccURSE9PZ0LFy7g4eFB3759WbVqFVOnTkVRFDZs2MDYsWPz1b6+ffsyaNAgFi9ejF6vJzw8nN69e2ebiAAIDAw0qysxMZHy5cuzZo07Njae+WqDeDxarRE/v0giInxemN8EPG2kD9Ql8Vef9IG6JP7qkz5Q34vYB8nJF4iPn8TatbNwc3NTtS1Go5HIyEhatGhRqPVIMkKIAmRra2v2OSkpiSFDhjBq1Kgs11aokDENok+fPkycOJGjR4+SkpJCXFwcvXr1ylf9nTp1QlEUdu/eTYMGDTh48CDz58/P8Xq9Xo9er89y/N49yxfmB//TymjUSh+oTPpAXRJ/9UkfqEvirz7pA/W9SH1gMFhiMBixtLREq306nrmw2yHJCCHy4MGFJn/66SeqVKmS45ZDdevW5dSpU7i7u+dYZrly5fD29iY8PJyUlBR8fHwoWbJkvtpXpEgRunXrRnh4OOfOnaNatWrUrVs3z+WkpFwmPb1wduoQD5exYFNGdvxFWbDpaSN9oC6Jv/qkD9Ql8Vef9IH6XsQ+SEmJU7sJT5wkI4TIxurVqxk9ejTx8fFmxy9evMjYsWMZMmQIkydPZseOHSxevDjHciZOnEjDhg0ZMWIEAwcOxNbWllOnThEZGcknn3xiuq5v374EBwdjMBiyjGTQaDRs376dLl265Krtffv2pWPHjpw8eZI33ngj1898v9TUZaSk5OtW8Zh0Oi3gT3z8i7WV1dNE+kBdEn/1SR+oS+KvPukD9b2ofeDsrC+UtRmeVpKMECIP+vXrR0pKCq+88goGg4HixYszePDgHK+vVasW3377LVOmTKFp06YoikLlypWzTMPo0aMHI0aMwNLSMkvS4d9//6VYsWK5bmPLli1xcnLizJkz+Pn55en5MgUFDcLOzi5f94rHoygKSUlJzJgx3Gx9EvHkvOh9YGdnh7Ozs2r1p6WlERMTw9q1s3IcdSYKl/SBuiT+6pM+UN+L2gcODg4vzLaeIMkIIfJEq9WyYMEClixZQkhICDt27DC9rMTGxmZ7T4MGDdi7d+9Dy3V0dOTu3btmxwwGAzqdjtKlS+d43+rVq7Mcs7Cw4PLlyw9/kEeYNu0z0tMfqwiRTzqdlsBAf6ZM+fSF+k3A0+RF7wNnZz0REUtU+8eQ0WgkJiYGNze3p2bO7ItG+kBdEn/1SR+oT/rgxSDJCPFcun37NkOHDmXHjh04ODgwYcIEvvjiCzw9PVmwYAG3bt3inXfe4csvvyQ1NRVvb28WLVpElSpVcizz4sWL/Pzzz6xcuRJfX988/UM9cwvOOnXq8Mknn5Camoqfnx+LFi1Cp9MBGVuHvvTSS1hZWbF+/XpefvlloqKiskzTuHTpEuPHj+ebb74hNTUVDw8PPv30U1599VUAvvjiC0JDQzl16hRlypTB39+fKVOmYGWV+293vX4Ier1Hrq8XBSdjjmQMjo6zXpg5kk+bF7kPUlLiuHFjLomJiS/Ub2aEEEII8eRJMkI8l8aOHcuhQ4fYuXMnpUqVIigoiKNHj+Lp6QlkJAfOnj3Lzp07cXBwYOLEiXTo0IFTp05lm339/PPPiY2NpWXLlnz66aesW7eORYsWUalSpVy3af/+/RQpUoTo6GhiY2Pp378/zs7OzJgxw3TNmjVrGDZsGIcOHQIwTZXo3bs3VlZWKIpCSkoKGo2GRYsW0bZtW44ePUr6/4YxHDx4kH79+rFo0SKaNm3K+fPnTdNIgoODs7QpNTWV1NRU0+fExEQA7O1LYWNTIdfPJgqOVmsEYihatNwLs3r00+ZF7gOdLo34eC1paWkYjeqMCsmsV636hfSB2iT+6pM+UJ/0gbqeVPw1iqIohVqDEE/Y7du3cXZ2JiIigh49egCQkJBAmTJlGDRoEMOHD6dq1aocOnSIxo0bA3Djxg3Kly/PmjVr6NmzZ5YFLBs3bkydOnX49NNPTfU0bNiQu3fvcvz48Ue2KSAggC+//JK4uDhsbGwAWLp0KePHjychIQELCwuaN29OYmIiR48eNd137tw5qlSpwuLFi/Hx8WHjxo3MmjWL6OhoatasibW1tVk9rVu3plWrVgQGBpqOrV+/ngkTJmQ7dSMkJITQ0NAsxyMiIkztFEIIIYQQQrx4kpOT8fPzIyEhoVAW1pSREeK589dff2E0GnnllVdMx4oWLUq1atUAiImJwcrKyjStAcDZ2Zlq1aoRExOTbZkxMTEMHTrU7FijRo2IiorKdbtq165t9oLfqFEjkpKSiIuLo2LFigDUq1fP7J7MLUFdXFxwd3fn8uXL1KtXj/r162dbx4kTJzh06JDZaIu0tDTu3r1LcnJylgRDYGAgY8eONX1OTEz8X1LGHRsbz1w/myg4Wq0RP79IIiJ8Xrjfyj8tXuQ+SE6+QHz8JNaunYWbm5sqbTAajURGRuLj4yPzhFUifaAuib/6pA/UJ32grsz4t2jRolDrkWSEEE8RW1vbh55/cCTEg5KSkggNDaVbt25ZzhUpUiTLMb1ej16vz3L83j3LF+4l7GljNGqlD1T2IvaBwWCJwWDE0tJS9X/8abVa1dvwopM+UJfEX33SB+qTPlBXYcdekhHiuVOpUiW0Wi1HjhyhQoWMdQ8SEhL4888/adasGR4eHty7d4/Dhw+bTdM4c+YMNWrUyLZMDw8PDh8+TL9+/UzHfvrppzy168SJE6SkpJgSCj/99BN2dnaUL18+12XUqlWLFStWcPPmTZycnLKcr1u3LmfOnDGNqMivlJTLpKcXfawyRP5kLJ6Y8RvqF23xxKfFi9wHKSlxajdBCCGEEC8ISUaI5469vT3+/v6MHz8eJycnSpYsSXBwMBYWFmg0GqpUqULnzp0ZNGgQy5Ytw97enkmTJlG2bFk6d+6cbZnvvPMOAQEB1K9fHy8vL8LDwzl58mSeFrA0GAwMGDCA9957j9jYWIKDgxkxYgQWFha5LqNPnz588MEHdOnShZkzZ+Li4sKxY8coU6YMjRo1IigoiI4dO1KhQgV69OiBhYUFJ06c4I8//mD69Om5ricpaQHx8bK3pxr0eh0wjGvXRpGaalC7Oc8kCwsrtNqsI35yS6fTAv7Ex096Ybf2LIx5oUIIIYQQ95NkhHguzZs3j6FDh9KxY0fT1p5xcXGmqQphYWG88847dOzYEYPBQLNmzfjqq6/QarVoNBpTOff/GeCtt95Cq9Xi5+fHsGHD+Oabb3LdplatWlGlShWaNWtGamoqffr0ISQkJE/PpdPp2Lt3L++++y4dOnTg3r171KhRw7SwZtu2bdm1axfTpk1j9uzZaLVaqlevzsCBA/NUD1j87z/x5Fne93/5EZ0fRYtaMW/eVJydnfN1f1paGjExMaxdOwtLyxdrZASAg4ODbOsphBBCiEIn/9IVzyV7e3vCw8NNn+/cuUNoaKhpm8tixYqxdu3abO/9999/TX/etGkTQUFBnDlzxnTMzs7OtOXm7Nmz89Su0NDQbHevAIiOjs72+IMb3lSsWJEtW7bkWEfbtm1p27Ztntr1IDu7Uej1Ho9VhsifjCkCMZQsOf+FmyJQEFJS4khOnouzszOVK1fOVxlGo5GYmBjc3NxknqoQQgghRCGRZIR4Lh07dozTp0/zyiuvkJCQwLRp0wBynIZxv9KlS5v+XLRoUTQajdmxR4mOjqZFixZ8/fXXTJo0idOnT+Po6Iinpyd79uxh7Nix/PPPP3Ts2JEVK1aYdrhIT09n9uzZLF++nCtXrlC1alWmTp1q2p40LS2NwYMHc+DAAa5cuUKFChV4++23eeedd0x1BwQEEB8fT5MmTZg7dy4Gg4HevXuzYMGCPL1UWVuXwdo6fy9y4vFotUYgBhsbeRHOr9RUtVsghBBCCCEeRZIR4rk1Z84czpw5g06no169ehw8eJDixYsXSl2ZIyUgI2kA0KFDB3Q6HZ988gljxozhyJEjLFiwgIiICJKSkujatSsff/wxEydOBGDmzJmsX7+epUuXUqVKFb777jveeOMNSpQogbe3N+np6ZQrV47Nmzfj7OzMDz/8wODBg3FxccHX19dUf1RUFC4uLkRFRXHu3Dl69eqFp6cngwYNytLu1NRUUu97c0tMTATAyirtfy/F4knLjLvEP390ujR0Oi1paWkYjfmLYeZ9+b1fPB6Jv/qkD9Ql8Vef9IH6pA/U9aTir1EeHAMuhDBZvXo1o0ePJj4+/qHXnTt3zvTnw4cP88Ybb7BmzRoaN25M2bJlWbhwIYGBgZw/f9606OXQoUOJjY3l66+/JjU1FScnJ/bt20ejRo1MZQ0cOJDk5GQiIiKyrXfEiBFcuXLFNG0jICCA6Ohozp8/b5rr7uvri4WFBRs3bsxyf0hISLbTRiIiIkwjNoQQQgghhBAvnuTkZPz8/EhISCiUxa1lZIQQBeD+rTQvXboEQPv27U2LwJUqVQobGxuz3TdKlSrFzz//DGQkM5KTk/Hx8TEr12AwUKdOHdPnTz/9lFWrVnHx4kVSUlIwGAx4enqa3VOzZk2zRfdcXFz4/fffs213YGAgY8eONX1OTEykfPnyrFnjjo2NZ7b3iMKl1Rrx84skIsIHo1GmaeRVcvIF4uMnsXbtLNzc3PJVhtFoJDIyEh8fH5kqowKJv/qkD9Ql8Vef9IH6pA/UlRn/Fi1aFGo9kowQopDc/4NTo9Fk+UGq0WhIT8/YPjMpKQmA3bt3U7ZsWbPr9PqMLQo3btzIuHHjmDt3Lo0aNcLe3p6PPvqIw4cP51jvg/U8SK/Xm8q/3+3bVzEYLubmMUUBy1jAEhISLskClvmQknIZg8GIpaXlY//jRavVyj+AVCTxV5/0gbok/uqTPlCf9IG6Cjv2kowQ4ilQo0YN9Ho9Fy9exNvbO9trDh06ROPGjXn77bdNx86fP18o7UlNXUZKSqEULR5Bp9MC/sTHT8JgkHmS+eHsrC+UoYRCCCGEEKLgSDJCiKeAvb0948aNY8yYMaSnp9OkSRMSEhI4dOgQDg4O+Pv7U6VKFdauXcs333yDm5sb69at48CBA7i4uBR4e4KCBpktyimeHEVRSEpKYsaM4Wg0GrWbozo7OzucnZ3zdI+Dg4NpipQQQgghhHg6STJCCBXduHGDpk2b8scffwBQsmRJgoKC+Pfff3F0dKRu3bpMnjwZgCFDhnDs2DF69eqFRqOhT58+jBw5kqioqAJv17Rpn5HDzA5RyHQ6LYGB/kyZ8qmMjCBjlENExBJJLgghhBBCPGckGSHEQwQEBBAQEJDluMFgQKfTZXtP8+bNeXCTmuzKCQkJ4ezZs3h5edG4cWOKFCnC7Nmz2b59OxcuXMh27YiwsDDCwsJybO/q1auzHFuwYEGO1+dErx+CXu+R5/vE48tYMyIGR8dZL/yaESkpcdy4MZfExERJRgghhBBCPGckGSEEGQmEl156CYB169ah1WoZNmwY06ZNQ6PR4OrqyoABAzh79iw7duygW7durF69mu+//57AwEB++eUXihcvTteuXZk5cya2trZMnjyZ/fv3Z1lgsnbt2nTv3p2goCDCw8PNzq1YsYKtW7eyf/9++vXr98h2u7q6Mnr0aEaPHo2fnx9paWls2rTJdN5oNOLi4sK8efNyVV4ma+syWFtXzvX1ouBotUYgBhsbN1mwCUhNVbsFQgghhBCiMEgyQoj/WbNmDQMGDODnn3/ml19+YfDgwVSoUIFBgwYBMGfOHIKCgjAajXz++ed8/vnnpKSkoNPpsLS05L///mPDhg3cvn2bsLAw+vbty8yZMzl//jyVK2e82J88eZLffvuNrVu3ZtuG5ORkjEYjTk5OeW5/37596dmzJ0lJSab1Hr755huSk5Pp2rVrtvekpqaSet/bXmJiIgBWVmn/eykWT1pm3CX+GaNEdDotaWlpGI1PLh6ZdT3JOsX/k/irT/pAXRJ/9UkfqE/6QF1PKv4a5cHx5EK8gJo3b861a9c4efKkadHASZMmsXPnTk6dOoWrqyt16tRh+/btXLt2jcTERCZPnoyFhQXTp083lRMTE0OXLl24c+cORYoUwdPTk+7duzN16lQAJk+ezIEDB/jpp5+ybcfbb7/NN998w8mTJylSpMgj233/yIh79+6ZRkG8+eabAPj5+ZGens7GjRuzvT8kJITQ0NAsxyMiIrCxsXlk/UIIIYQQQojnU3JyMn5+fiQkJBTKTmUyMkKI/2nYsKHZ7gWNGjVi7ty5pKWlAVC/fn0gY5HJkiVLcuHCBX777Td27dplukdRFNLT07lw4QIeHh707duXVatWMXXqVBRFYcOGDYwdOzbb+mfNmsXGjRuJjo7OVSLiQVZWVvj6+hIeHs6bb77JnTt3+OKLL3JMRAAEBgaatScxMZHy5cuzZo07NjaeeW6DeHxarRE/v0giInwwGl/saRrJyReIj5/E2rWzcHNze2L1Go1GIiMj8fHxkakyKpD4q0/6QF0Sf/VJH6hP+kBdmfFv0aJFodYjyQghcsnW1tbsc1JSEkOGDGHUqFFZrq1QoQIAffr0YeLEiRw9epSUlBTi4uLo1atXluvnzJnDrFmz2LdvH7Vq1cp3G/v27Yu3tzfXrl0jMjISa2tr2rVrl+P1er0evV6f5fjt21cxGC7mux0i/zIWsISEhEuygGXKZQwGI5aWlqr8Q0Sr1co/gFQk8Vef9IG6JP7qkz5Qn/SBugo79pKMEOJ/Hlxo8qeffqJKlSpYWmb/Qli3bl1OnTqFu7t7jmWWK1cOb29vwsPDSUlJwcfHh5IlS5pd8+GHHzJjxgy++eYb0+iL/GrcuDHly5dn06ZN7Nmzh549e+brh0hq6jJSUh6rKSKfdDot4E98/CTZ2pOMrT0LY1igEEIIIYRQlyQjhPifixcvUr58eVq2bEm7du34+OOPmTt3rtk1Go2G7du306VLFyZOnEjDhg0ZMWIEAwcOxNbWlk2bNjF16lRu3bqFo6MjkDFaITg4GIPBwPz5883Kmz17NkFBQURERODq6sqVK1cAsLOzMy1C+TD//fcfK1euZPTo0aZjfn5+LF26lD///JOoqKh8xSIoaFCu6hcFT1EUkpKSmDFjuNm0oeeZnZ0dzs7O2Z5zcHCQbT2FEEIIIZ5DkowQ4n/69evH9u3b2bhxI19++SXvvPMOgwcPNrvm33//pVixYgDUqlWLb7/9lilTptC0aVMURaFUqVJZyu3RowcjRozA0tKSLl26mJ1bsmQJBoOBHj16mB0PDg4mJCTkkW12cnLCz8/P7Fjfvn2ZMWMGFStWxMvLKxdPntW0aZ+Rnp6vW8Vj0um0BAb6M2XKpy/MyAhnZz0REUsk6SCEEEII8QKRZIQQ/6PVaqlatSqenp4sWLDA7FxsbGy29zRo0IC9e/eaPkdHR2dZ6MXR0ZG7d+9me39O5ebWxYtZ13Xw8PDgcTfJ0euHoNd7PFYZIn8y1oyIwdFx1guxZkRKShw3bswlMTFRkhFCCCGEEC8QSUYI8YD09HQmTJjAihUr0Ol0DB061DRK4f5pGrm1detWgoKCOHfuHC4uLowcOZJ33333kfdNnjyZ/fv3Z1nLonbt2nTv3p2goCACAgKIj49nx44dXL9+nZdffplRo0YxefJkAH744QeaN2/Onj17aNWqVZY6UlNTSU1NNX1OTEwEwN6+FDY2FXL9jKLgaLVGIIaiRcu9ELtp6HRpxMdrSUtLe2r2Epe9zdUl8Vef9IG6JP7qkz5Qn/SBup5U/CUZIcQD1qxZw9ixYzl8+DA//vgjAQEBeHl54ePjk+eyfv31V3x9fQkJCaFXr1788MMPvP322zg7OxMQEPDQe6tXr87MmTOxsbHBwsICyEiUpKSkcPbsWYKCgsyuL1GiBKtWraJLly60adOGatWq8eabbzJixIhsExEAM2fOJDQ0NMtxf/9z2NhczvPzioLj5xepdhOeIH9iYmKIiYlRuyFmIiNfpD54+kj81Sd9oC6Jv/qkD9QnfaCu/K4/l1sa5XHHcwvxHGnevDlpaWkcPHjQdOyVV16hZcuWzJo165EjIzKnaWQuYNm3b1+uX79uNpVjwoQJ7N69m5MnTz60LSkpKdStW5e2bdsyYsQIAObOncuPP/7Ili1bcHd3NxsZkWn48OHs27eP+vXr8/vvv3PkyJFst++E7EdGlC9fnrZtf8bGxvMR0RKFQas14ucXSUSEzwsxMiI5+QLx8ZNYu3YWbm5uajcHkL3N1SbxV5/0gbok/uqTPlCf9IG6MuP/6quv4uLiQkJCQqHsbiYjI4R4QK1atcw+u7i4cO3atSzXtW/f3pS0qFixYrbJhZiYGDp37mx2zMvLiwULFpCWlpbjtqEA1tbWvPXWW6xatYoFCxagKApff/01Y8eOfeh2onPmzOGll15i8+bN/PrrrzkmIgD0en225+/ds3whXoSfZkaj9oXoA4PBEoPBiKWl5VP3jw3Z21xdEn/1SR+oS+KvPukD9UkfqKuwYy/JCCEe8OA3nUajIT2brSVWrFhBSkpKtvcUlD59+jBx4kSOHj1KSkoKcXFx9OrV66H3nD9/nsuXL5Oenk5sbCwvv/xynutNSblMenrR/DZbPIaMBSwzRgy8KAtYCiGEEEKIF48kI4TIp7Jlyz7yGg8PDw4dOmR27NChQ1StWtVsVERISAg7duzg+PHjZteWK1cOb29vwsPDSUlJwcfHh5IlS+ZYn6urK0ajkV69elGtWjVef/11wsLCHrk+xYNSU5fxvzyLeMJ0Oi3gT3z8pBdqa8/CGPonhBBCCCGeXpKMEKIQvfvuuzRo0ID333+fXr168eOPP/LJJ5+wePFis+vGjRvHyJEjsy2jb9++BAcHYzAYmD9//kPru3XrFpaWlixatAg7Ozt27NjBpk2b8pyMCAoahJ2dXZ7uEQVDURSSkpKYMWM4Go1G7eYUCjs7O5ydnU2fHRwcZFtPIYQQQogXjCQjxAvDYDCg0+meaJ1169bl888/JygoiPfffx8XFxemTZuWJTlgZ2eX48t/jx49GDFiBJaWlg/dUjQ6OprExERGjhxp+i3zpk2bqF27NkuWLGHYsGG5bve0aZ+RzcwU8QTodFoCA/2ZMuXT53ZkhLOznoiIJZKAEEIIIYR4gUkyQjy3mjdvzksvvYSVlRXr16/n5Zdf5uOPP2b8+PEcPHgQW1tb2rRpw/z58ylevDgABw4cYM6cObi7uxMXF0epUqUYMmQIU6ZMAeDixYu8++67BAQEYGFhQdOmTVm4cCGurq6mehs0aEDZsmXRarXUrFmTiIiIR+6c8eA0jcxdMpo0acLcuXOxtbWld+/eZotNXrt2jRs3brBv3z7c3NyYPn06FStWpFKlSqZr3NzcHrr7R070+iHo9R55ukcUjIw1I2JwdJz1XK4ZkZISx40bc0lMTJRkhBBCCCHEC0ySEeK5tmbNGoYNG8ahQ4eIj4+nZcuWDBw4kPnz55OSksLEiRPx9fXlwIEDAAQGBvLZZ58xf/58mjRpwr///svp06eBjC1u2rZtS6NGjTh48CBWVlZMnz6ddu3a8dtvv2FhYUGXLl0YNGgQGzZswGAw8PPPP+d7qH1UVBQuLi5ERUVx7tw5evXqhaenJ4MGDQIyEhaXL18mKioKrVbLqFGjst3142Gy29oTwN6+FDY2FfLVbvF4tFojEEPRouWey900dLo04uO1pKWlYTQ+nSM/Mtv1tLbveSfxV5/0gbok/uqTPlCf9IG6nlT8NYqiKIVagxAqad68OYmJiRw9ehSA6dOnc/DgQb755hvTNZcuXaJ8+fKcOXMGFxcXSpQowSeffMLAgQOzlLd+/XqmT59OTEyMKcFgMBhwdHRkx44d1K9fH2dnZ6Kjo/H29n5k+w4ePEj79u1N5aSlpWFtbQ1kJAnKli3L+fPnTQtd+vr6YmFhwcaNG/nzzz+pVq0aP//8Mw0aNADg9OnTeHh4MH/+fEaPHg1k7ATysJERISEhhIaGZjkeERGBjY3NI59BCCGEEEII8XxKTk7Gz8+PhISEQllsXEZGiOdavXr1TH8+ceIEUVFR2a7NcP78eeLj40lNTaVVq1bZlnXixAnOnTuHvb292fG7d+9y/vx52rRpQ0BAAG3btsXHx4fWrVvj6+uLi4tLtuXVr1/fNC1j0aJFREZG8uWXXwIwYcIEUlNTzXbccHFx4ffffwcgJiYGKysrs+erXr06jo6Ojw7KfQIDAxk7dqzpc2JiIuXLl2fNGndsbDzzVJYoGFqtET+/SCIifJ7LkRHJyReIj5/E2rWzcHNzU7s52TIajURGRuLj4yN7m6tA4q8+6QN1SfzVJ32gPukDdWXGv0WLFoVajyQjxHPN1tbW9OekpCQ6derE7Nmzs1zn4uLCX3/99dCykpKSqFevHuHh4VnOZc59DwsLY9SoUXz99dds2rSJ9957j8jISBo2bJjlHmtra9zd3QFwcnJCr9ebPjs4OBAfH292vUajIb2AV5XU6/Vm61BkunfP8rl8EX6WGI3a57IPDAZLDAYjlpaWT/0/LrRa7VPfxueZxF990gfqkvirT/pAfdIH6irs2EsyQrww6taty9atW3F1dcXKKuuXfpUqVbC2tmb//v3ZTtOoW7cumzZtomTJkg8dplSnTh3q1KlDYGAgjRo1IiIiIttkxOOoXr069+7d49dffzVN0zhz5kyWBEZ+paRcJj29aIGUJfImYwHLjBEEz+sClkIIIYQQQkgyQqjiUWsZFIbhw4fz2Wef0adPHyZMmICTkxPnzp1j48aNrFixgiJFijBx4kTeeecd3nnnHX777TeuX7/OyZMnGTBgAH379uWjjz6ic+fOTJs2jXLlyvH333+zbds2JkyYgNFoZPny5bz++uuUKVOGM2fOcPbsWfr161fgz1KtWjXatWvHkCFDWLJkCVZWVowePdq05sTjSkpaQHy87O2pBr1eBwzj2rVRpKYa1G7OY7GwsEKrzTryxtlZXyjzDoUQQgghxLNDkhHimZaXpEaZMmU4dOgQEydOpE2bNqSmplKxYkXatWuHhYUFAFOnTuW3335j+/bteHh44OLiwtChQwGwsbHhu+++Y+LEiXTr1o3bt29TtmxZWrVqhYODAykpKZw+fZo1a9Zw48YNXFxcGD58OEOGDCmUZw8LC2PgwIF4e3tTqlQppk+fztSpUwuodIv//SeePMv7/v9s/4guWtSKefOm4uzsbHbcwcFBtvUUQgghhHjBPdv/0hXiIaKjo7Mcq1KlCtu2bcvxHgsLCzp16sT+/fuznfJQunRp1qxZk+29Dg4ObN++PV9tDQkJISQkxPR59erVWa5ZsGBBlrbs2rXL7Nibb75p9jm/m+XY2Y1Cr/fI173i8WRM04ihZMn5z/Q0jZSUOJKT5+Ls7EzlypXVbo4QQgghhHjKSDJC5Nny5csJCQnh0qVLphEFAJ07d8bZ2ZlVq1axZMkS5syZQ1xcHG5ubrz33ntZXpRzw2AwMHbsWLZu3cqtW7coVaoUQ4cOJTAwEFdXVwC6du0KQMWKFYmNjQV4ZP3x8fFMnDiRHTt2kJCQgLu7O7NmzaJjx45Z2nD9+nXat29P+fLl2bhxY7YLPmaKjo6mRYsWfP3110yaNInTp0/TqFEjNm7cyK+//srYsWP5559/6NixIytWrDBtn5mens7s2bNZvnw5V65coWrVqkydOpUePXoAkJaWxuDBgzlw4ABXrlyhQoUKvP3227zzzjumugMCAoiPj6dJkybMnTsXg8FA7969WbBgQZ4Xn7G2LoO1tbxAqkGrNQIx2Ni4PfMLNqWmqt0CIYQQQgjxtJJkhMiznj17MnLkSKKiokzbYN68eZOvv/6ar776iu3bt/POO++wYMECWrduza5du+jfvz/lypXL8/YwixYtYufOnXz++edUqFCBuLg44uIyFsA7cuQIJUuWJCwsjHbt2pm2wXxU/enp6bRv357bt2+zfv16KleuzKlTp8y20cwUFxeHj48PDRs2ZOXKldlek52QkBA++eQTbGxs8PX1xc3NjdTUVNPL5YYNG9iyZQs6nY5ly5YRGxvL+vXrWbp0KVWqVOG7777jjTfeoESJEnh7e5Oenk65cuXYvHkzzs7O/PDDDwwePBgXFxd8fX1N9UZFReHi4kJUVBTnzp2jV69eeHp6MmjQoGzbmZqaSup9b4yJiYkAWFml/e+lWDxpmXF/1uOv06Wh02lJS0vDaHy2niWzvc9au58XEn/1SR+oS+KvPukD9UkfqOtJxV+j5Hcct3ihdenSBWdnZ1auXAlkjJYIDQ0lLi6Opk2bUrNmTZYvX2663tfXlzt37rB7924g92s9jBo1ipMnT7Jv3z40Gk2W89mV4+Xl9dD69+7dS/v27YmJiaFq1apZyly9ejWjR4/m8OHD+Pj40LVrVxYsWJBt/Q/KHBmxb98+U6Jm1qxZBAYGsn//fipUqABkrE3xzz//sGrVKhwdHalYsSL79u2jUaNGprIGDhxIcnIyERER2dY1YsQIrly5wpYtW4CMkRHR0dGcP3/elDTx9fXFwsKCjRs3ZltGSEgIoaGhWY5HRESYRm0IIYQQQgghXjzJycn4+fmRkJBQKIuPy8gIkS99+/Zl0KBBLF68GL1eT3h4OL1798bCwoKYmBgGDx5sdr2XlxcLFy7Mcz0BAQH4+PiYdo/o2LEjbdq0eeg9j6r/+PHjlCtXLttERKaUlBSaNm2Kn59flrUacqNWrVqmP5cqVQobGxtatmxpOla1alXOnDmDu7s7J0+eJDk5GR8fH7MyDAYDderUMX3+9NNPWbVqFRcvXiQlJQWDwYCnp6fZPTVr1jQbveHi4sLvv/+eYzsDAwMZO3as6XNiYiLly5dnzRp3bGw8c7xPFB6t1oifXyQRET4Yjc/uNI3k5AvEx09i7dpZuLm5qd2cPDEajURGRuLj4/PMT5V5Fkn81Sd9oC6Jv/qkD9QnfaCuzPjndVR7XkkyQuRLp06dUBSF3bt306BBAw4ePMj8+fMLvJ66dety4cIF9uzZw759+/D19aV169am0QD5kZvtL/V6vWmKx/jx4ylbtmye6rj/h6ZGo8nyQ1Sj0ZCenrF1ZlJSEgC7d+/OUk/m+hQbN25k3LhxzJ07l0aNGmFvb89HH33E4cOHc6z3wXpyes7s1sC4ffsqBsPFRz2mKAQZC1hCQsKlZ3wBy8sYDEYsLS2f2X9EaLXaZ7btzwOJv/qkD9Ql8Vef9IH6pA/UVdixl2SEyJciRYrQrVs3wsPDOXfuHNWqVaNu3boAeHh4cOjQIfz9/U3XHzp0iBo1auSrLgcHB3r16kWvXr3o0aMH7dq14+bNmzg5OaHVZsxJv9+j6q9VqxaXLl3izz//zHF0hIWFBevWrcPPz48WLVoQHR1NmTJl8tX+R6lRowZ6vZ6LFy/i7e2d7TWHDh2icePGvP3226Zj58+fL5T2AKSmLiMlpdCKFw+h02kBf+LjJ2EwPNvzJJ2d9YUypE8IIYQQQjz7JBkh8q1v37507NiRkydP8sYbb5iOjx8/Hl9fX+rUqUPr1q358ssv2bZtG/v27ctzHfPmzcPFxYU6depgYWHB5s2bKV26NI6OjgC4urqyf/9+vLy80Ov1FCtW7JH1e3t706xZM7p37868efNwd3fn9OnTaDQa2rVrZ6rb0tKS8PBw+vTpQ8uWLYmOjqZ06dKPF7Rs2NvbM27cOMaMGUN6ejpNmjQhISGBQ4cO4eDggL+/P1WqVGHt2rV88803uLm5sW7dOo4cOVJow9+DggZhZ2dXKGWLh1MUhaSkJGbMGJ6rdUqeZi4uLpQoUULtZgghhBBCiKeQJCNEvrVs2RInJyfOnDmDn5+f6XiXLl1YuHAhc+bM4Z133sHNzY2wsDCaN2+e5zrs7e358MMPOXv2LJaWljRo0ICvvvrKtKXo3LlzGTt2LJ999hlly5YlNjY2V/Vv3bqVcePG0adPH+7cuWPa2vNBVlZWbNiwgcqVK+Pi4pLl/NmzZ5k+fTpr1qwxO16sWDHOnj2Lu7t7rp7z/fffp0SJEsycOZO//voLR0dH6taty+TJkwEYMmQIx44do1evXmg0GurUqWO2C0ZBmzbtMx4yu0MUIp1OS2CgP1OmfPpcjIyIiFgiCQkhhBBCCJGF7KYhRC4EBARw9epVwsLCzI6XKFGCAQMG5Hgut1uBZjIYDOh0ukdel7njR3x8fJ7Kf5TExESKFi1K48Zfotd7FGjZInd0ujSGDYthyRKPZ3zNiDhSU+eyefMCKleurHZz8sRoNPLVV1/RoUMHmaeqAom/+qQP1CXxV5/0gfqkD9SVGf8mTZpQvHhx2U1DCLXp9focp2k87NzDNG/enJdeegkrKyvWr1/Pyy+/TFRUFPPmzSMsLIy//voLJycnOnXqxIcffoidnR3R0dH0798fwDSMPzg4mJCQEFJTU5kyZQobNmwgPj6el156idmzZ+d5VIq1dRmsrZ+tF8jnhVZrBGKwsXF75v/yLcTBO0IIIYQQ4hknyQihqg8++IAPPvgg23NNmzZlz549T7hFDzd06FDWr19vdiw1NRVFURg6dChLly7Nc5lr1qxh2LBhHDp0yHTMwsKCRYsW4ebmxl9//cXbb7/NhAkTWLx4MY0bN2bBggUEBQVx5swZANP6DiNGjODUqVNs3LiRMmXKsH37dtq1a8fvv/9OlSpVstSdmppqNt0jMTERACurtP+9FIsnLTPuz3r8dbo0dLqMBWaNxmfrWTLb+6y1+3kh8Vef9IG6JP7qkz5Qn/SBup5U/GWahlDVzZs3uXnzZrbnrK2t87ylZmEJCAhg/fr1ZttgNmvWjI8//pgJEyawc+dO9Hq9aaRC+/bt2bx58yPLbd68OYmJiRw9evSh123ZsoWhQ4fy33//AdlP07h48SKVKlXi4sWLZjt/tG7dmldeeSXbpE9ISAihoaFZjkdERGBjY/PI9gshhBBCCCGeT8nJyfj5+ck0DfF8cnJywsnJSe1m5EqLFi1YsmSJ6bOtrS0uLi44ODhkey636tWrl+XYvn37mDlzJqdPnyYxMZF79+5x9+5dkpOTc0wS/P7776SlpWXZrjQ1NRVnZ+ds7wkMDGTs2LGmz4mJiZQvX541a9yxsfHM9TOIgqPVGvHziyQiwgej8dmdppGcfIH4+EmsXTur0HZ9KSxGo5HIyEh8fHye+akyzyKJv/qkD9Ql8Vef9IH6pA/UlRn/Fi1aFGo9kowQIpdsbW1z3B3jYedyU+79YmNj6dixI8OGDWPGjBk4OTnx/fffM2DAAAwGQ47JiKSkJCwtLfn111+zLJyZ0zader3ebLRHptu3r2IwXMzX84jHo9OlAZCQcOkZX8DyMgaDEUtLy2f2HxFarfaZbfvzQOKvPukDdUn81Sd9oD7pA3UVduwlGSHEU+bXX38lPT2duXPnmrYw/fzzz82u0el0pKWlmR2rU6cOaWlpXLt2jaZNmz5WG1JTl5GS8lhFiHzS6bSAP/Hxk56LrT0LY0ifEEIIIYR49kkyQoinjLu7O0ajkY8//phOnTpx6NChLAtjurq6kpSURHh4OG+88QY//PADjRo1om/fvvTr14+5c+dSp04drl+/zv79+6lVqxavvfZartsQFDQox9EUonApikJSUhIzZgw3rUHypNnZ2eU4tScvHBwcKFGiRAG0SAghhBBCPG8kGSGeS1euXGHGjBns3r2bf/75h5IlS+Lp6cno0aNp1aoVrq6ujB49mtGjR2d7f1xcHMHBwXz99df8999/6HQ6SpUqxY0bN8xe0i5cuMB3333H5cuXKVKkCMWLF6devXrMnj2b6tWrA+T4Qrlhw4Zsj9euXZt58+Yxe/ZsAgMDadasGTNnzqRfv36maxo3bszQoUMZNWoUAHv27KFRo0aEhYUxffp03n33Xf755x+KFy9Ow4YN6dixY57iN23aZ6Sn5+kWUUB0Oi2Bgf5MmfKpaiMjnJ31REQskUSCEEIIIYQoNJKMEM+d2NhYvLy8cHR05KOPPuLll1/GaDTyzTffMHz4cE6fPv3Q+//66y8aNWpE1apV2bBhA25ubpw8eZLx48fTqFEjfvrpJ5ycnDAajfj4+ODh4UFERAQuLi5cunSJPXv2mO1yARAWFka7du3Mjjk6OtK7d+9s2zBmzBjGjBljduzNN980+7xkyRKzRTMhY15XaGhotjtk5IVePwS93uOxyhD5k7FmRAyOjrNUWTMiJSWOGzfmkpiYKMkIIYQQQghRaCQZIZ47b7/9NhqNhp9//tlscciaNWvy1ltvPfL+4cOHo9Pp2Lt3L9bW1gBUqFCBOnXqULlyZaZMmcKSJUs4efIk58+fZ//+/VSsWBGAihUr4uXllaVMR0dHSpcunafnSExMpFSpUmzbto327dubjm/fvp1+/fpx9epVrl27hpubG8eOHcPT05Np06axdOlSfv/9d9MIjtdee43k5GT2799vWoPiUayty2BtXTlP7RUFQ6s1AjHY2LiptmBTaqoq1QohhBBCiBeIJCPEc+XmzZt8/fXXzJgxI9vtNR0dHR95/zfffMOMGTNMiYhMpUuXpm/fvmzatInFixdTokQJLCws2LJlC6NHj86yg8XFixepUaMGAL1798bKyvzb7dSpU1SoUCHHtjg4ONCxY0ciIiLMkhHh4eF06dIl2101pkyZwtdff83AgQPZvn07n376KT/88AMnTpzINhGRmppK6n1vnomJiQBYWaX976VYPGmZcVcr/jpdGjqdlrS0NIzGF/NrIPO5X9TnV5vEX33SB+qS+KtP+kB90gfqelLxl2SEeK6cO3cORVFM6zXk1dmzZ1EUBQ+P7KcoeHh4cOvWLa5fv07ZsmVZtGgREyZMIDQ0lPr169OiRQv69u1LpUqVKFOmDMePH6dKlSpAxsKE97t3794j29O3b1/efPNNkpOTsbGxITExkd27d7N9+/Zsr7e0tGT9+vV4enoyadIkFi1axIoVK3JMesycOTPbKR3+/uewsbn8yPaJwuPnF6li7f7ExMQQExOjYhvUFxmpZh8Iib/6pA/UJfFXn/SB+qQP1BUVFVWo5UsyQjxXHnzhL+xyhg8fTr9+/YiOjuann35i8+bNfPDBB+zcuRMfHx/c3d0BWLBgAa1btza792GjIjJ16NABrVbLzp076d27N1u3bsXBwSFLWferVKkSc+bMYciQIfTq1Qs/P78crw0MDGTs2LGmz4mJiZQvX541a9yxsfF8ZPtEwdNqjfj5RRIR4YPR+OSnaSQnXyA+fhJr187Czc3tidf/NDAajURGRuLj4yN7m6tA4q8+6QN1SfzVJ32gPukDdWXGv0WLFoVajyQjxHOlSpUqaDSaRy5SmRN3d3c0Gg0xMTF07do1y/mYmBiKFStmtrCfvb09nTp1olOnTkyfPp22bdsyffp0fHx8TNeULl3alJjIC51OR48ePYiIiKB3795ERETQq1evLFM+HvTdd99haWlJbGws9+7dy/F6vV6PXq/Pcvz27asYDBfz3F7x+DIWsISEhEsqLWB5GYPBiKWl5Qv/l79Wq33hY6Amib/6pA/UJfFXn/SB+qQP1FXYsZdkhHiuODk50bZtWz799FNGjRqVZd2I+Pj4h64b4ezsjI+PD4sXL2bMmDFm60ZcuXKF8PBw+vXrl+N2nRqNhurVq/PDDz8UyPNAxlQNHx8fTp48yYEDB5g+ffpDr9+0aRPbtm0jOjoaX19f3n///TzvrpGauoyUlMdptcgvnU4L+BMfP0nVrT0dHBxUqVsIIYQQQrwYJBkhnjuffvopXl5evPLKK0ybNo1atWpx7949IiMjWbJkiWke/D///MPx48fN7q1YsSKffPIJjRs3No1wuH9rz7JlyzJjxgwAjh8/TnBwMG+++SY1atTgvffe48KFC5w9e5aJEyealRsfH8+VK1fMjtnb22e7yOaDmjVrZlo8083NjVdffTXHay9dusSwYcOYPXs2TZo0IS0tjenTp9O+fXsaNmyYm/ABEBQ0CDs7u1xfLwqOoigkJSUxY8bwHJNeBcnOzs6080omBwcH2dZTCCGEEEIUKklGiOdOpUqVOHr0KDNmzODdd9/l33//pUSJEtSrV48lS5aYrpszZw5z5swxu3fdunW88cYb/PLLLwQHB+Pr68vNmzcpXbo0Xbp0ITg4GCcnJwDKlSuHq6sroaGhxMbGAhnrQISGhjJmzBizcvv375+lnTNnzmTSpEmPfB6NRkOfPn348MMPCQoKYvXq1YwePZr4+Hiz6xRFISAggFdeeYURI0YAYG1tjZeXF2+88QbHjx/PdYJh2rTPSE/P1aWigOl0WgID/Zky5dMnMjLC2VlPRMQSST4IIYQQQognSpIR4rnk4uLCJ598wieffAKAwWBAp9OZzmcmD3JSsWJFVq9e/dBrihcvzsKFCx/ZloJYVHP27NnMnj0bwKxdrq6uZuXv27cvy73dunVj9OjReapPrx+CXp/9jiKicGWsGRGDo+OsQl8zIiUljhs35pKYmCjJCCGEEEII8URJMkI8k5o3b85LL70EZIxm0Gq1DBs2jGnTpqHRaHB1dWXAgAGcPXuWHTt20K1bN1avXs33339PYGAgv/zyC8WLF6dr167MnDkTW1tbJk+ezP79+zl8+LBZXbVr16Z79+4EBQU9tE0BAQHEx8ezY8cOli9fTkhICJcuXcLCwsJ0TefOnXF2dmbVqlUPLevEiROMHj2aX375BY1GQ5UqVVi2bBlJSUmmURaZQ/iDg4MJCQnh2rVrDBgwgH379lG6dOlHri0BkJqaSmpqqulzYmIiAPb2pbCxefRuH6LgabVGIIaiRcsV+m4aOl0a8fFa0tLSZB/v+8je5uqS+KtP+kBdEn/1SR+oT/pAXU8q/hqloPZCFOIJat68Ob/++isDBgxg2LBh/PLLLwwePJgFCxYwaNAgXF1duXXrFkFBQXTp0sV0X+3atZk+fTqvvfYa169fZ8SIEdSuXZuwsDBOnjzJSy+9xLlz56hcuTKA6djZs2cfuRvG/cmIW7duUbp0ab766itatWoFwM2bN3FxcTE71r59ew4ePJilrOTkZGrXrs2GDRuwtLTk+PHjVK1aFQ8PD5YsWUJQUBBnzpwBMub829nZ0aFDBy5fvszSpUvRarWMGjWKY8eO8cEHH+Q4MiIkJCTbxS0jIiKwsbF5ZD8IIYQQQgghnk/Jycn4+fmRkJBQKIubSzJCPJOaN2/OtWvXOHnypGmEwKRJk9i5cyenTp3C1dWVOnXqsH37dtM9AwcOxNLSkmXLlpmOff/993h7e3Pnzh2KFCmCp6cn3bt3Z+rUqQBMnjyZAwcO8NNPPz2yTfcnIwC6dOmCs7MzK1euBGD58uWEhoYSFxdnGi3xzz//kJLNthWenp7Mnj2b4cOHZzmX3ZoRf/75J9WqVePnn3+mQYMGAJw+fRoPDw/mz5+fYzIiu5ER5cuXp23bn7Gx8XzkM4uCp9Ua8fOLJCLCp9BHRiQnXyA+fhJr187Czc2tUOt6lsje5uqS+KtP+kBdEn/1SR+oT/pAXZnxf/XVV3FxcSm0ZIRM0xDPrIYNG5rtNtCoUSPmzp1LWloaAPXr1ze7/sSJE/z222+Eh4ebjimKQnp6OhcuXMDDw4O+ffuyatUqpk6diqIobNiwgbFjx+arfX379mXQoEEsXrwYvV5PeHg4vXv3Npu2UbZs2WzvHTduHKNHj2b79u20bt2anj17mkZrZCcmJgYrKyvq1atnOla9evWHbmMKoNfr0ev1WY7fu2dZ6C/C4uGMRm2h94HBYInBYMTS0lL+os+G7G2uLom/+qQP1CXxV5/0gfqkD9RV2LGXZIR4bj24bWZSUhJDhgxh1KhRWa6tUCFjfYQ+ffowceJEjh49SkpKCnFxcfTq1Stf9Xfq1AlFUdi9ezcNGjTg4MGDzJ8/P1f3hoSE4Ofnx+7du9mzZw/BwcFs3LiRrl275qsteZWScpn09KJPpC5hLmMBy4xRC09iAUshhBBCCCHUIMkI8cx6cKHJn376iSpVqmBpmf0LXN26dTl16tRD134oV64c3t7ehIeHk5KSgo+PDyVLlsxX+4oUKUK3bt0IDw/n3LlzVKtWjbp16+b6/qpVq1K1alXGjBlDnz59CAsLo2vXruh0OtPoj0zVq1fn3r17/Prrr6ZpGmfOnCE+Pp5vv/02z7tppKYuI5vZI+IJ0Om0gD/x8ZOe2NaehTHsTgghhBBCiIeRZIR4Zl28eJGxY8cyZMgQjh49yscff8zcuXNzvH7ixIk0bNiQESNGMHDgQGxtbTl16hSRkZGmLUAhY3pFcHAwd+7cITExkddee43du3eblbV9+3Zmz55NTEwM6enpVKhQAUVRqFq1KvD/6zps2bKFjh07cvLkSdq0aUP58uVp2LAh4eHhZluN3i8lJYXx48fTo0cP3NzcuHTpEkeOHKF79+5AxqKaSUlJ7N+/n9q1a2NjY0O1atVo164dQ4YMYcmSJVhZWTF69GizaSx5ERQ0CDs7u3zdKx6PoigkJSUxY8bwfPdfTuzs7HB2djY75uDgINt6CiGEEEKIJ06SEeKZ1a9fP1JSUnjllVewtLTknXfeYfDgwTleX6tWLb799lumTJlC06ZNURSFypUrZ5mG0aNHD0aMGMG9e/cYNmwYa9eu5fLly5QpUwaA/fv306tXL2bMmMHrr7+ORqPh1KlTTJo0KUudLVu2xMnJiTNnznDt2jW6d+/OsmXLzNaNeJClpSU3btygX79+XL16leLFi9OtWzfTrhdVqlRBp9PRq1cvbty4YdraMywsjIEDB+Lt7U2pUqWYPn06P/74Y35Cy7Rpn5Genq9bxWPS6bQEBvozZcqnBT4ywtlZT0TEEkk+CCGEEEII1UkyQjyztFotCxYsYMmSJVnOxcbGZntPgwYN2Lt370PLdXR05L///sPFxYVRo0Zx48YNVq9ezeTJkwH48ssv8fLyYvz48aZ7qlataraFaCYLCwvWr19P586dGTRoELNnz37kc+l0OiZNmsTo0aO5desWt2/f5ocffuCPP/4gKSmJ/v37A3Djxo0sdWk0GjQaDRYWFlhYWJimneSVXj8Evd4jz/eJx5exZkQMjo6zCnTNiJSUOG7cmEtiYqIkI4QQQgghhOokGSFENj7//HOqV69OtWrVeOONNxg9ejSBgYFoNBpKly5NREQEf/zxBy+99NJDy9m+fTt+fn6EhIQwceLEXNfft29f6tSpw5IlS7C0tOT48eNotVoaN27MggULCAoK4syZMwCm6RQBAQFcvnyZqKgotFoto0aN4tq1aw+tJ7utPQHs7UthY1Mh1+0VBUerNQIxFC1arkB309Dp0oiP15KWlobRWPhrUTzLMuMjcVKHxF990gfqkvirT/pAfdIH6npS8ZdkhBDZWLlyJW+88QYA7dq1IyEhARsbGywtLVEUhdTUVF5++WXTKIRx48YRGhpqtk1mUlISPXv2ZPLkyVkSETVr1uTvv//Otu5ly5Zx8eJFxo8fT/Xq1YGMqRmZihYtakqKZPrzzz/Zs2cPP//8s2kBy5UrV+Lh8fDRDTNnzjRN/7ifv/85bGwuP/ReUbj8/CILoVR/YmJiiImJKYSynz+RkYXRByK3JP7qkz5Ql8RffdIH6pM+UFdUVFShli/JCPFMio6OLrSyz5w5w88//8z27dsBsLKyolevXly6dIk5c+aYrvv77785fPgwx48fZ9myZezZs4cff/wRGxsbAKytrWnSpAmfffYZffr0MUsMfPXVVzlmGkuVKsXZs2cZOHAg69ato3Xr1vTs2ZPKlSvn2OaYmBisrKyoV6+e6Vj16tVxdHR86LMGBgYyduxY0+fExETKly/PmjXu2Nh4PvReUTi0WiN+fpFERPgU6MiI5OQLxMdPYu3aWbi5uRVYuc8jo9FIZGQkPj4+sre5CiT+6pM+UJfEX33SB+qTPlBXZvxbtGhRqPVIMkKIB6xcuZJ79+6ZFqyEjB0O9Ho9JUqUoGjRogC4u7vTqlUrAC5cuEDVqlXZtGmTaU0HS0tLduzYQbdu3WjRogVRUVGmhETFihUf2oaQkBD8/PzYvXs3e/bsITg4mI0bN9K1a9cCfVa9Xm82miPTvXuWBfoiLPLOaNQWaB8YDJYYDEYsLS3lL/Vc0mq1EisVSfzVJ32gLom/+qQP1Cd9oK7Cjr0kI4S4z71791i7di1z586lTZs2Zue6dOnChg0bGDp0aJb7XF1dsbGx4c6dO2bH9Xo927Zto0ePHrRo0YIDBw5Qo0aNXLWlatWqVK1alTFjxtCnTx/CwsLo2rUrOp2OtLQ0s2urV6/OvXv3+PXXX03TNM6cOUN8fHwenv7/paRcJj29aL7uFY8nYwHLjJEMBb2ApRBCCCGEEE8LSUYIcZ9du3Zx69YtBgwYYBoBkal79+6sXLmSK1eukJycTIcOHahYsSLx8fEsWrQIo9GIj49PljL1ej1bt26lZ8+epoREzZo1c2xDSkoK48ePp0ePHri5uXHp0iWOHDlC9+7dgYzER1JSEvv376d27drY2NhQrVo12rVrx5AhQ1iyZAlWVlaMHj0aCwsLtm/fzujRo/MUh6SkBcTHy96eatDrdcAwrl0bRWqqoUDKtLCwQqvV4+ysx8HBoUDKFEIIIYQQ4nFIMkKI+6xcuZLWrVubEhEBAQGsWbPG7JqkpCTKlSvHxo0buXr1KgaDgTp16rB3716qVauGRqMxXWtra0uZMmXw8vJi8uTJzJo1y5SQyGknDktLS27cuEG/fv24evUqxYsXp1u3bqaFJg2GjBfUnj17cuvWLYKDgwkJCSEsLIyBAwfi7e1NqVKlmD59OkeOHMlnJCz+95948izv+3/B/IguWtSKefOm4ubmJtt6CiGEEEKIp4IkI4S4z5dffpnlWLt27QgLCwPgypUrvPfee/z2229cvHgRAI1GQ1BQEE2aNDHdExYWRrt27bh79y5//vkny5cvx8vLi1WrVpkWxsyJTqdjw4YNj2zrX3/9ZbZAZenSpdm1a5fZNStXrsTT0/ORZT3Izm4Uev3Dd+IQhSNjmkYMJUvOL5BpGikpcSQnz8XZ2VkSEUIIIYQQ4qkhyQghHkGv15u20SxdujSTJk2iadOmXL9+PceXO0dHR9M9rq6utGnTBn9/f0aMGEGnTp0oVqzYQ+v8+++/GTFiBN9//z0GgwFXV1c++ugjatSoYVrVNrMMf39/Vq9ezZ07dxg2bBjbtm3D3t6ecePG5fuZra3LYG2d8+4dovBotUYgBhsbtwJbNCg1tUCKEUIIIYQQosBIMkKIPEhKSmL9+vW4u7vj7Oycp3vHjBnD2rVriYyMJDQ0lL///jvb65YtW8aGDRswGAx899132NracurUKezs7Chfvjxbt26le/funDlzBgcHB6ytrQEYP3483377LV988QUlS5Zk8uTJHD169KEjI1JTU0m97001MTERACurtP+9FIsnLTPuBRV/nS4NnU5LWlpajtvJCnOZcZJ4qUPirz7pA3VJ/NUnfaA+6QN1Pan4SzJCiEfYtWsXdnZ2ANy5cwcXFxd27dqFhUXe1lSoXr06ALGxsXz11Vc5fnOXKlWK2bNn0717d15++WUAKlWqZDrv5OQEQMmSJU3TNJKSkli5ciXr1683bTe6Zs0aypUr99A2zZw507QWxf38/c9hY3M5T88nCpafX2QBluZPTEwMMTExBVjm8y8ysiD7QOSVxF990gfqkvirT/pAfdIH6oqKiirU8iUZIcQjtGjRgiVLlgBw69YtFi9eTPv27fn555+pWLFirstRFAXIWGPiUfeNGjWKYcOGsXfvXlq3bk337t2pVatWjtefP38eg8HAq6++ajrm5OREtWrVHlpPYGAgY8eONX1OTEykfPnyrFnjjo2NZy6eShQ0rdaIn18kERE+GI2PP00jOfkC8fGTWLt2Fm5ubgXQwuef0WgkMjISHx8f2dtcBRJ/9UkfqEvirz7pA/VJH6grM/6Z08MLiyQjhHgEW1tb3N3dTZ9XrFhB0aJF+eyzz5g+fXquy8n8rXRuXggHDhxI27Zt2b17N3v37mXmzJnMnTuXkSNH5v0BHkKv16PX67Mcv337KgbDxQKtS+ROxgKWkJBwqYAWsLyMwWDE0tJS/jLPI61WKzFTkcRffdIH6pL4q0/6QH3SB+oq7NhLMkKIPNJoNFhYWJCSkpKn+xYsWICDgwOtW7fO1fXly5dn6NChDB06lMDAQD777DNGjhyJTqcDIC0tzXRt5cqV0Wq1HD58mAoVKgAZozj+/PNPvL2989ROgNTUZeTx8UQB0em0gD/x8ZMwGApmnp6zsx4HB4cCKUsIIYQQQoiCIMkIIR4hNTWVK1euABkv+J988glJSUl06tQpx3vi4+O5cuUKqamp/PnnnwwaNIi///6b8PBws+04czJ69Gjat29P1apVuXXrFlFRUXh4ZGy1WbFiRTQaDbt27aJDhw5YW1tjZ2fHgAEDGD9+PM7OzpQsWZIpU6ZgYWHBTz/9hKenJ8ePH8/1MwcFDTKtkyGeLEVRSEpKYsaM4Wg0mscuz87ODjc3N9nWUwghhBBCPFUkGSEEGQs5btu2jdOnT2NtbU3jxo2ZPXs2AF9//TUuLi4A2NvbU716dTZv3kzz5s3x9fUFzEcpAPTv3x+AIkWKULZsWaysrPD29sbPzy9X7UlLS2P48OFcunQJBwcH2rVrx/z58wEoW7YsoaGhTJo0if79+9OvXz9Wr17NRx99ZEqS2Nvb8+6775KQkMDdu3fzHI9p0z4jPT3Pt4kCoNNpCQz0Z8qUTwtkZISzs56IiCUF0DIhhBBCCCEKjiQjhAC+/fZbhg8fToMGDbh37x6TJ0+mTZs2nDp1itWrV7Nz50569uzJoUOHTDtcbN68mV27dnH69GmzhSIzF6q8X0BAAPHx8bluz8cff/zQ81OnTmXq1Klmx+zs7Fi3bh3r1q0zHRs/fjwhISHs2LEj13UD6PVD0Os98nSPKBgZa0bE4Og467HXjEhJiePGjbkkJibKyAghhBBCCPFUkWSEEGSMfrjf6tWrKVmyJL/++ivNmjXj9ddfx8/PD39/fw4fPkx8fDzDhw9n1qxZj9yx4n6hoaF88sknpKam4ufnx6JFi0xrQKSmpjJ+/Hg2btxIYmIi9evXZ/78+TRo0ACA6OhoWrRowb59+5g4cSKnTp3C09OTsLAwszbMmjWL+fPnk5ycjK+vb75eQq2ty2BtXTnP94nHp9UagRhsbNwKZNGg1NTHb5MQQgghhBAFTZIRQmQjISEByNgeM9PChQt5+eWXef/994mJieGll17K0+4W+/fvp0iRIkRHR9OvXz+WLVvGqlWrzJIRaWlpvPnmm0ycOJEPP/yQtm3bcu7cObN2TJkyhblz51KiRAmGDh3KW2+9xaFDhwD4/PPPCQkJ4dNPP6VJkyasW7eORYsWUalSpWzblJqaSup9b6uJiYkAWFml/e+lWDxpmXEviPjrdGnodFrS0tIwGqU/cyszVhIzdUj81Sd9oC6Jv/qkD9QnfaCuJxV/jZLdmHIhXmDp6em8/vrrxMfH8/3335udO3DgAG3atMHW1pbffvuNihUr5qrMgIAAvvzyS+Li4rCxseGff/5h5cqVfPjhhxw9epS7d+9Sv359Zs2aRUBAAE5OThiNRlxdXRk9ejTjx483GxnRqlUrAL766itee+01UlJSKFKkCI0bN6ZOnTp8+umnprobNmzI3bt3s13AMiQkhNDQ0CzHIyIisLGxyUPUhBBCCCGEEM+T5ORk/Pz8SEhIKJSd2WRkhBAPGD58OH/88UeWRARAy5YtadiwIZ6enrlORGSqXbu26QW/bNmydO7cmeDgYPR6PXfv3sVoNNK9e3fTKAitVssrr7xCTEyMWTm1atUy/TlzYc1r165RoUIFYmJiGDp0qNn1jRo1IioqKts2BQYGMnbsWNPnxMREypcvz5o17tjYeObp+UTB0GqN+PlFEhHhg9H4eNM0kpMvEB8/ibVrZ+Hm5lZALXz+GY1GIiMj8fHxkb3NVSDxV5/0gbok/uqTPlCf9IG6MuPfokWLQq1HkhFC3GfEiBHs2rWL7777jnLlymV7jZWVFVZW6n3r3P8DOXPrx/R8bn2h1+vR6/VZjt++fRWD4WL+GigeS8YClpCQcKkAFrC8jMFgxNLSUv4izwetVitxU5HEX33SB+qS+KtP+kB90gfqKuzYSzJCCDJ2wBg5ciTbt28nOjq6UH6LfOLECVJSUrC2tgbgp59+ws7OjvLly1O8eHF0Oh2HDh0yjbgwGo0cOXKE0aNH57oODw8PDh8+TL9+/UzHfvrppzy3NTV1GSkpeb5NFACdTgv4Ex8/qcC29iyMYXVCCCGEEEI8DklGiCyaN2+Op6cnCxYsyPa8RqNh+/btdOnSJdvzmWsb3Lp1C0dHx0JrZ0EaPnw4ERERfPHFF8THx6PRaIiMjMTLy8uUPHhcBoOBAQMG8N577xEbG0twcDAjRozAwsICW1tbhg0bxvjx43FycqJChQp8+OGHJCcnM2DAgFzX8c477xAQEED9+vXx8vIiPDyckydP5riAZU6CggZhZ2eX10cUBUBRFJKSkpgxY7hp5Et+2dnZ4ebmJtt6CiGEEEKIp44kI0Se/fvvvxQrVkztZgCPTpzk1pIlS0zlZfLx8SEsLIyAgIDHKjtTq1atqFKlCs2aNSM1NZU+ffoQEhJiOj9r1izS09N58803uX37NvXr1+ebb77JU6x79erF+fPnmTBhAnfv3qV79+4MGzaMb775Jk9tnTbtM/I580M8Jp1OS2CgP1OmfPrYIyOcnfVERCwpoJYJIYQQQghRcCQZIfKsdOnSajehwN2/qUxsbCxubm4cO3YMT0/PLNdGR0fnufzVq1eb/pzd7hUARYoUYdGiRSxatCjb882bN+fBzW88PT2zHJs8eTKTJ082OzZ79uw8tVevH4Je75Gne0TByFgzIgZHx1mPtWZESkocN27MJTExUUZGCCGEEEKIp44kI0S20tPTmTBhAitWrECn0zF06FDTb/EfNU0jO1u3biUoKIhz587h4uLCyJEjeffdd3N17+LFi5k/fz5xcXEULVqUpk2bsmXLFgICAvj222/59ttvWbhwIQAXLlzA1dWVb7/9lvHjx3PixAmcnJzw9/dn+vTppoUn09PTmTNnDsuXLycuLo5SpUoxZMgQpkyZkqX+tLQ0Bg0axA8//MDevXupUKHCQ9ur0WhYunQpX375JQcOHKBixYqsWrWKEiVKMHDgQI4cOULt2rVZt24dlStXNt33xRdfEBoayqlTpyhTpgz+/v5MmTLF1OZ58+YRFhbGX3/9hZOTE506deLDDz80TadYvXo1o0ePZtOmTYwePZq4uDiaNGlCWFiYadeNB6WmppKammr6nJiYCIC9fSlsbB7+nKJwaLVGIIaiRcs91m4aOl0a8fFa0tLSZI/uPJK9zdUl8Vef9IG6JP7qkz5Qn/SBup5U/CUZIbK1Zs0axo4dy+HDh/nxxx8JCAjAy8sLHx+fPJf166+/4uvrS0hICL169eKHH37g7bffxtnZ+ZFTIH755RdGjRrFunXraNy4MTdv3uTgwYMALFy4kD///JOXXnqJadOmAVCiRAn++ecfOnToQEBAAGvXruX06dMMGjSIIkWKmBIqgYGBfPbZZ8yfP58mTZrw77//cvr06Sz1Z06niI2N5eDBgzn+hvnB9RWGDRuGTqfDwsKCEiVK4OfnR6VKlQgMDKRChQq89dZbjBgxgj179gBw8OBB+vXrx6JFi2jatCnnz59n8ODBAAQHBwNgYWHBokWLcHNz46+//uLtt99mwoQJLF682FRvcnIyc+bMYd26dVhYWPDGG28wbtw4wsPDs233zJkzsx2p4e9/Dhubyzn2iyh8fn6RBVCKPzExMVm2hxW5ExlZEH0g8kvirz7pA3VJ/NUnfaA+6QN1RUVFFWr5GuXBMd7ihde8eXPS0tJML/0Ar7zyCi1btmTWrFl5XsCyb9++XL9+nb1795qumTBhArt37+bkyZMPbcu2bdvo378/ly5dwt7ePtu2PrhmxJQpU9i6dSsxMTGmBQAXL17MxIkTSUhI4M6dO5QoUYJPPvmEgQMHZikzc5rGwYMHCQkJITU1lV27dlG0aNEc23nu3DnTn6tUqcLbb7/NmDFjAPjnn39o3rw5K1eu5K233gJg48aN9O/fn5T/bVnRunVrWrVqRWBgoKmc9evXM2HCBC5fzj4psGXLFoYOHcp///0HZIyM6N+/P+fOnTONuFi8eDHTpk3jypUr2ZaR3ciI8uXL07btz9jYeOb4vKLwaLVG/PwiiYjweayREcnJF4iPn8TatbMKZXeY55nsba4uib/6pA/UJfFXn/SB+qQP1JUZ/1dffRUXFxcSEhIKZXc2GRkhslWrVi2zzy4uLly7di3Lde3btzclLSpWrJhtciEmJobOnTubHfPy8mLBggWkpaVhaZnzvHgfHx8qVqxIpUqVaNeuHe3ataNr167Y2NjkeE9MTAyNGjUy24nAy8uLpKQkLl26xJUrV0hNTaVVq1Y5lgHQp08fypUrx4EDBx65o4a7u7vZ5+bNm5uOZT7fyy+/bDpfqlQp7t69S2JiIg4ODpw4cYJDhw4xY8YM0zVpaWncvXuX5ORkbGxs2LdvHzNnzuT06dMkJiZy7949s/MANjY2ZlM/cuq3THq9Hr1en+X4vXuWj/UiLB6f0ah9rD4wGCwxGIxYWlrKX+L5JHubq0virz7pA3VJ/NUnfaA+6QN1FXbsJRkhsvXgF55GoyE9m+0VVqxYYfrtfmF8sdrb23P06FGio6PZu3cvQUFBhISEcOTIkXxvG5rbrTo7dOjA+vXr+fHHH2nZsmWe6rg/FplJkeyOZcY0KSmJ0NBQunXrlqWsIkWKEBsbS8eOHRk2bBgzZszAycmJ77//ngEDBmAwGEzJiOz6LT+Dn1JSLpOenvNIEFF4MhawzBjZ8LgLWAohhBBCCPG0kmSEeCxly5Z95DUeHh4cOnTI7NihQ4eoWrXqQ0dFZLKysqJ169a0bt2a4OBgHB0dOXDgAN26dUOn05GWlpalvq1bt6Ioiuml/9ChQ9jb21OuXDlKliyJtbU1+/fvz3aaRqZhw4bx0ksv8frrr7N79268vb0f2db8qlu3LmfOnMkywiLTr7/+Snp6OnPnzsXCwgKAzz//vNDak5q6jP/lmMQTptNpAX/i4ycVyNaehTGkTgghhBBCiMclyQhR6N59910aNGjA+++/T69evfjxxx/55JNPzBZezMmuXbv466+/aNasGcWKFeOrr74iPT2datWqAeDq6srhw4eJjY3Fzs4OJycn3n77bRYsWMDIkSMZMWIEZ86cITg4mLFjx2JhYUGRIkWYOHEiEyZMQKfT4eXlxfXr1zl58iQDBgwwq3/kyJGkpaXRsWNH9uzZQ5MmTQolRkFBQXTs2JEKFSrQo0cPLCwsOHHiBH/88QfTp0/H3d0do9HIxx9/TKdOnTh06BBLly4FoFixYhw7dqyA2zMoy6Kc4slQFIWkpCRmzBhuNtUoN+zs7HB2djZ9dnBwkG09hRBCCCHEU0mSEaLQ1a1bl88//5ygoCDef/99XFxcmDZt2iN30gBwdHRk27ZthISEcPfuXapUqcKGDRuoWbMmAOPGjcPf358aNWqQkpJi2trzq6++Yvz48dSuXRsnJycGDBjAe++9B0BcXByxsbHcu3cPf39/IOMlbvTo0WZ116lTB8hYV8HR0ZHWrVtz4MABGjdubFos8kH3r78QEBDAmjVrmDBhgtk1O3bsoGvXrmbH2rZty65du5g2bRqzZ89Gq9VSvXp108iN2rVrM2/ePGbPnk1gYCDNmjVj5syZ9OvXj9OnT1O5cmWOHz/+yHjm1rRpn5HNrBzxBOh0WgID/Zky5dM8j4xwdtYTEbFEEhBCCCGEEOKpJ8kIkUV0dHSWYzt27DD9+VFrEDRv3jzLNd27d6d79+55bkuTJk2ybU+mqlWr8uOPP2Y57u3tzc8//5zl+F9//UWjRo2oWrUqX375JW5ubpw8eZLx48ezadMmxowZg6urK97e3lStWpVp06aRnJzM2rVrCQ0N5e+//6Zx48ZAxm+dz5w5Y1a+RqOhVKlSQEbMihQpwvLly7l58ybFihUzu/bBGLVt25a2bdvm+Kxjxowx7dCR6c033zT9OSAgIEuCp0uXLvlaM0KvH4Je75Hn+8Tjy1gzIgZHx1l5WjMiJSWOGzfmkpiYKMkIIYQQQgjx1JNkhHihDB8+HJ1Ox969e00LWVaoUIE6depQuXJlpkyZwpIlS4CMnSlKly4NQEhICBEREezcuZM+ffoAGYmHzPM5ad26NefOnWPmzJl8+OGHeWprYmIipUqVYtu2bbRv3950fPv27fTr14+rV69y7do13NzcOHbsGJ6enkybNo2lS5fy+++/m4brv/baayQnJ7N//37TehOZstvaE8DevhQ2NhXy1F5RMLRaIxBD0aLl8rSbhk6XRny8lrS0NIzGx1tr4kWXGT+Jozok/uqTPlCXxF990gfqkz5Q15OKv0bJz69NhSggBw8eNHvRflBSUlKB1XXz5k2KFy/OjBkzCAwMzHJ+8ODBbNmyhRs3btCiRQs8PT1ZsGCB6Xzt2rXR6/WcOnUKo9GIwWDA1tbWdP7BrU0DAgKIj4/H398fPz8/zp49S7ly5UzTNHLzrdezZ0+KFCnCunXrTMd69OiBtbU169atIzY21iwZkZaWRtOmTSlVqhTbt2/n008/5b333uPEiRNUqJA1uRASEkJoaGiW4xEREQ/dPlUIIYQQQgjxfEtOTsbPz4+EhIRCWRRdRkYIVdWvX79A1zp4mLNnz6IoCh4e2U8/8PDw4NatW1y/ft3seFpaGhs2bOC3335jzpw5dO7cma1btzJp0iSzhEJsbCzt27dnz549Zvd37doVT09PgoODWblyZZ7a3LdvX958802Sk5OxsbEhMTGR3bt3s3379myvt7S0ZP369Xh6ejJp0iQWLVrEihUrsk1EAAQGBjJ27FjT58TERMqXL8+aNe7Y2Hjmqa2iYGi1Rvz8IomI8MnTyIjk5AvEx09i7dpZuLm5FWILn39Go5HIyEh8fHxkb3MVSPzVJ32gLom/+qQP1Cd9oK7M+Ldo0aJQ65FkhFCVtbV1jttZFpbcDgZavHgxK1aswGAwYGlpaVqzwcLCglKlSmFvb8/Ro0fN7smc+vGg2bNn07JlS8aNG5entnbo0AGtVsvOnTvp3bs3W7duxcHBgdatW+d4T6VKlZgzZw5DhgyhV69e+Pn55XitXq83W3Qz0717lnl6ERYFz2jU5qkPDAZLDAYjlpaW8pd2AdFqtRJLFUn81Sd9oC6Jv/qkD9QnfaCuwo69JCPEC8Pd3R2NRkNMTEyW3SwAYmJiKFasmGnxv759+zJlyhSsra1xcXHJst6ChYVFrhMpzZo1o23btgQGBuZqF5FMOp2OHj16EBERQe/evYmIiKBXr15YWT38W/e7777D0tLStGvIo65/UErKZdLTi+bpHlEwMhawzBjpkNcFLIUQQgghhHhWSDJCPNM0Gg3bt2+nS5cuj7zW2dkZHx8fFi9ezJgxY8xGMVy5coXw8HD69euHRqMBoGjRoo81auPcuXMcPnzY9HnWrFl4enpSrVq1PJXTt29ffHx8OHnyJAcOHGD69OkPvX7Tpk1s27aN6Oho2rRpw0svvcTp06fzVGdq6jJSUvJ0iyggOp0W8Cc+flK+tvYsjPl8QgghhBBCFDRJRogXyieffELjxo1p27Yt06dPN23t2b59e1xcXJgxY0auy1IUhStXrmQ5XrJkySyjKABefvll+vbty6JFi/LU5mbNmlG6dGn69u2Lm5sbpUqVQqPRcOzYMRwdHc2uvXTpEsOGDWP27Nk0adIELy8v9u/fz08//UTDhg1zXWdQ0CDs7Ozy1E5RMBRFISkpiRkzhpsSY7lhZ2eHm5ubbOsphBBCCCGeCZKMEC+UKlWq8MsvvxAcHIyvry83b940bc85e/ZsnJyccl1WYmIiLi4uWY7/+++/OW75OW3aNDZt2pSnNms0Gvr06cOHH35IUFBQjtcpikJAQACvvPIKI0aMAKBs2bK4urryxhtvcPz48VwnGKZN+4z09Dw1UxQQnU5LYKA/U6Z8mqeREc7OeiIilhRiy4QQQgghhCg4kowQqlm+fDkhISFcunTJbCRB586dcXZ2ZtWqVSxZsoQ5c+YQFxeHm5sb7733Hm+++Wae6zIYDIwdO5atW7dy69YtSpUqxTvvvENgYCCurq4A9OvXj379+lGxYkViY2MBcqw/ICDAtHXnxIkT2bFjBwkJCbi7u/PLL7/QsWNHBg4cyB9//GFqw/Xr1+nRowcdOnRg48aND23vrVu3GDFiBHv37iUpKYly5cqxatUq+vfvb/pteZ06dQDw9vY2betZq1YtVq1aRfHixRkwYACKolCrVi127NiRp3jp9UPQ67PfdUQUrow1I2JwdJyV6zUjUlLiuHFjLomJiTIyQgghhBBCPBMkGSFU07NnT0aOHElUVBStWrUC4ObNm3z99dd89dVXbN++nXfeeYcFCxbQunVrdu3aRf/+/SlXrlyet5lZtGgRO3fu5PPPP6dChQrExcURF5ex4N+RI0coWbIkYWFhtGvXDkvLjBfAR9Wfnp5O+/btuX37NuvXr6dy5cqcOnXKdP/94uLi8PHxoWHDhqxcuTLba+43depUTp06xZ49eyhevDjnzp0j5X+LOPz888+88sor7Nu3j5o1a6LT6QCYO3cuq1evZtWqVXh4eDB37ly2b99Oy5Ytc6wnNTWV1NRU0+fExEQA7O1LYWOT/XagonBptUYghqJFy+V6Nw2dLo34eC1paWkYjXlbZ0JklRlDiaU6JP7qkz5Ql8RffdIH6pM+UNeTir9Gye0+h0IUgi5duuDs7MzKlSuBjNESoaGhxMXF0bRpU2rWrMny5ctN1/v6+nLnzh12794N5H4By1GjRnHy5En27duX7Tz87Mrx8vJ6aP179+6lffv2xMTEULVq1Sxlrl69mtGjR3P48GF8fHzo2rUrCxYsMKu/ffv2HDx4MMu9d+/epXbt2vz6669ZzsXGxuLm5saxY8fw9PQ0HS9Tpgxjxoxh/PjxANy7dw83Nzfq1auX48iIkJAQQkNDsxyPiIjAxsYm23uEEEIIIYQQz7/k5GT8/PxISEgolEXSZWSEUFXfvn0ZNGgQixcvRq/XEx4eTu/evbGwsCAmJobBgwebXe/l5cXChQvzXE9AQAA+Pj5Uq1aNdu3a0bFjR9q0afPQex5V//HjxylXrly2iYhMKSkpNG3aFD8/PxYsWJDl/IoVK0wjHu737bffMnLkSDw9PWnTpg1dunShcePGOdaTkJDAv//+y6uvvmo6ZmVlRf369XlYvjEwMJCxY8eaPicmJlK+fHnWrHHHxsYzx/tE4dFqjfj5RRIR4ZPrkRHJyReIj5/E2rWzcHNzK+QWPv+MRiORkZH4+PjI3uYqkPirT/pAXRJ/9UkfqE/6QF2Z8c/raPS8kmSEUFWnTp1QFIXdu3fToEEDDh48yPz58wu8nrp163LhwgX27NnDvn378PX1pXXr1mzZsiXfZd6/NWhO9Hq9aYrH+PHjKVu2rNn5Bz9ncnd35/XXX+err74iMjKSVq1aMXz4cObMmZPv9ubUPr1en+X4vXuWuX4RFoXDaNTmug8MBksMBiOWlpbyF3YB0mq1Ek8VSfzVJ32gLom/+qQP1Cd9oK7Cjr0kI4SqihQpQrdu3QgPD+fcuXNUq1aNunXrAuDh4cGhQ4fw9/c3XX/o0CFq1KiRr7ocHBzo1asXvXr1okePHrRr146bN2/i5OSEVpsx3/5+j6q/Vq1aXLp0iT///DPH0REWFhasW7cOPz8/WrRoQXR0NGXKlMlVe0uUKIG/vz/+/v40bdqU8ePHM2fOHNMaEfe3t2jRori4uHD48GGaNWsGZEzT+PXXX03xzIuUlMukpxfN833i8WUsYJkx2iEvC1gKIYQQQgjxLJFkhFBd37596dixIydPnuSNN94wHR8/fjy+vr7UqVOH1q1b8+WXX7Jt2zb27duX5zrmzZuHi4sLderUwcLCgs2bN1O6dGkcHR0BcHV1Zf/+/Xh5eaHX6ylWrJhZ/ZGRkfz555+cPn3aVL+3tzfNmjWje/fuzJs3D3d3d06fPo1Go6Fdu3amui0tLQkPD6dPnz60bNmS6OjoHLf+zBQUFES9evWoWbMmqamp7Nq1Cw+PjN0tSpYsibW1NV9//TXlypWjSJEiFC1alHfeeYdZs2ZRpUoVqlevzrx584iPj89zrACSkhYQHy97e6pBr9cBw7h2bRSpqQazcxYWVmi1WUeyQMbWnoUxl08IIYQQQojCYPHoS8SLICAgAI1Gg0ajQafT4e7uzrRp07h37x7R0dGmcxqNhhIlStChQwd+//13szIMBgMffvghtWvXxsbGhuLFi+Pl5UVYWNhDV2Jt2bIlTk5OnDlzBj8/P9PxLl26sHDhQubMmUPNmjVZtmwZYWFhNG/ePNtyQkJCzBZ0vJ+9vT0ffvgh9evXp0GDBsTGxvLVV1+ZthSdO3cukZGRlC9f3rRl5v3179ixg9jY2Cz1b926lQYNGtCnTx9q1KjBhAkTsoywgIz1GzZs2EDNmjVp2bIl165dyzEeADqdjsDAQGrVqkWzZs2wtLQ0bQdqZWXFokWLWLZsGWXKlKFz584AvPvuu7z55pv4+/vTqFEj7O3t6dq160PryZkFGblK+e/J/5c5GsIyy7miRa1YunQqmzcvyPJfRMQS2dZTCCGEEEI8M2Q3DQFkJCOuXr1KWFgYqampfPXVVwwfPpwZM2bQqFEjWrRowZkzZ3BwcODy5cuMHz+es2fPcu7cOXQ6HQbD/7F373E53//jxx9Xp6tzKYdCyilyaJg5H2rLimEOc8pGzsdZa3JqksPm2IRhZlRYY2PYMDQyZMIsH9SMxjCHNpOkdnX8/dG398+lg0LeG8/77eZ263pf78Pr/Xx28H5er0Mm3t7enDp1itmzZ9O2bVusra05evQoixYtYu3atcUWCp6UkJAQtm3bRnx8/BM/t5+fHykpKcWuSvGsSE1NxcbGhjZtvkWrdVO7Oc8lE5McxoxJZOVKN71hGhkZV9DpQvnqqzBq166tYguffVlZWezatYsuXbrIOFUVSPzVJzlQl8RffZID9UkO1FUQ/3bt2lGxYkVZTUOUP61WqwwfGDNmDFu3buWbb76hdevWQP7wAFtbWxwcHPD396d79+788ssvuLu7ExYWxsGDBzlx4oTSswCgVq1a9OnTh8zMzCKveb/du3czZ84czpw5g6GhIa1bt2bJkiV6D15Xr14lMDCQPXv2oNPpcHNzY/ny5SQmJipLVBYsnVnQi+HBZTBTUlKoUKECMTExeHh4kJOTw8iRI9m/fz83btygRo0ajB07lnfeeeeR4ujh4UHjxo0xNDQkMjISExMT5syZg6+vL+PHj2fz5s1UqVKFZcuW0blzZ+W4M2fOEBgYyKFDh7CwsODVV19l8eLFVKxYsVTxKVjyc8uWLSxbtoy4uDjq1q3LJ598ouSwtMzMqmJmJg+8ajA2zgISMTevWeiPr06nTpuEEEIIIYR40qQYIYplZmbGrVu3Cm2/c+eOMmSgYDLFzz//HC8vL71CRIHSzoJ77949AgICcHd3Jy0tjeDgYHr27El8fDwGBgakpaXRsWNHqlWrxjfffIODgwMnT54kNzeX33//HSMjI3JycjA1NQVg3LhxJS5rWSA3N5fq1avz1VdfYW9vz5EjRxg5ciSOjo707dv3occXJTIykkmTJnHs2DE2bdqkFHd69uzJtGnT6NGjB126dMHc3ByNRkNeXh7p6ekYGxvTs2dPpkyZwuTJk+nbty/79+8vVXwKBAUFsWjRIurWrUtQUBADBgzgwoULGBkV/nHX6XTo7nvCTU1NBcDIKOf/HorF01YQ9wfjb2KSg4lJ/kSrJQ17Eo+vIL4SZ3VI/NUnOVCXxF99kgP1SQ7U9bTiL8M0BKA/DCEvL499+/bRtWtX3n77bV577TU8PT2xsLAA8h+KAbp378727dsBMDc3Z8SIESxZsuSJtemvv/6iUqVKnD59mkaNGvHpp58yceJELl26hJ2dnd6+f//9NyEhIURHR/Ptt98q269evYqnp2eJPSOKMn78eG7cuKEs/VmWYRoFvS0OHToE5K96YWNjQ69evVi3bh2Q3wuicePGfPnllzRt2pTly5dz4sQJwsPDsba2pnLlyly9ehUnJyfOnTtX5GodD8anoGfEZ599xrBhwwBISEigYcOGJCYmUr9+/ULnCAkJUXqU3C8qKgpzc/OH3qsQQgghhBDi2ZSeno6vr68M0xDlb8eOHVhaWpKVlUVubi6+vr6EhIRw/PhxAA4dOoS5uTlHjx7lww8/5JNPPlGOfRI1rfPnzxMcHExcXBx//fUXubn5qzlcvnyZRo0aER8fT9OmTQsVIgDs7Oyws7NDq9VSp04dZXtRvQGKsnz5ctauXcvly5fJyMggMzPzsea4cHd3V742NDTE3t6exo0bK9saNmwIoLT36tWrxMXFFXnNpKQkXF1dHxqfoq7t6OgIQHJycpHFiKlTpxIQEKC8Tk1NxcnJicjIOpibF26LKH/Gxln4+kYTFdWJrKz/36MoPf0iKSlTWLduHjVr1lSxhc++rKwsoqOj6dSpk4xTVYHEX32SA3VJ/NUnOVCf5EBdBfH39PQs1+tIMUIoPD09WblyJSYmJlStWrXQg3zNmjWxtbWlXr16JCcn069fPw4ePAiAq6srv/zyy2Ndv1u3bjg7O7N69WqqVq1Kbm4ujRo1UuabMDMzK/M5C4Yv3F8sebC70caNG5k4cSKhoaHKKhQLFy4kLi7uke/lwV+aGo1Gb1vBvBYFBYW0tDS6devG/PnzC52roKDwsPgUde0Hr/MgrVaLVlt4qci7d2+SmXn5ofcpnjwTk/zVWO7cufrABJbXyMzMwtDQUP4oPyWlHWImyofEX32SA3VJ/NUnOVCf5EBd5R17KUYIhYWFhV6vgpKMGzeOuXPnKvMg+Pr6Mm3aNH7++edC80ZkZWWRmZmpDPMoyq1btzh37hyrV6+mffv2ABw+fFhvH3d3dz777DP+/vvvIntHmJiYFFpWs2Cpw+vXryvtenC1jdjYWNq0acPYsWOVbUlJSQ+JwJPVrFkztmzZgouLS5G9OUoTnydJp1tFRka5nV6UwMTEGBhMSsoUMjP1C2f29tpy6SInhBBCCCHE0ybFCPFICuaImDFjBj169MDf35+dO3fyyiuvMHv2bNq1a4eVlRUnTpxg/vz5rFmzpsRhDxUqVMDe3p5PP/0UR0dHLl++zJQpU/T2GTBgAB9++CE9evRg7ty5ODo68vPPP1O1alVat26Ni4sLFy9eJD4+nurVq2NlZYWZmRmtWrVi3rz8ru3Jycm8//77euetW7cu69atY8+ePdSsWZP169dz/Pjxp9oVfty4caxevZoBAwYwadIk7OzsuHDhAhs3buSzzz4rVXyKUlCwSEtLK1N7goNHYGlp+Uj3Ih5PXl4eaWlpfPDBODQaDZaWltjb2wNgbW2tFNiEEEIIIYT4L5NihHhk48eP56OPPuKrr76ib9++REdHs3jxYlatWsXEiRMxNzfHzc2NCRMm6M1pUBQDAwM2btyo7FuvXj2WLl2qN8GkiYkJe/fu5b333qNLly5kZ2fToEEDli9fDkDv3r35+uuv8fT0JCUlhfDwcPz8/Fi7di3Dhg3jxRdfpF69eixYsIBXX31VOe+oUaP4+eef6devHxqNhgEDBlCjRg1OnTqFRqPByMgIU1NTHBwc+Oeff5TVOgqGQDzIzc2NvXv3Fnr/3Xff5d133wXA2dlZ772qVasSGxvL5MmTefXVV9HpdDg7O+Pj44OBgQEajUYvPkZGRvj4+CjzeTxps2atppiRHaKcmZgYM3XqYIKClpOZmYW9vZaoqJVShBBCCCGEEM8UKUYIACIiIop9z8PDo8gJKp2cnPTmX9BqtUyZMqVUn9gXxcvLi4SEBL1tD17X2dlZWeHiQVqttsj33NzcOHLkSLHn1Wq1hIeHEx4ermzz8/OjevXqhIeHk5WVxU8//cTgwYOZMWOG3rwO4eHh+Pj46J3b1tYWnU5Hxn3jHBwdHfX2NTQ0LPRwWbduXb7++usi7w304+Ph4UH16tX17sPFxaVQvAp6N7Rr167Y8xZFqx2FVutWpmPEk5E/Z0QitrbzuHPnGrduhZKamirFCCGEEEII8UyRYoQQxdBqtTg4OAD5hRcvLy+io6P1ihG2trbKPvczNTXFxsZGb1tx+xZnxYoVLF68mCtXrmBjY0P79u3ZvHkzfn5+/PDDD/zwww/KUqoXL17ExcWFXbt24e/vz5UrV2jVqhWDBw9+lFvHzKwqZma1H+lY8XiMjbOARMzNa5KZaYhOp3aLhBBCCCGEePKkGCGeisuXL9OgQYNi309ISKBGjRpPsUVlc+bMGY4cOYKjo6PeXAr9+/fXm3DySd3HiRMnmDBhAuvXr6dNmzb8/fffHDp0CIAlS5bw66+/0qhRI2bNmgXkT9R55coVevXqxbhx4xg5ciQnTpzgvffeK/E6Op0O3X1Pu6mpqQAYGeX830OxeNoK4m5snIWJSQ4mJsbk5OQUWgVGlJ+CWEvM1SHxV5/kQF0Sf/VJDtQnOVDX04q/Jq+o/vdCPGHZ2dlcunSp2PeLW0VCLX5+fmzYsAFTU1Oys7PR6XQYGBjwxRdf0KxZMyB/WIVWq8XQ8P8vv6jRaIosSGg0GrZu3UqPHj1Kdf2vv/6aIUOGcPXqVaysrAq97+HhQZMmTQgLC1O2TZs2je3bt3P27Fll25QpU5g/fz63b9/G1ta20HlCQkKYOXNmoe1RUVGYm5uXqq1CCCGEEEKIZ096ejq+vr7cuXOnXFZ0+/c8/YlnmpGRUamXDf238PT0ZOXKldy7d4/FixdjZGRE37599fYJCwvDy8tLb1vVqlUf+9qdOnXC2dmZWrVq4ePjg4+PDz179iyxQJCYmEjLli31trVu3brE60ydOpWAgADldWpqKk5OTkRG1sHcvMlj3YN4NMbGWfj6RhMV1Yk7d66SkjKFdevmPdXVXZ53WVlZREdH06lTJ1nbXAUSf/VJDtQl8Vef5EB9kgN1FcTf09OzXK8jxQghimFhYaEUUNauXcsLL7zAmjVrGDZsmLKPg4NDuRRZrKysOHnyJAcOHGDv3r0EBwcTEhLC8ePHi+zh8Ki0Wi1arbbQ9rt3b5KZefmJXUeUXv4ElnDnzlXu3LlGZmYWhoaG8odYBcbGxhJ3FUn81Sc5UJfEX32SA/VJDtRV3rGXYoQQpWBgYMC0adMICAjA19cXMzOzcr+mkZERXl5eeHl5MWPGDGxtbdm/fz+9evXCxMSEnJwcvf3d3Nz45ptv9LYdPXr0ka6t063ivsVAxFNkYmIMDCYlZYqytGd5dIsTQgghhBBCTVKMEKKU+vTpQ2BgIMuXL2fixIkApKSkcOPGDb39rKyssLCweKxr7dixg99++40OHTpQoUIFdu3aRW5uLvXq1QPy59iIi4vj0qVLWFpaYmdnx+jRowkNDSUwMJDhw4fz008/lbhka0mCg0foTdQpnp68vDzS0tJYt24ehoaGWFtby7KeQgghhBDimSPFCCEecPDgQfbt28eff/6pN/GkkZER48ePZ/78+fz1118ADBkypNDxxsbGRERE4Ovrq7d9ypQpbNiwgc2bN5d4fT8/PyIjI5XXGo2GihUrEhkZScOGDQGYOHEi9erVo169emRmZnLx4kVlToFFixaxaNEiLC0tGTJkCMuWLStzDGbNWk1ubpkPE0+AiYkxU6cOxsrKCkdHR7WbI4QQQgghRLmQYoQQD7h37x6DBw/mxRdfpFevXnrvTZkyBY1Gw9y5c9m2bRs1a9Zk+vTpnD59moSEBExNTVm6dClvv/02np6eysPkggULCA0N5ZNPPilVG3x8fAgPDycrK4uffvqJwYMHc/r0aeV9V1dXADZt2qS3Qkd4eDg+Pj6kpqayYsUKli9fzv/+978yzzOh1Y5Cq3Ur0zHiycjJuQykcvfuXSlGCCGEEEKIZ5YUI4R4QOfOnencuXOR7+Xl5REWFsb777/P66+/DsC6deuoUqUK27Zto3///rz99tts27aNESNGsGPHDn755ReCg4PZtGkTFStWLFUbtFotDg4OADg5OeHl5UV0dDTz588v8ThbW1scHBxwcHBg9uzZLFmyhJiYGBo3blzk/jqdDp1Op7xOTU0FwMqqCubmNYo8RpSvrKxMIJWcnBxZW1slsra5uiT+6pMcqEvirz7JgfokB+p6WvGXYoQQZXDx4kVu3Liht5ynjY0NLVu25Mcff6R///5oNBrCw8Nxd3dn9erVrFmzhv79+9O9e3flmEOHDhVb8NDpdLz22mvK6zNnznDkyBGcnZ1L3c7s7GzWrFkDgImJSbH7zZ07l5kzZxbaPnjwBczNr5X6euLJ+/XXX/n111/VbsZzLTo6Wu0mPNck/uqTHKhL4q8+yYH6JAfqiomJKdfzSzFCiDIomKyySpUqeturVKmiN5Gls7MzYWFhDB8+nOrVq7N37169/Zs3b058fHyR15g0aRLffPMNlpaWZGdno9PpMDAw4OOPP35o+wYMGIChoSEZGRnk5ubi4uJC3759i91/6tSpBAQEKK9TU1NxcnIiMrIO5uZNHno98eRlZV1g+PBfcXV1LZdlY8XDydrm6pL4q09yoC6Jv/okB+qTHKirIP6enp7leh0pRghRToYMGcL06dN5++23Cy3NaGZmVuyDprW1NZ6enqxcuZJ79+6xePFijIyM6N2790OvuXjxYry8vPjtt9949913Wbp0KXZ2dsXur9Vq0Wq1hbZnZxuSlSW/+NWQlWUIgKGhofzxVZmsba4uib/6JAfqkvirT3KgPsmBuso79lKMEKIMCuZxuHnzpt7kgjdv3qRJkyaF9jcyMsLIqOw/ZhYWFkqxYu3atbzwwgusWbOGYcOGPbR9derUoU6dOoSHh9OlSxcSEhKoXLlyma6fkXGN3FybMrdbPL6cnD/UboIQQgghhBDlTooRQpRBzZo1cXBwYN++fUrxITU1lbi4OMaMGVMu1zQwMGDatGkEBATg6+uLmZlZqY5r0aIFL774Ih988AFLliwp0zV1ulVkZDxKa8XjMjExBvKX9hRCCCGEEOJZJcUI8Uzy8/MjMjJSeW1nZ8dLL73EggULcHd3B0Cj0bB161ZlaUyNRqPsb2pqSqVKlQA4ePAgLi4u2NnZUaNGDfz9/ZkzZw5169ZVlvasWrWq3hKbT1qfPn0IDAxk+fLlTJw4sdTH+fv707NnTyZNmkS1atVKfVxw8AgsLS0fpaniMZmbm3Pz5s1Sr7wihBBCCCHEf5EUI8Qzy8fHh/DwcCB/4sn333+frl27cvny5WKPCQ8Px9ramt69e3PlyhUgfx6GxYsXM3jwYCIiIpg0aRL37t1j5MiRpKSk0K5dO3bv3o2pqWm53YuRkRHjx49nwYIFjBkzBgsLi1Id5+PjQ82aNfnggw9YsWJFqa83a9ZqcnMftbXicTg4WDJqVH+1myGEEEIIIUS5kmKEeGZptVpljgcHBwemTJlC+/bt+fPPP5VeDw+ytbWlR48e5OXlKdsGDx7M1q1bWbx4MZDfg2LWrFnMmjWr0PERERH4+/uzYcMG3nvvPZKTkzl8+DAjR47kq6++YsaMGdy5c4e33nqLxYsXY2iYP1mhTqcjKCiIL774gpSUFBo1asSBAwfw8PAA4NatW5w6dQpjY2MqVapE7dq1iYqK0uuN0bFjR/bv38+RI0f47LPPMDExYfTo0SQmJj5C7Eah1bqV+TjxeDIyrvD330vVboYQQgghhBDlTooR4rmQlpbGhg0bqFOnDvb29mU69t1332XdunVER0eXuExmgfT0dJYuXcrGjRu5e/cuvXr1omfPntja2rJr1y5+++03evfuTdu2benXrx8A48ePJyEhgY0bN1K1alW2bt2Kj48Pp0+fpm7duvzzzz+8+OKLTJ48GWtra3bu3Mlbb71F7dq1adGihXLtyMhIAgICiIuL48cff8TPz4+2bdvSqVOnItuq0+nQ6XTK69TUVACsrKpgbl6jTHESj8/EJIf09PxZi7OyslRuzfOrIPaSA3VI/NUnOVCXxF99kgP1SQ7U9bTir8m7/yNgIZ4Rfn5+bNiwQRk6ce/ePRwdHdmxYwfNmjUDip4z4v7XBf755x/MzMyYP38+kyZNKvG6ERERDBkyhAsXLlC7dm0ARo8ezfr167l58yZ///03DRo04J9//kGj0aDVasnNzSUjIwMzMzN++eUXatTILwJ4eXnRokULPvzwwyKv1bVrV+rXr8+iRYsA8PDwICcnh0OHDin7tGjRgpdffpl58+YVeY6QkBBmzpxZaHtUVBTm5uYl3qsQQgghhBDi2ZWeno6vry937tzB2tr6iZ9fekaIZ5anpycrV64E4Pbt26xYsYLOnTtz7NgxnJ2dS32egnrd/RNclsTc3FwpRABUqVIFFxcXLC0tMTU1JT4+nkmTJpGWlsaKFSuIiYlh5MiRaDQaGjRooByn0+mUXhw5OTl8+OGHfPnll/zxxx9kZmai0+kKFQwKJucs4OjoSHJycrFtnTp1KgEBAcrr1NRUnJyciIysg7l5k1Ldr3hy0tMvkp4+nffe86VTp06yrrZKsrKyiI6OlhyoROKvPsmBuiT+6pMcqE9yoK6C+Ht6epbrdaQYIZ5ZFhYW1KlTR3n92WefYWNjw+rVq5kzZ06pz1Mw50LNmjVLtf+DvzA1Go2yzcjIiDp16mBtbU1ubi516tThp59+wtDQkJMnTypzSBQoWNFi4cKFLFmyhLCwMBo3boyFhQX+/v5kZmY+9Nq5JcxEqdVq0Wq1hbZnZxuSlSW/+J+2zExDMjPzu8MZGxvLH1+VSQ7UJfFXn+RAXRJ/9UkO1Cc5UFd5x16KEeK5odFoMDAwICMjo0zHhYWFYW1tjZeXV7m0q2nTpuTk5JCcnEz79u2L3Cc2NpbXX3+dN998E4Dc3Fx+/fVXvZ4UT1JGxjVyc23K5dyieBkZV9RughBCCCGEEE+FFCPEM0un03Hjxg0gf5jGxx9/TFpaGt26dSv2mJSUFG7cuIFOp+PXX39l1apVbNu2jXXr1mFra1su7XR1dWXgwIEMGjSI0NBQmjZtyp9//sm+fftwd3fntddeo27dumzevJkjR45QoUIFPvroI27evFluxYi0tDBSUmRtTzVUrWqrdhOEEEIIIYQod1KMEM8UPz8/IiMjldeOjo5A/nAHNzc3vvrqK72xTz179tQ7fsiQIUWed+DAgQwcOBBnZ2cuXbr0xNsdHh7OnDlzeO+99/jjjz+oWLEirVq1omvXrgC8//77/Pbbb3h7e2Nubs7IkSPp0aMHd+7ceeJtyWfwf//E01e6uUmEEEIIIYT4L5NihHjm+Pj4EB4eTlZWFj/99BODBw9m9OjRzJ8/X9knPDwcHx8fveNsbW3R6XR6wzgcHR319n1wTocH+fn54efnp7ctJCSEkJAQvW0RERF6r42NjZk5c2aRK1sA2NnZsW3bthKvfeDAgULbHnZMcSwtJ6DVuj3SseLRZWRc4e7dpWo3QwghhBBCiHInxQjxzNFqtTg4OADg5OSEl5cX0dHResUIW1tbZZ/7mZqaYmOjP1dCcfsWx8XFheHDh/Prr7/y9ddfY29vz7Jly2jdujXDhw9n37591KpVi7Vr19K8eXPluMOHDzN16lROnDhBxYoV6dmzJ3PnzsXCwgKA9evXs2TJEs6dO4eFhQUvv/wyYWFhVK5cGcgvRnh6evL9998zefJkEhISaNKkCeHh4dSrV6/0AQTMzKpiZlb74TuKJy49Xe0WCCGEEEIIUf6kGCGeaWfOnOHIkSNlWsqzJJ07d+bQoUNFvjdt2jSmTZsGwOLFi/nwww+ZPn06ixcv5q233qJNmzYMHTqUhQsXMnnyZAYNGsTZs2fRaDQkJSXh4+PDnDlzWLt2LX/++Sfjx49n/PjxhIeHA/lL7MyePZt69eqRnJxMQEAAfn5+7Nq1S68dQUFBhIaGUqlSJUaPHs3QoUOJjY0tss06nQ6dTqe8Tk1NBcDIKAdj46zHjpcoGxOTHLKz82ctzsqS+KulIPaSA3VI/NUnOVCXxF99kgP1SQ7U9bTir8nLy8sr1ysI8RT5+fmxYcMGTE1Nyc7ORqfTYWBgwJdffknv3r2B/FU1TE1NCw25SEhIoEaNGnrbNBoNW7dupUePHgD88ccfxa7GYWdnh52dHS4uLrRv357169cDcOPGDRwdHZk+fTqzZs0C4OjRo7Ru3Zrr16/j4ODA8OHDMTQ0ZNWqVcr5Dh8+TMeOHbl37x6mpqaFrnfixAleeukl7t69i6WlpV7PiFdeeQWAXbt28dprr5GRkVHkOUJCQoocGhIVFYW5uXmR9ymEEEIIIYR49qWnp+Pr68udO3ewtrZ+4ueXnhHimePp6cnKlSu5d+8eixcvxsjISClEFFi8eHGhpTqrVq360HNXq1atVG1wd3dXvq5SpQoAjRs3LrQtOTkZBwcHTp06xf/+9z8+//xzZZ+8vDxyc3O5ePEibm5u/PTTT4SEhHDq1Clu375Nbm7+aheXL1/WW1Xj/msXTOCZnJxcqNACMHXqVAICApTXqampODk5ERlZB3PzJqW6V/HkpKdfJD19Ou+950unTp1kXW2VZGVlER0dLTlQicRffZIDdUn81Sc5UJ/kQF0F8b9/4v/yIMUI8cyxsLCgTp06AKxdu5YXXniBNWvWMGzYMGUfBwcHZZ/ycP8vTY1GU+y2goJCWloao0aNYsKECYXOVaNGDe7du4e3tzfe3t58/vnnVKpUicuXL+Pt7U1mZuZDr11wnQdptVq0Wm2h7Xfv3iQz83Kp7lU8ORkZ18jLy+8OZ2xsLH98VSY5UJfEX32SA3VJ/NUnOVCf5EBd5R17KUaIZ5qBgQHTpk0jICAAX19fzMzM1G5SkZo1a0ZCQkKxBZLTp09z69Yt5s2bh5OTE5A/TKO86HSrKGY0iihnDg6WajdBCCGEEEKIcifFCPHM69OnD4GBgSxfvpyJEycCkJKSwo0bN/T2s7KyUlaueJIeXNazKJMnT6ZVq1aMHz+e4cOHY2FhQUJCAtHR0Xz88cfUqFEDExMTli1bxujRozlz5gyzZ89+6Hm/+eabR2pzcPAILC3lobi8WVpaYm9vr7fN3NycY8eOqdQiIYQQQgghng4pRohnnpGREePHj2fBggWMGTMGgCFDhhTar379+ty5c4fr16/rTVo5YcIEdu3axaeffqq3/6RJk/jqq6/43//+h5WV1WO10d3dnR9++IGgoCDat29PXl4etWvXpl+/fgBUqlSJiIgIpk2bxtKlS2nWrBmLFi2ie/fuj3Xd4syatZpiRnaIJ8jeXktU1EoqVaqkbJNZo4UQQgghxPNAihHimRIREVHk9ilTpjBlyhQgf2LIB3333XfExsby4osv0qtXL2V7Xl4eP/30E61bt6Z37954e3sD+athLF68mO+//75QIeLSpUuFzv/CCy8oxQ0AFxeXQu146aWX2Lt3b7H3NmDAAAYMGKC37f5zeHh4FDpnjRo1sLGxwcXFpdjzFkWrHYVW61amY0TZZGRc4datUFJTU/WKEUIIIYQQQjwPpBghBNC5c2c6d+5c5HsvvvgiQUFBDBs2jDNnzmBqasqQIUN4++236dixY6mvsWrVKubMmcOtW7fo2rUrq1evxsbGBsifYHLOnDl8+umn/Pnnn7i5uTFv3jx8fHyA/AJHzZo12bJlC8uWLSMuLo66devyySef0Lp1a+UaERERBAcH89dff+Ht7U27du0eKR5mZlUxM6v9SMeK0tPp1G6BEEIIIYQQ6pBihBClEBQUxLfffkv//v3Zt28fOTk5XL58udDQjbS0tCKPv3DhAl9++SXffvstqampDBs2jLFjxypLeS5ZsoTQ0FBWrVpF06ZNWbt2Ld27d+fs2bPUrVtXrx2LFi2ibt26BAUFMWDAAC5cuICRkRFxcXEMGzaMuXPn0qNHD3bv3s2MGTNKvC+dTofuvifi1NRUAIyMcjA2luEC5cnEJAcTE2NycnL0hmYUfC3DNdQjOVCXxF99kgN1SfzVJzlQn+RAXU8r/pq8ovqsC/Ec02g0enNGFEhISODFF18kJyeHTZs20bhx40LHFrUaRkhICHPmzOH333+nWrVqAOzevZvXXnuNP/74AwcHB6pVq8a4ceOYNm2aclyLFi146aWXWL58udIz4rPPPlOWKE1ISKBhw4YkJiZSv359fH19uXPnDjt37lTO0b9/f3bv3k1KSkqR9xoSEsLMmTMLbY+KisLc3PyhsRJCCCGEEEI8m9LT05VnDGtr6yd+fukZIUQpNWjQgN69e5OSkkLPnj3LdGyNGjWUQgRA69atyc3N5dy5c5ibm3Pt2jXatm2rd0zbtm05deqU3jZ3d3fla0dHRwCSk5OpX78+iYmJhdrVunVrdu/eXWy7pk6dSkBAgPI6NTUVJycnIiPrYG7epEz3KMomPf0iKSlTWLduHjVr1lS2Z2VlER0dTadOnWRdbZVIDtQl8Vef5EBdEn/1SQ7UJzlQV0H8PT09y/U6UowQogyMjIwwMlLvx+b+X8YajQbIn2/iUWm1WrRabaHtd+/eJDPz8iOfVzxcRsY1MjOzMDQ0LPKPrLGxsfzxVZnkQF0Sf/VJDtQl8Vef5EB9kgN1lXfspRghxFNw+fJlrl27RtWqVYH81TgMDAyoV68e1tbWVK1aldjYWL0JMWNjY2nRokWpr+Hm5kZcXJzetqNHjz5Se3W6VWRkPNKhogzs7bXl0uVNCCGEEEKIfzspRohy4+HhQZMmTQgLCyvy/eLmZihw4MABPD09uX37Nra2tuXWTsifePLChQvK64sXLxIfH4+dnR01atR4pHMWzPMwatQoTE1NGTx4MIsWLSI1NZUJEybQt29fHBwcAAgMDGTGjBnUrl2bJk2aEB4eTnx8vDLBZWlMmDCBtm3bsmjRIl5//XX27NnD9u3byXiEqkJw8AgsLS3LfJwoHUtLS+zt7bG2tpZlPYUQQgghxHNJihFCNdevX6dChQpqNwOAdu3a6c3PUDCPwuDBg4mIiHjs89epU4devXrRpUsX/v77b7p27cqKFSuU9ydMmMCdO3d47733SE5OpkGDBnzzzTd6K2ncz8XFhVGjRulta9WqFatXr2bGjBkEBwfj5eVF9+7d2bRpU5nbO2vWah5j9Id4CHt7LVFRK6UQIYQQQgghnltSjBCqKegV8G9ga2vLO++8U2wvjgKPUpgYPXo0n3zyCQBjxowpch8DAwNmzJhR7FKcLi4uPLjwjZmZWaFtQ4cOZejQoXrtLWkCy+JotaPQat3KfJx4uIyMK9y6FUpqaqoUI4QQQgghxHNLihGiXOXm5jJp0iQ+++wzTExMGD16NCEhIcDDh2kUZcuWLQQHB3PhwgUcHR15++23ee+990p17IoVK1i8eDFXrlzBxsaG9u3bs3nzZvz8/Pjhhx/44YcfWLJkCZA/TMPFxYUffviBwMBATp06hZ2dHYMHD2bOnDnKJJa5ubksWrSITz/9lCtXrlClShVGjRpFUFBQoevn5OQwYsQIjhw5wt69e0sc/pGXl8fMmTNZu3YtN2/exN7enjfeeIOlS5fi4eHB77//zrvvvsu7776r7A/5xYfg4GD++usvvL29adeuXaljez8zs6qYmdV+pGPFw+l0ardACCGEEEIIdUkxQpSryMhIAgICiIuL48cff8TPz4+2bdvSqVOnMp/rp59+om/fvoSEhNCvXz+OHDnC2LFjsbe3x8/Pr8RjT5w4wYQJE1i/fj1t2rTh77//5tChQwAsWbKEX3/9lUaNGjFr1iwAKlWqxB9//EGXLl3w8/Nj3bp1/PLLL4wYMQJTU1OloDJ16lQWLVqEkZERhoaG/Pnnn8yaNYu5c+fqrXKh0+kYMGAAly5d4tChQw/9RHzLli0sXryYjRs30rBhQ27cuKEMI/n666954YUXGDlyJCNGjFCOiYuLY9iwYcydO5cePXqwe/fuYnta3N8u3X1PxqmpqQAYGeVgbJxV4rHi0ZiY5GBiYkxOTg5ZWYVjXLCtqPfE0yE5UJfEX32SA3VJ/NUnOVCf5EBdTyv+mrwH+3kL8YR4eHiQk5OjPPQDtGjRgpdffpl58+aVeQLLgQMH8ueff7J3715ln0mTJrFz507Onj1bYlu+/vprhgwZwtWrV7GysiqyrQ9OthkUFMSWLVtITExUltFcsWIFkydP5s6dO9y7d49KlSoxc+ZMevfuXeicV69exdPTk0OHDhESEoJOp2PHjh3Y2NiU2FaAjz76iFWrVnHmzJkil9RxcXHB398ff39/ZZuvry937txh586dyrb+/fuze/duUlJSirxOSEgIM2fOLLQ9KioKc3Pzh7ZTCCGEEEII8WxKT09XnjHKYwU46RkhypW7u7vea0dHR5KTkwvt17lzZ6Vo4ezsXGRxITExkddff11vW9u2bQkLCyMnJwdDQ8Ni29GpUyecnZ2pVasWPj4++Pj40LNnzxIfuBMTE2ndurVSiCi4XlpaGlevXuXGjRvodDr69u1LzZo1Cx1fMJRjwIABVK9enf3792NmZlbs9e7Xp08fwsLClPZ26dKFbt26Kecsrr09e/bU29a6desS54yYOnWqMlkn5PeMcHJyIjKyDubmTUrVVlE26ekXSUmZwrp184r8vsnKyiI6OppOnTrJutoqkRyoS+KvPsmBuiT+6pMcqE9yoK6C+Ht6epbrdaQYIcrVg788NBqN3vCFAp999pmyBGV5/MKxsrLi5MmTHDhwgL179xIcHExISAjHjx9/5GVDS1tY6NKlCxs2bODHH3/k5ZdfLtUxTk5OnDt3ju+//57o6GjGjh3LwoUL+eGHH55ofLRaLVqtttD2u3dvkpl5+YldR/x/GRnXyMzMwtDQsMRcGhsbyx9flUkO1CXxV5/kQF0Sf/VJDtQnOVBXecdeihHiX6FatWoP3cfNzY3Y2Fi9bbGxsbi6upbYK6KAkZERXl5eeHl5MWPGDGxtbdm/fz+9evXCxMSEnJycQtfbsmULeXl5Su+I2NhYrKysqF69OpUrV8bMzIx9+/YxfPjwYq87ZswYGjVqRPfu3dm5cycdO3Z8aFshv9jRrVs3unXrxrhx46hfvz6nT5+mWbNmxbY3Li5Ob9vRo0dLda0H6XSr+L/akCgH9vbacunqJoQQQgghxH+FFCPEf8Z7773HSy+9xOzZs+nXrx8//vgjH3/8MStWrHjosTt27OC3336jQ4cOVKhQgV27dpGbm0u9evWA/DkY4uLiuHTpEpaWltjZ2TF27FjCwsJ4++23GT9+POfOnWPGjBkEBARgYGCAqakpkydPZtKkSZiYmNC2bVv+/PNPzp49y7Bhw/Su//bbb5OTk0PXrl357rvvHrrKRUREBDk5ObRs2RJzc3M2bNiAmZkZzs7OSnsPHjxI//790Wq1VKxYkQkTJtC2bVsWLVrE66+/zp49ex5pWU+A4OARWFpaPtKxojBLS0vs7e2V19bW1rKspxBCCCGEeK5JMUL8ZzRr1owvv/yS4OBgZs+ejaOjI7NmzSq0ksaPP/5Iu3bt8PHxUSZztLW15euvv2batGmkp6ej0WgwMTGhb9++dOrUiYkTJzJ48GBcXV3JyspSlvbctWsX48ePZ/ny5Wi1Wt5++23ef/995VrTp0/HyMiI4OBgrl27hqOjI6NHjy6y/f7+/uTm5tKlSxd2795NmzZtir1XW1tb5s2bR0BAADk5OTRu3Jhvv/1WeaCdNWsWo0aNonbt2uh0OvLy8mjVqhWrV69mxowZBAcH4+Xlxfvvv8/s2bPLHOtZs1ZTxGga8Yjs7bVERa2UAoQQQgghhBD/R1bTEM+c4cOHY2lpyZo1azh37hxVq1YFYN++fXTu3JkPPviA7t27o9FoSEhIIDo6muXLlwP5PRL8/f2V1SeOHz9O586d6dmzJ6tWrcLAwECt23oqUlNTsbGxoU2bb9Fq3dRuzjMhI+MKOl0oX30VRu3atR+6f1ZWFrt27aJLly4yRlIlkgN1SfzVJzlQl8RffZID9UkO1FUQ/3bt2lGxYkVZTUOI0khLS2PTpk2cOHGCGzduEBERwbRp0wD49ttvadu2LYGBgcr+rq6uxS4tun//fl5//XXGjh3L/PnzS3X9kJAQtm3bxoQJEwgJCeHvv/9m0KBBLFu2jNDQUD766CNyc3N55513CAoKUo5LSUlh4sSJbN++HZ1OR/PmzVm8eDEvvPACAElJSQQEBHD06FHu3buHm5sbc+fOxcvLSzmHi4sLI0eO5MKFC3z11VdUqFCB999/n5EjRxbbXp1Oh06nU16npqYCYGVVBXPzGqW6Z1EyE5McUlKMycnJKdVazbKutvokB+qS+KtPcqAuib/6JAfqkxyo62nFX3pGiGfCoUOH6Ny5M1lZWWRnZ2NmZkZ2djaZmZmYmZlx79495s2bx0cffcT+/ftp1KhRkecp6BkRHh6Or68vISEhTJ48udTtCAkJITQ0FB8fH2bOnElSUhJvvPEGnp6euLq6Mm7cOI4cOcLQoUMxNTVVJt7MyMhAo9FgbGxMtWrV6NGjBxEREfz666/Y2dlx6tQpjh49Stu2bdFqtaxbt45FixZx7tw5atTILxq4uLhw9+5dZs+ezauvvsrmzZsJCgoiISFBmRujqPbOnDmz0PaoqKgSlz0VQgghhBBCPNvS09Px9fUtt54RUowQz4SMjAz++OMP+vXrR+fOnfHz8yM7O5s2bdqwbNkyBg4cyL179+jbty+7du3C2dmZVq1a8eqrrzJw4EBlecuIiAhlZYxp06Yxa9asMrUjJCSEhQsXcuPGDaysrADw8fHh3LlzJCUlKcM8XF1def311xk1ahQnTpxgxIgRHD16FK1Wi7GxMc7OztSpU4dJkyYV27OhUaNGjB49mvHjxwP5xYj27duzfv16APLy8nBwcGDmzJnFzmNRVM8IJycnvL2PYW7epEz3LoqWnn6RlJQprFs3j5o1az50f1lXW32SA3VJ/NUnOVCXxF99kgP1SQ7UVRD/li1b4ujoKMM0hCiJmZkZOTk5/O9//+O7776jcuXKAPj6+rJ7924GDhyIhYUFO3fuJCkpiZiYGI4ePcp7773HkiVL+PHHH5WeAGZmZrRr147Vq1czYMAA3NzKNneCi4uLUogAqFKlCoaGhnrzTTg6OpKTk0OdOnXYs2cP6enptGzZUu88GRkZJCUlAfnDT0JCQti5cyfXr18nOzubjIwMLl++rHeMu7u78rVGo8HBwYHk5ORi26rVapVCzP2ysw3JypJf/E9CZqYhmZlZGBoalumPqayrrT7Jgbok/uqTHKhL4q8+yYH6JAfqKu/YSzFCPDPWrFlDdna2MmEl5PcO0Gq1fPzxx9jY2ABQu3ZtateuzfDhwwkKCsLV1ZVNmzYxZMgQAAwNDdm2bRu9evXC09OTmJiYMhUkHvyhLRh+8eC23P9briItLQ1HR0cOHDhQ6Fy2trYATJw4kejoaBYtWkSdOnUwMzPjjTfeIDMz86HXzn2EZTEyMq6Rm2tT5uNEYRkZV9RughBCCCGEEP86UowQz4Ts7GzWrVtHaGgor776qt57PXr04IsvvihyqIKLiwvm5ubcu3dPb7tWq+Xrr79W5nvYv38/DRo0KJe2N2vWjBs3bmBkZISLi0uR+8TGxuLn50fPnj2B/ALGpUuXyqU9ADrdKjIyyu30zx17e225dG0TQgghhBDiv0qKEeKZsGPHDm7fvs2wYcOUHhAFevfuzZo1a7hx4wbp6el06dIFZ2dnUlJSWLp0KVlZWXTq1KnQObVaLVu2bKFPnz5KQaJhw4YPbcu9e/cwNDTEx8eHnTt3KtsvXbpEzZo1MTAwoEWLFsp2Ly8vXnzxRWU+gUOHDmFgYMCAAQP0hmGcOXOG4OBg5bWZmRkAfn5+REZGKr0oCmzbto1Tp04Vu1pISYKDR2BpaVnm40RhlpaW1KxZk0qVKqndFCGEEEIIIf41pBghnglr1qzBy8urUCEC8osRCxYs4M033+TMmTMMGjSImzdvUqFCBZo2bcrevXuLXW3CxMSEzZs307dvX6UgUdxKHAX+/vtv3n77bdasWcO1a9cKvV+tWjVu3rypvNZoNHTp0oXExETu3r2Lp6cnjo6OtGzZkq+//ppq1apx5coV/P39+emnn8jNzcXR0RFnZ2flHKampqSmppKenl7akJVo1qzVPMLoDlEEe3stUVEr1W6GEEIIIYQQ/ypSjBDPhG+//bbY91q0aEHBojHvvPNOiefx8/PDz89Pb5uxsTFbt24tVTsmTpxIaGgoY8aM4caNG0RERBAREQGgDKsYPHgwmzZtIiwsTDkuKioKf39/Zs+ezfnz5wsN13BwcCA2NpYRI0awY8cOYmNjqV69utJmLy8vLly4QEpKSqE2hYSElKrt99NqR6HVlm3iTlFYRsYVbt0KJTU1VXpGCCGEEEIIcR8pRgjxBH355ZfUr1+fevXq8eabb+Lv78/UqVPRaDTKPt27d+eTTz7h8OHDtGvXjsOHD3P79m26devG7Nmziz33ihUrWLduHTExMUohooChoSEffvghvr6+TJgwodD7xSlqaU8AK6sqmJvXKMutiyKYmOSQkmJMTk4OWVlZpTqmYL/S7i+ePMmBuiT+6pMcqEvirz7JgfokB+p6WvHX5BV8ZCyEeKiGDRvy+++/F/neqlWrWLFiBX379uWdd94hOzsbR0dHvvrqKzw8PJQ5I37++WciIyO5c+cOa9euZejQodja2jJo0CCaNm3KxYsXC/WMOHjwIF5eXqxYsYLhw4frvefn50dKSgrbtm2jdevWNGjQgDVr1rBt2zZ69uxJST/iISEhzJw5s9D2qKgoZalTIYQQQgghxPMnPT0dX19f7ty5Uy6TsUsxQogy+P3334utEKamptKyZUv++OMPKleuDMD48eO5c+cO69ev1ytGGBoa0qZNG86fP0/dunX58ccfyc7OLrIYcfnyZZo3b07fvn35+OOPC133/mLEwYMHefnllzl9+jTnzp17aDGiqJ4RTk5OeHsfw9y8yaMFSSjS0y+SkjKFdevmKROUPkxWVhbR0dF06tRJ1tVWieRAXRJ/9UkO1CXxV5/kQH2SA3UVxL9ly5Y4OjqWWzFChmkIUQb3Txr5oEmTJpGdnU3VqlWVbXl5eWi12kJFhMaNG1O/fn0GDBiAm5sbjRo1Ij4+vtA5MzIy6NmzJw0bNtSbY6I4HTp0wNvbm6lTpxaa+6IoWq0WrVZbaHt2tiFZWfKL/3FlZhqSmZmFoaFhmf+QGhsbyx9flUkO1CXxV5/kQF0Sf/VJDtQnOVBXecdeihFCPAHZ2dmsW7eO0NBQXn31Vb33evTowRdffIGPj4/e9qFDhzJ27FhWrix+pYXhw4fz999/s2fPHoyMSvfjOm/ePJo0aVLsCiGlkZFxjdzcwiuTiLLJyLiidhOEEEIIIYT4V/pPFCM0Gg1bt26lR48eajelWAcOHMDT05Pbt29ja2tLREQE/v7+yuoGISEhbNu2rchPv8W/i4eHB02aNClVT4QCO3bs4Pbt2wwbNqzQ8qK9e/dmzZo1hYoRI0aMoE+fPtja2hZ5zoULF/LVV1/x7bffkp2dzY0bN/Tet7GxwczMrNBxjRs3ZuDAgSxdurTU7X9QWloYKSmytufjMjAwwsHBuly6tQkhhBBCCPFfZlAeJw0JCUGj0ej9q1+/fnlc6j9j4sSJ7Nu3T+1mlIpGo2Hbtm1qN+OhIiIiin2Qf9rWrFmDl5dXoUIE5BcjTpw4oaxUUcDIyIiKFSsW2+NhxYoVZGVl4ePjg6OjY6F/mzZtKrY9s2bNIjf3cYoJBuTXKuXf4/yzsTFi6dLZsqynEEIIIYQQDyi3nhENGzbk+++///8XKmUX83+bvLw8cnJyHrv9lpaWWFpaPqFWPZqsrKynOuYqMzMTExOTp3Y9NX377bfFvteiRQtlEsmSJpNs0qSJ3vsXL14s1bUjIiIKbXNxcdGbmLKsLC0noNW6PfLxIn+IRnp66HPzMyCEEEIIIURZlEvPCMgvPjg4OCj/KlasWKrjzp8/T4cOHTA1NaVBgwZER0cX2mfy5Mm4urpibm5OrVq1mD59urLCwaVLlzAwMODEiRN6x4SFheHs7PzQT4sPHDiARqPhu+++48UXX0Sr1XL48GF0Oh0TJkygcuXKmJqa0q5dO44fP17KaOT3FmnSpIny2s/Pjx49erBo0SIcHR2xt7dn3Lhxeis1XL9+nddeew0zMzNq1qxJVFQULi4upR4+oNFoWLlyJd27d8fCwoIPPvgAgO3bt9OsWTNMTU2pVasWM2fOJDs7G0BZxaFnz55oNBrldUF77+fv74+Hh4fy2sPDg/Hjx+Pv70/FihXx9vZW4rlv3z6aN2+Oubk5bdq04dy5c6W6h1OnTuHp6YmVlRXW1ta8+OKLnDhxggMHDjBkyBDu3Lmj9L4JCQkB4Pbt2wwaNIgKFSpgbm5O586dOX/+vN55Y2Nj8fDwwNzcnAoVKuDt7c3t27eLbMPOnTuxsbHh888/f2h7C+L04YcfUqVKFWxtbZk1axbZ2dkEBgZiZ2dH9erVCQ8P1zvuypUr9O3bF1tbW+zs7Hj99de5dOmS8v7x48fp1KkTFStWxMbGho4dO3Ly5Em9c2g0Gj777DN69uyJubk5devW5ZtvvilFlAszM6uKhUVt+fcY/8zMnB4p9kIIIYQQQjwPyq27wvnz56latSqmpqa0bt2auXPnUqNGjRKPyc3NpVevXlSpUoW4uDju3LmDv79/of2srKyIiIigatWqnD59mhEjRmBlZcWkSZNwcXHBy8uL8PBwmjdvrhwTHh6On58fBgalq79MmTKFRYsWUatWLSpUqMCkSZPYsmULkZGRODs7s2DBAry9vblw4QJ2dnZlik2BmJgYHB0diYmJ4cKFC/Tr148mTZowYsQIAAYNGsRff/3FgQMHMDY2JiAggOTk5DJdIyQkhHnz5hEWFoaRkRGHDh1i0KBBLF26lPbt25OUlMTIkSMBmDFjBsePH6dy5cqEh4fj4+ODoaFhma4XGRnJmDFjiI2NBfILKgBBQUGEhoZSqVIlRo8ezdChQ5V9SjJw4ECaNm3KypUrMTQ0JD4+HmNjY9q0aUNYWBjBwcFKYaOg54mfnx/nz5/nm2++wdramsmTJ9OlSxcSEhIwNjYmPj6eV155haFDh7JkyRKMjIyIiYkhJyen0PWjoqIYPXo0UVFRdO3atVQx2L9/P9WrV+fgwYPExsYybNgwjhw5QocOHYiLi2PTpk2MGjWKTp06Ub16dbKysvD29qZ169YcOnQIIyMj5syZg4+PD//73/8wMTHh7t27DB48mGXLlpGXl0doaChdunTh/PnzWFlZKdeeOXMmCxYsYOHChSxbtoyBAwfy+++/F/s9WtTSngBGRjkYGxe9hKkoHROTHExMjMnJySl2OdiiFOxblmPEkyU5UJfEX32SA3VJ/NUnOVCf5EBdTyv+mryS+o0/ou+++460tDTq1avH9evXmTlzJn/88QdnzpzRe3B60N69e3nttdf4/fffleURd+/eTefOnUucwHLRokVs3LhR6Q3x5ZdfMnr0aK5fv45Wq+XkyZM0b96c3377TfmkvzgFE1Fu27aN119/HYB79+5RoUIFIiIi8PX1BfIT4+Ligr+/P4GBgWWewNLPz48DBw6QlJSkPPD37dsXAwMDNm7cyC+//IKbmxvHjx9XiioXLlygbt26LF68uMgizYM0Gg3+/v4sXrxY2ebl5cUrr7zC1KlTlW0bNmxg0qRJXLt2TTnuwXj7+fmRkpKiN5eEv78/8fHxHDhwAMjvGZGamqr3iX1BXL7//nteeeUVAHbt2sVrr71GRkYGpqamJd6DtbU1y5YtY/DgwYXeezDGkF8Ec3V1JTY2ljZt2gBw69YtnJyciIyMpE+fPvj6+nL58mUOHz5c5DULJrCsW7cuQUFBbN++nY4dO5bYzgIFef3tt9+Uwlf9+vWpXLkyBw8eBCAnJwcbGxs+++wz+vfvz4YNG5gzZw6JiYloNBogf4iLra0t27ZtK7Q6B+QX7mxtbfWKJBqNhvfff5/Zs2cD+d+3lpaWfPfdd4UmzywQEhLCzJkzC22PiorC3Ny8VPcshBBCCCGEePakp6fj6+vLnTt3ymVC9nLpGdG5c2fla3d3d1q2bImzszNffvklw4YNK/a4xMREnJyclEIEQOvWrQvtt2nTJpYuXUpSUhJpaWlkZ2frBadHjx6MGzeOrVu30r9/fyIiIvD09HxoIeJ+9/eqSEpKIisri7Zt2yrbjI2NadGiBYmJiaU+54MaNmyo1/PA0dGR06dPA3Du3DmMjIxo1qyZ8n6dOnWoUKFCma5x/31A/rCH2NhYZcgG5D8c//PPP6Snpz/2A+iLL75Y5HZ3d3fla0dHRwCSk5Mf2lsmICCA4cOHs379ery8vOjTpw+1a9cudv/ExESMjIxo2bKlss3e3p569eopuYqPj6dPnz4lXnfz5s0kJycTGxvLSy+9VOK+D2rYsKFeD5wqVarQqFEj5bWhoSH29vZKL5dTp05x4cKFQoW6f/75h6SkJABu3rzJ+++/z4EDB0hOTiYnJ4f09HQuX76sd8z9cbawsMDa2rrE3jRTp04lICBAeZ2amvp/hZs6mJs3KdN9C33p6RdJSZnCunXzqFmzZqmPy8rKIjo6mk6dOsm62iqRHKhL4q8+yYG6JP7qkxyoT3KgroL4e3p6lut1nsqskra2tri6unLhwoXHPtePP/7IwIEDmTlzJt7e3tjY2LBx40ZCQ0OVfUxMTBg0aBDh4eH06tWLqKgolixZUqbrWFhYPHZbH+bBHyyNRvOYKyAU9uB9pKWlMXPmTHr16lVo35J6KRgYGBSafLGobjvFxe3+ey349L809xoSEoKvry87d+7ku+++Y8aMGWzcuJGePXs+9NjiFLUc5oOaNm3KyZMnWbt2Lc2bN1faXBpF5bWkXKelpfHiiy8WOSdFwSoMgwcP5tatWyxZsgRnZ2e0Wi2tW7cmMzPzodcuKc5arRatVlto+927N8nMvFzEEaK0MjKukZmZhaGh4SP9ETU2NpY/viqTHKhL4q8+yYG6JP7qkxyoT3KgrvKO/VMpRqSlpZGUlMRbb71V4n5ubm5cuXKF69evK5+eHz16VG+fI0eO4OzsTFBQkLLt999/L3Su4cOH06hRI1asWEF2dnaRD9+lVbt2bUxMTIiNjcXZ2RnIfxA/fvx4qYZLPIp69eqRnZ3Nzz//rPQ2uHDhQrGTLJZWs2bNOHfuHHXq1Cl2H2Nj40LzJ1SqVIkzZ87obSuYv6G8ubq64urqyrvvvsuAAQMIDw+nZ8+emJiYFGqnm5sb2dnZxMXF6Q3TOHfuHA0aNADyew/s27evyOEJBWrXrk1oaCgeHh4YGhry8ccfl9v9NWvWjE2bNlG5cuViuz/FxsayYsUKunTpAuRPePnXX3+VW5t0ulVkZJTb6Z8b9vbacunSJoQQQgghxH9duRQjJk6cSLdu3XB2dubatWvMmDEDQ0NDBgwYUOJxXl5euLq6MnjwYBYuXEhqaqpe0QGgbt26XL58mY0bN/LSSy+xc+dOtm7dWuhcbm5utGrVismTJzN06NBSfRpeHAsLC8aMGaOshlCjRg0WLFhAenp6icNOHkf9+vXx8vJi5MiRrFy5EmNjY9577z3MzMzK9Cn9g4KDg+natSs1atTgjTfewMDAgFOnTnHmzBnmzJkD5K+osW/fPtq2bYtWq6VChQq8/PLLLFy4kHXr1tG6dWs2bNjAmTNnaNq06ZO65UIyMjIIDAzkjTfeoGbNmly9epXjx4/Tu3dvpZ1paWns27ePF154QVlB4vXXX2fEiBGsWrUKKysrpkyZQrVq1ZQ5QKZOnUrjxo0ZO3Yso0ePxsTEhJiYGPr06aO36ourqysxMTF4eHiwbt06Zs2aVS7Fp4EDB7Jw4UJef/11Zs2aRfXq1fn999/5+uuvmTRpEtWrV6du3bqsX7+e5s2bk5qaSmBg4EO/py9dusSdO3cKDeUojeDgEaovRftfY2lpib29vd42a2trpXeLEEIIIYQQ4v8rl2LE1atXGTBgALdu3aJSpUq0a9eOo0ePPvQ/5QYGBmzdupVhw4bRokULXFxcWLp0qd7ke927d+fdd99l/Pjx6HQ6XnvtNaZPn64s63i/glUMhg4d+tj3NG/ePHJzc3nrrbe4e/cuzZs3Z8+ePWWew6Es1q1bx7Bhw+jQoQMODg7MnTuXs2fPPnTSx5J4e3uzY8cOZs2axfz58zE2NqZ+/foMHz5c2Sc0NJSAgABWr15NtWrVuHTpEt7e3kyfPp1Jkybxzz//MHToUAYNGqTMcVEeDA0NuXXrFoMGDeLmzZtUrFiRXr16KT0a2rRpw+jRo+nXrx+3bt1ixowZhISEEB4ezjvvvEPXrl3JzMykQ4cO7Nq1S+nF4erqyt69e5k2bRotWrTAzMyMli1bMmDAACIiIjh8+LCyDGu9evXYv38/HTp04LfffiuX+zQ3N+fgwYNMnjyZXr16cffuXapVq8Yrr7yifKq+Zs0aRo4cSbNmzZScVa5cuVzaAzBr1mqe8IihZ569vZaoqJVSfBBCCCGEEKIUymU1jX+L2bNn89VXX/G///1P7aY8EVevXsXJyUlvZYpnSWZmJiYmJqq2oagVOv5tilrZpCiXLl2iZs2a/Pzzz0px5WFSU1OxsbGhTZtv0WrdHr+xz4mMjCvodKF89VVYiROslkZWVha7du2iS5cuMkZSJZIDdUn81Sc5UJfEX32SA/VJDtRVEP927dpRsWLFcltNw+Dhu/z3pKWlcebMGT7++GPefvtttZvzyPbv388333zDxYsXOXLkCP3798fFxYUOHTqo3bRS8fDwYPz48YwfPx4bGxsqVqzI9OnTlYkwXVxcmD17NoMGDcLa2pqRI0cC+fMjeHh4YG5uToUKFfD29i7VXBk6nY4JEyZQuXJlTE1NadeuHcePH1feP3DgABqNhp07d+Lu7o6pqSmtWrVS5sI4cOAAQ4YM4c6dO2g0GjQajdLjxsXFhbCwMOVcly9f5vXXX8fS0hJra2v69u3LzZs3lfdDQkJo0qQJ69evx8XFBRsbG/r378/du3dLFbvNmzfTuHFjzMzMsLe3x8vLi3v37hESEkJkZCTbt29X2liwtOqxY8do2rQppqamNG/enJ9//rlU1yqKmVlVLCxqy79S/jMzc3rkWAshhBBCCPE8eioTWBb4/PPPGTVqVJHvOTs7c/bs2SdynfHjx/PFF1/Qo0ePQkM0Ro8ezYYNG4o87s033+STTz55Im14ErKyspg2bRq//fYbVlZWtGnThs8//xxjY+OnFsvHFRkZybBhwzh27BgnTpxg5MiR1KhRgxEjRgD5D+1GRkYYGhry5ZdfsmnTJv755x+MjIyYOXMmr7/+OjExMYUmqizKpEmT2LJlC5GRkTg7O7NgwQK8vb25cOECdnZ2yn6BgYEsWbIEBwcHpk2bRrdu3fj1119p06YNYWFhBAcHc+7cOYBC8yZYWlqSl5fHP//8A6BMorllyxbOnz+vVwBISkpi27Zt7Nixg9u3b9O3b1/mzZunt6xqUa5fv86AAQNYsGABPXv25O7duxw6dIi8vDwmTpxIYmIiqamphIeHA2BnZ0daWhpdu3alU6dObNiwgYsXL/LOO+88NGY6nQ6dTqe8Tk1NBcDIKAdj48KrpYiimZjkYGKSP/FrUavMlEXB8Y97HvHoJAfqkvirT3KgLom/+iQH6pMcqOtpxf+pDtO4e/eu3qfH9zM2NlZWqihPycnJygPXg6ytrct1HP6T9G+I5cN4eHiQnJzM2bNnlUk3p0yZwjfffENCQgIuLi7Uq1eP5cuXK8e8++67XL9+nY0bN1KlShWsrKxKda179+5RoUIFIiIi8PX1BfJ/eFxcXPD39ycwMJADBw7g6enJxo0b6devHwB///031atXJyIigr59+xY7TKPgPF27duXw4cMMHz6cmJgYZdWX8+fP06VLF44dO8ZLL71ESEgICxcu5MaNG8o9TJo0iYMHDxZaIeZBJ0+e5MUXX+TSpUtF5rGoYRqffvop06ZN4+rVq8qcIp988gljxowpcZhGSEhIkauKREVFYW5uXmI7hRBCCCGEEM+u9PR0fH19y22YxlPtGWFlZVXqh8vyUrly5f9MwaEk/4ZYlkarVq30Vv9o3bo1oaGhSk+HDh066C0zmpSURJ8+fUpcerQoSUlJZGVl0bZtW2WbsbExLVq0IDExUW/f1q1bK1/b2dlRr169QvsUp06dOuzatQsnJyfat2+vt93W1pbExEReeuklIL+AcX+OHB0dSU5Ofug1XnjhBV555RUaN26Mt7c3r776Km+88UaJk6UmJiYqQ0+Kus/iTJ06lYCAAOV1amoqTk5OREbWwdy8yUOPF/nS0y+SkjKFdevmUbNmzcc6V1ZWFtHR0XTq1EnGSKpEcqAuib/6JAfqkvirT3KgPsmBugri7+npWa7XearFCCEeZGFhoff6cZZg/bd58BenRqMhtxRLVBgaGhIdHc2RI0fYu3cvy5YtIygoiLi4uMd+0H2QVqtFq9UW2n737k0yM8u+JOjzKiPjGpmZWRgaGj6xP5jGxsbyx1dlkgN1SfzVJzlQl8RffZID9UkO1FXesZdihChXcXFxeq+PHj1K3bp1MTQ0LHJ/d3d39u3bV+TQgZLUrl0bExMTYmNjlaENWVlZHD9+HH9//0JtqFGjBgC3b9/m119/xc0tf+WIgjkgSuLm5saVK1e4cuUKTk75ExcmJCSQkpJCgwYNytTu4mg0Gtq2bUvbtm0JDg7G2dmZrVu3EhAQUGQb3dzcWL9+Pf/884/SO+Jhw0FKotOtIiPjsW7huWNvry2X7mtCCCGEEEI8i6QYIcrV5cuXCQgIYNSoUZw8eZJly5YRGhpa7P5Tp06lcePGjB07ltGjR2NiYkJMTAx9+vShYsWKxR5nYWHBmDFjCAwMxM7Ojho1arBgwQLS09MZNmyY3r6zZs3C3t6eKlWqEBQURMWKFenRoweQP7QiLS2Nffv28cILL2Bubl5o7gQvLy8aN27MwIEDCQsLIzs7m7Fjx9KxY0eaN2/+6MH6P3Fxcezbt49XX32VypUrExcXx59//qkUTFxcXNizZw/nzp3D3t4eGxsbfH19CQoKYsSIEUydOpVLly6xaNGiR25DcPCIQpN3isIsLS2xt7cH8uecqVSpksotEkIIIYQQ4r9BihGiXA0aNIiMjAxatGiBoaEh77zzjrKEZ1FcXV3Zu3cv06ZNo0WLFpiZmdGyZUsGDBjw0GvNmzeP3Nxc3nrrLe7evUvz5s3Zs2dPobkW5s2bxzvvvMP58+dp0qQJ3377LSYmJgC0adOG0aNH069fP27dusWMGTOU5T0LaDQatm/fzttvv02HDh0wMDDAx8eHZcuWFdmu++fMKOp1wTW2bt3K/PnzOXv2LBkZGQQHBwP5vT5CQ0O5efMmtra2nD9/ngMHDtC8eXPS0tKIiYnBw8ODb7/9ltGjR9O0aVM0Gk2pViApzqxZqynFiJLnnr29lqiolVKEEEIIIYQQooykGCHKlbGxMWFhYaxcubLQe5cuXSrymI4dOxIbG1vma5mamrJ06VKWLl1a4n7t2rXjzJkzxb6/cuXKQu19sK01atRg+/btxZ4jJCREKWJcv35d2b5p0ya9pUMh/9P1ffv20a9fPz744AMiIyPRaDQkJCQQHR2trDYSEREBQKVKldi7d2+ha7Zq1Yr4+HgOHz7MwIEDadeuHe7u7sWupFESrXYUWq1bmY97nmRkXOHWrVBSU1OlGCGEEEIIIUQZSTFCiHLm4OCgfG1jY4NGo9HbBvDtt9/Stm1bAgMDlW2urq7K8JGyWLNmDb6+vnTs2JF33nmHyZMnF7uvTqdDp9MprwuWvbWyqoK5eY0yX/t5YmKSQ0qKMTk5OU90DWZZV1t9kgN1SfzVJzlQl8RffZID9UkO1PW04i/FCPGfcPny5RInh0xISFAmpfy3y8vLKzQfQ2ZmJllZWZibm/PLL7888r3cvXuXr776iri4OOrXr8+dO3c4dOiQ3jKk95s7d26Rk4UOHnwBc/Nrj9SG58tgEhMTS700bFlER0c/8XOKspEcqEvirz7Jgbok/uqTHKhPcqCumJiYcj2/FCNEuTlw4MATO1fVqlWJj48v8f2H8fDwIC8v74m16VFpNJpC95Kens6ECRP44Ycf6NChA61ateLVV19l4MCBRS69WZyNGzdSt25dGjZsCED//v1Zs2ZNscWIqVOnEhAQoLxOTU3FycmJyMg6mJs3KfO9PU/S0y+SkjKFdevmPdElV2VdbfVJDtQl8Vef5EBdEn/1SQ7UJzlQV0H8PT09y/U6UowQ/wlGRkbUqVNH7WY8MUXdy4EDB0hKSiImJoajR4/y3nvvsWTJEn788cdCK3oUZ+3atbz55pvK6zfffJOOHTuybNkyrKysCu2v1WqLLHZkZxuSlSW/+EuSmWlIZmYWhoaG5fJHUtbVVp/kQF0Sf/VJDtQl8Vef5EB9kgN1lXfspRghxL9I7dq1qV27NsOHDycoKAhXV1c2bdrEkCFDHnpsQkICR48e5dixY3rzROTk5LBx40ZGjBhR6nZkZFwjN9fmke7heZGRcUXtJgghhBBCCPGfJcUIIf6lXFxcMDc35969e6Xaf82aNXTo0EFZfaNAeHg4a9asKVMxQqdbRUZGmZr7XLK312Jtba12M4QQQgghhPjPea6KERqNhq1btz7SCgVPy4EDB/D09OT27dvY2toSERGBv78/KSkpQP6Skdu2bStx/gTx7+Dh4UGTJk0ICwt76L4hISGkp6fTpUsXnJ2dSUlJYenSpWRlZdGpUydlv5ycnEK512q11KlTh/Xr1zNr1iwaNWqkvKfRaFi6dCkfffQRZ8+eVeaSeJjg4BGFJtkUhTk6OsqynkIIIYQQQjyCf3UxIiQkpNBM//Xq1eOXX35RqUXqmzhxIm+//bbazSiV/0LxByhU8FFDx44dWb58OYMGDeLmzZtUqFCBpk2bsnfvXurVq6fsl5aWRtOmTfWOrV27NvPnz+fWrVv07Nmz0LmdnJxwc3NjzZo1fPTRR6Vqz6xZq8nNfbx7eh7Y22uJilopBQkhhBBCCCHK6F9djABo2LAh33//vfLayOhf3+Qi5eXlkZOT89jtt7S0VP0T66ysrKc6kUxmZiYmJiZP7Xrlyc/PDz8/v0LbPT09HzpbbcGxxfWOycnJKfbYhISEMrVTqx2FVutWpmOeNxkZV7h1K5TU1FQpRgghhBBCCFFG//oneyMjIxwcHMp83Pnz5xk2bBjHjh2jVq1aLFmypNA+kydPZuvWrVy9ehUHBwcGDhxIcHAwxsbGXLp0iVq1anHs2DGaN2+uHBMWFsbixYu5ePEiBgYGxV6/YLjFrl27eP/99zl9+jR79+6ldevWBAYGsnHjRlJTU2nevDmLFy/mpZdeKtV9Pfgg6ufnR0pKCu3atSM0NJTMzEz69+9PWFiYUjC4fv06w4cPZ//+/Tg4OPDBBx8wbdo0/P398ff3f+g1NRoNK1as4LvvvmPfvn0EBgYSEhLC9u3bmTlzJgkJCVStWpXBgwcTFBSEkZERLi4uAMon9c7Ozly6dElp77Zt25Tz+/v7Ex8frywF6uHhQaNGjTAyMmLDhg00btyYGTNm4Onpyffff8/kyZNJSEigSZMmhIeH6/UcKM6pU6fw9/fnxIkTaDQa6taty6pVq0hLS1Mmh9RoNADMmDGDkJAQbt++zTvvvMO3336LTqejY8eOLF26lLp16yrnjY2NJSgoiGPHjqHVamnRogUbN26kQoUKhdqwc+dOfH19WbFiBQMHDiyxvQcOHGDSpEmcPXsWY2NjGjZsSFRUFDExMUpvoYL2hoeH4+fnV6rv+QfpdDp0Op3yOjU1FQArqyqYm9d46PHPMxOTHFJSjMnJySErK+uJnbfgXE/ynKJsJAfqkvirT3KgLom/+iQH6pMcqOtpxf9fX4w4f/48VatWxdTUlNatWzN37lxq1Cj5ISk3N5devXpRpUoV4uLiuHPnTpEP3VZWVkRERFC1alVOnz7NiBEjsLKyYtKkSbi4uODl5UV4eLheMaLgwa+kQsT9pkyZwqJFi6hVqxYVKlRg0qRJbNmyhcjISJydnVmwYAHe3t5cuHABOzu7MsWmQExMDI6OjsTExHDhwgX69etHkyZNlAkLBw0axF9//cWBAwcwNjYmICCA5OTkMl0jJCSEefPmERYWhpGREYcOHWLQoEEsXbqU9u3bk5SUxMiRI4H8h/njx49TuXJlwsPD8fHxwdDQsEzXi4yMZMyYMcTGxgL5BRWAoKAgQkNDqVSpEqNHj2bo0KHKPiUZOHAgTZs2ZeXKlRgaGhIfH4+xsTFt2rQhLCyM4OBgzp07B6D0PCl4wP/mm2+wtrZm8uTJdOnShYSEBIyNjYmPj+eVV15h6NChLFmyBCMjI2JiYorsoRAVFcXo0aOJioqia9euJbY1OzubHj16MGLECL744gsyMzM5duwYGo2Gfv36cebMGXbv3q30GLKxsSn19/yD5s6dW2goFMDgwRcwN7/20OPFYBITE0lMTHziZ46Ojn7i5xRlIzlQl8RffZIDdUn81Sc5UJ/kQF0xMTHlev5/dTGiZcuWREREUK9ePa5fv87MmTNp3749Z86cwcrKqtjjvv/+e3755Rf27NlD1apVAfjwww/p3Lmz3n7vv/++8rWLiwsTJ05k48aNTJo0CYDhw4czevRoPvroI7RaLSdPnuT06dNs37691Pcwa9YsZQLCe/fusXLlSiIiIpS2rF69mujoaNasWUNgYGCpz3u/ChUq8PHHH2NoaEj9+vV57bXX2LdvHyNGjOCXX37h+++/5/jx40pR5bPPPtP7dL80fH199ZaXHDp0KFOmTGHw4MEA1KpVi9mzZzNp0iRmzJihdFu3tbV9pJ4tdevWZcGCBcrrgmLEBx98QMeOHYH8Qs9rr73GP//8g6mpaYnnu3z5MoGBgdSvX185fwEbGxs0Go1eOwuKELGxsbRp0waAzz//HCcnJ7Zt20afPn1YsGABzZs3Z8WKFcpxRU0QuXz5coKCgvj222+VtpckNTWVO3fu0LVrV2rXrg2Am9v/HzJhaWlZqMfQ3r17S/U9/6CpU6cSEBCgd20nJyciI+tgbt7koW19nqWnXyQlZQrr1s2jZs2aT+y8WVlZREdH06lTJ1lXWyWSA3VJ/NUnOVCXxF99kgP1SQ7UVRD/hw0jf1z/6mLE/Q9S7u7utGzZEmdnZ7788kuGDRtW7HGJiYk4OTkpD2UArVu3LrTfpk2bWLp0KUlJSaSlpZGdna23TF+PHj0YN24cW7dupX///kRERODp6akMQSiN+3tVJCUlkZWVRdu2bZVtxsbGtGjR4rE+WW3YsKFezwNHR0dOnz4NwLlz5zAyMqJZs2bK+3Xq1ClyGEFJ7r8PyB/2EBsbywcffKBsy8nJ4Z9//iE9PR1zc/NHuRXFiy++WOR2d3d35WtHR0cAkpOTH9pbJiAggOHDh7N+/Xq8vLzo06eP8qBflMTERIyMjGjZsqWyzd7ennr16im5io+Pp0+fPiVed/PmzSQnJxMbG1vqoTh2dnb4+fnh7e1Np06d8PLyom/fvsr9Ftfe0nzPP0ir1aLVagttz842JCtLfvGXJDPTkMzMLAwNDcvlj6SxsbH88VWZ5EBdEn/1SQ7UJfFXn+RAfZIDdZV37P/VxYgH2dra4urqyoULFx77XD/++CMDBw5k5syZeHt7Y2Njw8aNGwkNDVX2MTExYdCgQYSHh9OrVy+ioqJKNQ7/fhYWFo/d1od58JtEo9GQ+4SXQnjwPtLS0pg5cya9evUqtG9JvRQMDAzIy8vT21bUWKTi4nb/vRbMmVCaew0JCcHX15edO3fy3XffMWPGDDZu3Fjk6hOlZWZm9tB9mjZtysmTJ1m7di3NmzdX2vww4eHhTJgwgd27d7Np0ybef/99oqOjadWq1SO3tywyMq6Rm2vzVK71X5WRcUXtJgghhBBCCPGf9Z8qRqSlpZGUlMRbb71V4n5ubm5cuXKF69evK58mHz16VG+fI0eO4OzsTFBQkLLt999/L3Su4cOH06hRI1asWEF2dnaRD9+lVbt2bUxMTIiNjcXZ2RnIfxA/fvx4qcb3P4p69eqRnZ3Nzz//rPQ2uHDhArdv336s8zZr1oxz585Rp06dYvcxNjYuNH9CpUqVOHPmjN62gvkbypurqyuurq68++67DBgwgPDwcHr27ImJiUmhdrq5uZGdnU1cXJwyTOPWrVucO3eOBg0aAPm9NPbt26fMueDi4lJoUtDatWsTGhqKh4cHhoaGfPzxx6Vub9OmTWnatClTp06ldevWREVF0apVq2Lb++D3fMEkoRcvXixTnAB0ulVkZJT5sOeOvb1WrzeVEEIIIYQQonT+1cWIiRMn0q1bN5ydnbl27RozZszA0NCQAQMGlHicl5cXrq6uDB48mIULF5KamqpXdID8OQMuX77Mxo0beemll9i5cydbt24tdC43NzdatWrF5MmTGTp0aKk+DS+OhYUFY8aMITAwEDs7O2rUqMGCBQtIT08vcdjJ46hfvz5eXl6MHDmSlStXYmxszHvvvYeZmVmpP6UvSnBwMF27dqVGjRq88cYbGBgYcOrUKc6cOcOcOXOA/Ifzffv20bZtW7RaLRUqVODll19m4cKFrFu3jtatW7NhwwbOnDlD06ZNn9QtF5KRkUFgYCBvvPEGNWvW5OrVqxw/fpzevXsr7UxLSyMgIIAjR44oE1lWrFiRN998k3Xr1mFlZcWUKVOoVq0ar7/+OpA/30Ljxo0ZO3asMjnl8ePH+euvv6hYsaJyfVdXV2JiYvDw8MDIyIiwsLAS23vx4kU+/fRTunfvTtWqVTl37hznz59n0KBBAOzevZvExETi4+OpXr06VlZWRX7PL1q06JFjFhw8QvUlZP/NLC0tsbe3x9raWpb1FEIIIYQQ4hH8q4sRV69eZcCAAdy6dYtKlSrRrl07jh49+tD//BsYGLB161aGDRtGixYtcHFxYenSpfj4+Cj7dO/enXfffZfx48ej0+l47bXXmD59OiEhIYXON2zYMI4cOcLQoUMf+57mzZtHbm4ub731Fnfv3qV58+bs2bOnzHM4lMW6desYNmwYHTp0wMHBgblz53L27NmHTvpYEm9vb3bs2MGsWbOYP38+xsbG1K9fn+HDhyv7hIaGEhAQwOrVq6lWrRqXLl3C29ub6dOnM2nSJP755x+GDh3KoEGDlDkuHkVmZmaJ7xsaGnLr1i0GDRrEzZs3qVixIr169VJ6NLRp04bRo0ezfPlyMjMzGTVqFP7+/syaNYvNmzfTpUsXsrOz6dChA7t27VJ6cbi6urJ3716mTZtGixYtMDMzo2XLlsqknverV68e+/fvV3pI3D8c6EHm5ub88ssvREZGcuvWLRwdHRk3bhyjRo0C8pdJvXDhAp6enqSkpCgrvDz4PT9t2jT8/PweKaazZq3mCY/0eabY22uJilophQghhBBCCCEe0b+6GLFx48ZHPtbV1ZVDhw7pbXtwroIFCxbordgAFDlc4o8//qBx48alnoAQwMPDo9D1IH8+haVLl7J06dJSHefn56f3QBkSEqJXMImIiCh0jgc/eXd0dGTXrl3K66tXr5KcnFziEIv7FXUfkF+Q8Pb2Lva4bt260a1bt0LbZ86cWeRykvfLzs5m/PjxrF+/HmNjY8aMGUNubi4ajQYXFxeGDRvG+fPnsbKy4sMPPyQiIoLDhw8zdepUTpw4QcWKFenZsydz587FwsKCmjVr8ttvv3H58mW967zwwgv07t2blStXsnLlSr331q9fz44dO/j444+VXgkP6tixo7K0qIuLCz4+Ptja2uLr60uVKlX0clGnTh1ycnJ44YUXSrz3KlWqMHDgQGU4zd27d4mNjSUjI4OFCxeyYcMGvf0LJlRNSUkhLS0NjUaDlZWVMnzgUWbB1WpHodW6PXzH51BGxhVu3QolNTVVihFCCCGEEEI8on91MUJtaWlpXLp0iY8//lgZevBftH//ftLS0mjcuDHXr19n0qRJuLi40KFDB7WbVqzIyEiGDRvGsWPHOHHiBCNHjqRGjRqMGDECgEWLFhEcHMyMGTOA/JVKfHx8mDNnDmvXruXPP/9k/PjxjB8/nvDwcAYOHMjcuXNJSkpSVtE4e/Ys//vf/9iyZUuRbUhPTycrKws7O7syt3/gwIH06dOHtLQ0ZbjDnj17SE9Pf+ikmdevX2fAgAEsWLCAnj17cvfuXQ4dOkReXh4TJ04kMTGR1NRUwsPDgfzVN9LS0ujatSudOnViw4YNXLx4kXfeeeeh7dTpdOh0OuV1amoqAFZWVTA3L3mFkueViUkOKSn586EUNfnq4yo4Z3mcW5SO5EBdEn/1SQ7UJfFXn+RAfZIDdT2t+GvyivvY+1/s888/V7qsP8jZ2ZmzZ88+kev4+fnxxRdf0KNHD6KiovSWzxw9enShT6gLvPnmm3zyySdPpA1Pwp49e3jvvff47bffsLKyok2bNoSFheHs7PzUYlkWHh4eJCcnc/bsWWVeiylTpvDNN9+QkJCAi4sLTZs21Zvjo0KFCqSlpektU1mw1OjatWsZMmQITZo0oXfv3kyfPh2AadOmsX///kKTmxYYO3Yse/bsKfWQlvsnsMzOzsbR0ZGPPvpImXDV19eX3NxcNm7cWOJ8DGFhYYwYMYJLly4pE53ez8/Pj5SUFGWCSoBPP/2UadOmcfXqVaWtn3zyCWPGjOHnn3+mSZMmRV4rJCSkyF4qUVFRj708qxBCCCGEEOK/Kz09HV9fX+7cuVMuk7b/J3tGdO/enZYtWxb53pNclSEiIqLIYRAAs2bNYuLEiUW+92+bXb+k4RRPK5Zl1apVK70JNlu3bk1oaKiyikTz5s319q9RowaJiYl6Q0oKjm/cuDGQ31th7dq1TJ8+nby8PL744gsCAgKKvP68efPYuHEjBw4ceKS5NYyMjOjbty+ff/45b731Fvfu3WP79u3K0KP4+Phij3VwcGDjxo00btwYb29vXn31Vd54440S5xVJTEzE3d1dr62tW7d+aDunTp2qF4PU1FScnJyIjKyDuXmTh9/ocyg9/SIpKVNYt24eNWvWfOLnz8rKIjo6mk6dOsm62iqRHKhL4q8+yYG6JP7qkxyoT3KgroL4P8pw77L4TxYjrKyssLKyUrUNlStXpnLlyqq24Un4N8TyUVhYWOi9zszMZPTo0UyYMKHQvjVq5A83GDBgAJMnT+bkyZNkZGRw5coV+vXrV2j/RYsWMW/ePL7//nvc3d0fuY0DBw6kY8eOJCcnEx0djZmZmTKJ6sPm64iOjubIkSPs3buXZcuWERQURFxc3BN/+NVqtXq9SQpkZxuSlSW/+IuSmWlIZmYWhoaG5frH0djYWP74qkxyoC6Jv/okB+qS+KtPcqA+yYG6yjv2/8lihHj2xcXF6b0+evQodevW1Rsqc79mzZqRkJBQ4kN+9erV6dixI59//jkZGRl06tSpUEFpwYIFfPDBB+zZs6dQ74uyatOmDU5OTmzatInvvvuOPn36lPoHWqPR0LZtW9q2bUtwcDDOzs5s3bqVgIAATExMlB4iBdzc3Fi/fj3//POP0juiuOEnpZGRcY3cXJtHPv5ZlpFxRe0mCCGEEEII8Z8nxQjxr3T58mUCAgIYNWoUJ0+eZNmyZSUuhzl58mRatWrF+PHjGT58OBYWFiQkJBAdHc3HH3+s7Ddw4EBmzJhBZmYmixcv1jvH/PnzCQ4OJioqChcXF27cuAGApaVliXM8lMTX15dPPvmEX3/9lZiYmFIdExcXx759+3j11VepXLkycXFx/Pnnn7i55a9u4eLiwp49ezh37hz29vbY2Njg6+tLUFAQI0aMYOrUqVy6dIlFixY9UpsB0tLCSEmRtT0LGBgYYWz8/3uQ2Ntr/3XDsYQQQgghhPgvkWKE+FcaNGgQGRkZtGjRAkNDQ9555x1GjhxZ7P7u7u788MMPvP766yxfvhzI711QoUIFKleuzLRp0zh8+LCyGgfkL+MaFRXF/Pnzady4MStXriQzM5M33nhD79xmZmY0bdqU4cOH8+abb5apu9LAgQP54IMPcHZ2pm3btqU6xtramoMHDxIWFkZqairOzs6EhobSuXNnAEaMGMGBAwdo3rw5aWlpxMTE4OHhwbfffsvo0aNp2rQpDRo0YP78+fTu3bvUbdVn8H//BICNjREffTQde3t7ID9HsqynEEIIIYQQj06KEeJfydjYmLCwMFauXFnovUuXLhV5zEsvvcSrr77KzZs3CQ8PR6fTsWvXLsaNG4exsbEyoeO5c+ewtrbm2rVrBAYG8tprr3HhwgUuXbpEZmYm3t7enDp1itmzZ9O2bVusra05evQoixYtomnTpsWuTFFUu9zc3CjrgjVubm7s3r272PcrVarE3r17C21v1apVoYkxH3WxHEvLCWi1bo907LMmI+MK6emh2NvbK8vCCiGEEEIIIR6PFCPEM0er1eLg4ADAmDFj2Lp1K998841SjKhcuTK2trY4ODjg7+9P9+7d+eWXX3B3dycsLIyDBw9y4sQJmjZtqpyzVq1a9OnTh8zMzIde38PDg8aNG2NoaEhkZCQmJibMmTMHX19fxo8fz+bNm6lSpQrLli1TejsAnDlzhsDAQA4dOoSFhQWvvvoqixcvpmLFigDs3r2bOXPmcObMGQwNDWndujVLlixRHpAvXbpEzZo12bJlC8uWLSMuLo66devyySeflGpljfuZmVXFzEwevAvodGq3QAghhBBCiGeLFCPEM8/MzIxbt24V2n7nzh1lqU0TExMAPv/8c7y8vPQKEQCHDh3SKxw8KC0tTe91ZGQkkyZN4tixY2zatEkpivTs2RM/Pz+8vLzo0qUL5ubmaDQa8vLySE9Px9jYmN27d1OhQgUmT55M37592b9/PwD37t0jICAAd3d30tLSCA4OpmfPnsTHx2Ng8P+HVAQFBbFo0SLq1q1LUFAQAwYM4MKFCxgZFf5x1+l06O570k5NTQXAyCgHY+OsEuP6vDAxycHExJicnByysso/JgXXeBrXEkWTHKhL4q8+yYG6JP7qkxyoT3KgrqcVf03eo/bjFuJfyM/Pj5SUFLZt20ZeXh779u2ja9euvP3227z22mt4enoqy4Leu3cPgO7du7N9+3YAzM3NGTFiBEuWLNE7b0ZGBn/88Uex171/FQ8PDw9ycnI4dOgQADk5OdjY2NCrVy/WrVtHdnY2x48fp02bNnz55Zc0bdqU5cuXc+LECcLDw3FxccHIyIirV6/i5OTEuXPncHV1LXTNv/76i0qVKnH69GkaNWqk9Iz47LPPGDZsGAAJCQk0bNiQxMRE6tevX+gcISEhzJw5s9D2qKgozM3NS4y1EEIIIYQQ4tmVnp6Or68vd+7cKZfJ26VnhHjm7NixA0tLS7KyssjNzcXX15eQkBCOHz8O5PdyMDc35+jRo3z44Yd88sknyrHF1ebMzMxKXDb0Qe7u7srXhoaG2Nvb07hxYwCMjIxo1aoVkD+kpE6dOly9epW4uLgi56NISkrC1dWV8+fPExwcTFxcHH/99Re5ufmrXVy+fJlGjRoVeW1HR0cAkpOTiyxGTJ06lYCAAOV1amoqTk5OREbWwdy8cFueR+npF0lJmcK6dfOoWbNmuV8vKyuL6OhoOnXqJOtqq0RyoC6Jv/okB+qS+KtPcqA+yYG6CuLv6elZrteRYoR45nh6erJy5UpMTEyoWrVqoeEJNWvWxNbWlnr16pGcnEy/fv04ePAgAK6urvzyyy+P3YYHf2lqNBq9bRqNBkApKKSlpdGtWzfmz59f6FwFBYVu3brh7OzM6tWrqVq1Krm5uTRq1KjQPBYlXedBWq0WrVZbaPvduzfJzLz80Pt8HmRkXCMzMwtDQ8On+sfQ2NhY/viqTHKgLom/+iQH6pL4q09yoD7JgbrKO/ZSjBDPHAsLi1L3Yhg3bhxz585V5nPw9fVl2rRp/Pzzz4XmjcjKyiIzM1MZ5vEkNWvWjC1btihDNB5069Ytzp07x+rVq2nfvj0Ahw8ffuLtKKDTrSIjo9xO/59jb68tl65pQgghhBBCPK+eSDHCw8ODJk2aEBYW9tB9Dxw4gKenJ7dv38bW1paIiAj8/f1JSUl5Ek15JpQlnsUpmD/g559/pkmTJoXiLvIVzBExY8YMevTogb+/Pzt37qRVq1bUr1+fdevWYWVlxYkTJ5g/fz5r1qwpdmnPxzFu3DhWr17NgAEDmDRpEnZ2dly4cIGNGzfy2WefUaFCBezt7fn0009xdHTk8uXLTJky5Ym3o0Bw8AgsLS3L7fz/JZaWltSsWZNKlSqp3RQhhBBCCCGeGU+9Z0SbNm24fv06NjY2T/vSxfq3Pah//fXXT7xLzJOO+4PFDrU8idyNHz+ejz76iK+++oq+ffsSHR1NmzZtuHDhAq1atcLc3Bw3NzcmTJigNzfDk1S1alViY2OZPHkyr776KjqdDmdnZ3x8fDAwMECj0bBx40alDfXq1WPp0qV4eHiUS3tmzVpNMSM7njv29lqiolaq3QwhhBBCCCGeKU+9GGFiYoKDg8NTuVZeXh45OTlFdnsvL1lZWY9dSLCzs3tCrfn/nmbcy+pJxKxAREREse95eHgUOUGlk5OT3rI1Wq2Wxo0b4+TkxLZt28rchgMHDhTadunSpULbHmxL3bp1+frrr4s9r5eXFwkJCcWew8XFpdA5bW1ti52UsyRa7Si0WrcyH/esyci4wq1boaSmpkrPCCGEEEIIIZ4gg7IecO/ePQYNGoSlpSWOjo6Ehobqvb9+/XqaN2+OlZUVDg4O+Pr6kpycrLx/4MABNBpNkcMyLl26hIGBASdOnNDbHhYWhrOzc7GT8D147u+++44XX3wRrVbL4cOHyc3NZe7cudSsWRMzMzNeeOEFNm/erFyzYJbQChUqoNFo8PPzA/If7h4cKtGkSRNCQkKU1xqNhpUrV9K9e3csLCz44IMPCAkJoUmTJqxfvx4XFxdsbGzo378/d+/eLbH9BTw8PPD391deu7i48OGHHzJ06FCsrKyoUaMGn376qd4xx44do2nTppiamtK8eXN+/vnnImNzf9xjY2Px8PDA3NycChUq4O3tze3btwHYvXs37dq1w9bWFnt7e7p27UpSUpJybMGqAk2bNkWj0Sif0Ofm5jJr1iyqV6+OVqulSZMm7N69Wznu0qVLaDQaNm3aRMeOHTE1NeXzzz8vMR6///473bp1o0KFClhYWNCwYUN27dpVYu50Oh0TJkygcuXKmJqa0q5dO2U1jQJnz56la9euWFtbY2VlRfv27fXu8X7Hjx+nUqVKRU4w+aCC/K9du5YaNWpgaWnJ2LFjycnJYcGCBTg4OFC5cmU++OADveNSUlIYPnw4lSpVwtrampdffplTp04p7yclJfH6669TpUoVLC0teemll/j+++/1zlGa75XSMDOrioVF7ef+n5mZU5ljJ4QQQgghhHi4MncZCAwM5IcffmD79u1UrlyZadOmcfLkSaWrflZWFrNnz1ZWKggICMDPz49du3Y99NwuLi54eXkRHh5O8+bNle3h4eH4+flhYFC62smUKVNYtGgRtWrVokKFCsydO5cNGzbwySefULduXQ4ePMibb75JpUqVaNeuHVu2bKF3796cO3cOa2trzMzMyhSTkJAQ5s2bR1hYGEZGRqxdu5akpCS2bdvGjh07uH37Nn379mXevHmFHkBLKzQ0lNmzZzNt2jQ2b97MmDFj6NixI/Xq1SMtLY2uXbvSqVMnNmzYwMWLF3nnnXdKPF98fDyvvPIKQ4cOZcmSJRgZGRETE0NOTg6QX3QKCAjA3d2dtLQ0goOD6dmzJ/Hx8RgYGHDs2DFatGjB999/T8OGDTExMQFgyZIlhIaGsmrVKpo2bcratWvp3r07Z8+epW7dusr1p0yZQmhoqFJAKcm4cePIzMzk4MGDWFhYkJCQgKWlJU5OTsXmbtKkSWzZsoXIyEicnZ1ZsGAB3t7eXLhwATs7O/744w86dOiAh4cH+/fvx9ramtjYWLKzswtdf//+/fTq1YsFCxbg4+NT4lwKBT0XkpKS+O6779i9ezdJSUm88cYb/Pbbb7i6uvLDDz9w5MgRhg4dipeXFy1btgSgT58+mJmZ8d1332FjY8OqVat45ZVX+PXXX7GzsyMtLY0uXbrwwQcfoNVqWbduHd26dePcuXPUqFGjVN8rD9LpdOh0OuV1amoqAEZGORgbZxXa/3ljYpKDiYkxOTk5er1nylPBdZ7W9URhkgN1SfzVJzlQl8RffZID9UkO1PW04l+mYkRaWhpr1qxhw4YNvPLKKwBERkZSvXp1ZZ+hQ4cqX9eqVYulS5fy0ksvkZaWVqoJ8YYPH87o0aP56KOP0Gq1nDx5ktOnT7N9+/ZSt3PWrFl06tQJyH/Y+vDDD/n+++9p3bq10q7Dhw+zatUqOnbsqAyLqFy58iPNO+Dr68uQIUP0tuXm5hIREYGVlRUAb731Fvv27XvkYkSXLl0YO3YsAJMnT2bx4sXExMRQr149oqKiyM3NZc2aNZiamtKwYUOuXr3KmDFjij3fggULaN68OStWrFC2NWzYUPm6d+/eevuvXbuWSpUqkZCQQKNGjZQu6/b29nrDPxYtWsTkyZPp378/APPnzycmJoawsDCWL1+u7Ofv70+vXr1Kde+XL1+md+/eNG7cGMjPX4Gicnfv3j1WrlxJREQEnTt3BmD16tVER0ezZs0aAgMDWb58OTY2NmzcuFEZIuLq6lro2lu3bmXQoEF89tln9OvXj+zsbOLj44tta9WqVYH8/K9duxYrKysaNGiAp6cn586dY9euXRgYGFCvXj0lNi1btuTw4cMcO3aM5ORkZanNRYsWsW3bNjZv3szIkSN54YUXeOGFF5RrzZ49m61bt/LNN98wfvx4ZXtJ3ysPmjt3LjNnziy0ffDgC5ibXyv2Pp8vg0lMTCQxMfGpXjU6OvqpXk8UJjlQl8RffZIDdUn81Sc5UJ/kQF0xMTHlev4yFSOSkpLIzMxUPsmF/IfB+x9yfvrpJ0JCQjh16hS3b99WhlZcvnyZBg0aPPQaPXr0YNy4cWzdupX+/fsTERGBp6cnLi4upW7n/b0qLly4QHp6ulKcKJCZmVlo6cZHdf/1Cri4uCiFCABHR0e94Spl5e7urnyt0WhwcHBQzpeYmIi7u7teD4OCwktx4uPj6dOnT7Hvnz9/nuDgYOLi4vjrr7/08ljcJI6pqalcu3aNtm3b6m1v27at3nADKDpmxZkwYQJjxoxh7969eHl50bt3b714PCgpKYmsrCy9dhgbG9OiRQvlgTI+Pp727duXOFdFXFwcO3bsYPPmzfTo0QMAIyOjUi0b+mD+q1SpgqGhoV7vnipVqig5PHXqFGlpadjb2+udJyMjQxk6kpaWRkhICDt37uT69etkZ2eTkZHB5cuX9Y4p6XvlQVOnTiUgIEB5nZqaipOTE5GRdTA3b/LQ+3zWpadfJCVlCuvWzVOGJpW3rKwsoqOj6dSpk6yrrRLJgbok/uqTHKhL4q8+yYH6JAfqKoh/wZD48vJEZ3a8d+8e3t7eeHt78/nnn1OpUiUuX76Mt7c3mZmZpTqHiYkJgwYNIjw8nF69ehEVFcWSJUvK1A4LCwvl67S0NAB27txJtWrV9PYr+AS6OAYGBoUm/yuqq8r91yvw4A+NRqN56JwXJXnS53vYUJRu3brh7OzM6tWrqVq1Krm5uTRq1KjUeXyYomJWnOHDh+Pt7c3OnTvZu3cvc+fOJTQ0lLfffvuRr1+aoTi1a9fG3t6etWvX8tprr5XpF2FR+Soph2lpaTg6OhY5+WVBj4+JEycSHR3NokWLqFOnDmZmZrzxxhuFclKW7xWtVlvkz8HduzfJzLxcxBHPl4yMa2RmZmFoaPjU/xAaGxvLH1+VSQ7UJfFXn+RAXRJ/9UkO1Cc5UFd5W97tPwAApvpJREFUx75MxYjatWtjbGxMXFycMkb99u3b/Prrr3Ts2JFffvmFW7duMW/ePJyc8id+e3AyytIYPnw4jRo1YsWKFWRnZ5e6O39RGjRogFar5fLly3Ts2LHIfQrmOyiYL6FApUqVuH79uvI6NTWVixcvPnJbyoubmxvr16/nn3/+UXpHHD16tMRj3N3d2bdvX5Fd9G/dusW5c+dYvXo17du3B+Dw4cN6+xQVM2tra2WJyvtjHRsbS4sWLR7t5v6Pk5MTo0ePZvTo0UydOpXVq1fz9ttvF9mO2rVrY2JiQmxsLM7OzkB+Een48ePKxKDu7u5ERkaWuJJHxYoV+frrr/Hw8KBv3758+eWX5fYD2axZM27cuIGRkVGxvYBiY2Px8/OjZ8+eQH4Bo6hVOp4EnW4VGRnlcur/HHt7LdbW1mo3QwghhBBCiGdKmYoRlpaWDBs2jMDAQOzt7alcuTJBQUFK1/MaNWpgYmLCsmXLGD16NGfOnGH27NmlPr+HhwdNmjQhLCyMVq1aMXnyZIYOHVrkp9gHDhzA09OT27dvY2trS0REhN64+QJWVlZMnDiRd999l9zcXNq1a8edO3eIjY3F2tqawYMH4+zsjEajYceOHXTp0gUzMzMsLS15+eWXiYiIoFu3btja2hIcHIyhoWFZQvZU+Pr6EhQUxIgRI5g6dSqXLl1i0aJFACxcuLDI1SqmTp1K48aNGTt2LKNHj8bExISYmBj69OmDnZ0d9vb2fPrpp+Tk5ODp6anMJ3HmzBl69uzJn3/+iZmZGbt376Z69eqYmppiY2NDYGAgM2bMoHbt2jRp0oTw8HDi4+MfumJGSfz9/encuTOurq7cvn2bmJgY3Nzyl50sLndjxowhMDAQOzs7atSowYIFC0hPT2fYsGEAjB8/nmXLltG/f3+mTp2KjY0NR48epUWLFnrDjipXrsz+/fvx9PRkwIABbNy4sUxLxfr5+ZGSkvLQuUi8vLxo3bo1PXr0YMGCBbi6unLt2jV27txJz549ad68ubL0Z7du3dBoNEyfPr1UvWMSEhLKvKxrcPCIUs3x8iyztLTE3t4ea2trWdZTCCGEEEKIJ6zMwzQWLlxIWloa3bp1w8rKivfee487d+4A+T0JIiIimDZtGkuXLqVZs2YsWrSI7t27l7lhw4YNU1YcKEqbNm24fv06NjY2Dz3X7NmzqVSpEnPnzuW3337D1taWZs2aMW3aNACqVavGzJkzmTJlCkOGDGHQoEFEREQwdepULl68SNeuXbGxsWH27Nkl9owoKJBMnjy5zPf7OCwtLfn2228ZPXo0TZs2pUGDBsyfP5/evXsrExk+yNXVlb179zJt2jRatGiBmZkZLVu2ZMCAARgYGLBx40YmTJjAl19+CeQXBEaMGEG9evW4fv069vb2LF26lFmzZhEcHEz79u05cOAAEyZM4M6dO7z33nskJyfToEEDvvnmG72VNO536dIlatasyc8//6ysyPKgnJwcxo0bx9WrV7G2tsbHx4fFixcDxedu3rx55Obm8tZbb3H37l2aN2/Onj17qFChApA/8eb+/fsJDAykY8eO5OXlkZGRUWhJVAAHBwf279+Ph4cHAwcOJCoq6okXpTQaDbt27SIoKIghQ4bw559/4uDgQIcOHahSpQoAH330EUOHDqVNmzaYmZmRkZHx2D1OijNr1moeYxTQM8HeXktU1EopRAghhBBCCFEONHkPToqgovt7RsyePZuvvvqK//3vf6U6NiIiAn9/f1JSUp54u/Ly8sjJyXnoJ+IP9tZ4HCUNH3iaSlMs+Lec/3Fi9iRzd7+CnhHbtm17YueEsn2/u7i44O/vrwxRKUlqaio2Nja0afMtWq3b4zf0Pyoj4wo6XShffRVG7dq1n+q1s7Ky2LVrF126dPlX/A54HkkO1CXxV5/kQF0Sf/VJDtQnOVBXQfzbtWtHxYoVuXPnTrkMW36iE1iWxb179xgzZgxff/21MpQC8m/8zJkzLFy4EDs7O6ysrLCwsODll18mLCyMypUrAyU/PF66dIlatWpx7NgxvVUbwsLCWLx4MRcvXtRb1eBBBefetWsX77//PqdPn2bv3r106NCB+fPn8+mnn3Ljxg1cXV2ZPn06b7zxBpcuXVJmGy349H3w4MFEREQU+TDYpEkTevToQUhICJD/yfiKFSv47rvv2LdvH4GBgQBs27aN9957j+nTp3P79m06d+7M6tWr9VZqKM79xR3IfygdOXIkFy5c4KuvvqJChQq8//77jBw5Ujnm2LFjjBo1isTERBo1akRQUFCRsbk/7rGxsQQFBXHs2DG0Wi0tWrRg48aNVKhQgd27dzNnzhzOnDmDoaEhrVu3ZsmSJcoDXsEKBQUrm3Ts2JEDBw6Qm5vLnDlz+PTTT/nzzz9xc3Nj3rx5+Pj4KDmuWbMmGzduZMWKFcTFxfHJJ5/g5+dXbDx+//13xo8fz+HDh8nMzMTFxYWFCxcqS28WlTudTkdgYCAbN24kNTWV5s2bs3jxYl566SXlvGfPnmXy5MkcPHiQvLw8mjRpQkRERJEPscePH6dLly5MnDjxoT1oTp06hb+/PydOnECj0VC3bl1WrVpFWlqaspSsRqMBYMaMGYSEhJCcnMywYcP4/vvvcXBwYM6cOSVeQ6fTodPplNepqakAWFlVwdy8RonHPstMTHJISTEmJyfnqa9vLetqq09yoC6Jv/okB+qS+KtPcqA+yYG6nlb8VStGBAYG8sMPP7B9+3YqV67MtGnTOHnyJMnJyXz22We4u7szY8YMGjRoQHJyMgEBATRv3py///4b+P8TFlarVg2NRqP3cOji4oKXlxfh4eF6xYjw8HD8/PxKLETcb8qUKSxatIhatWpRoUIF5s6dy4YNG/jkk0+oW7cuBw8e5M0336RSpUq0a9eOLVu20Lt3b86dO4e1tXWRc10ULHGakZFBQkKCMrcDwNixY1m4cCFhYWEYGRmxdu1akpKS2LZtGzt27OD27dv07duXefPm8cEHHzxS3ENDQ5k9ezbTpk1j8+bNjBkzho4dO1KvXj3S0tLo2rUrnTp1YsOGDVy8eJF33nmnxPPFx8fzyiuvMHToUJYsWYKRkRExMTFKfu7du0dAQADu7u6kpaURHBxMz549iY+Px8DAgGPHjtGiRQtMTU3RaDQcP34cS0tLsrKyyMzMpF+/fsycOZO1a9fSvXt3zp49qzfkY8qUKYSGhtK0aVO9pU2LMm7cODIzMzl48CAWFhYkJCRgaWmJk5NTsbmbNGkSW7ZsITIyEmdnZxYsWECrVq2U9ubm5pKRkaGstjB79mzs7e3Jzs4udP39+/fTq1cvFixYoFcAKs7AgQNp2rQpK1euxNDQkPj4eIyNjWnTpg1hYWEEBwdz7tw5AGV+Bz8/P65du0ZMTAzGxsZMmDChxCVl586dW+QkpoMHX8Dc/NpD2/hsG0xiYqKyHOzTJutqq09yoC6Jv/okB+qS+KtPcqA+yYG6YmJiyvX8qhQj0tLSWLNmDRs2bOCVV14BIDIykurVq/Pqq68qn+QXqFWrFkuXLuWll14iPj4eCwsL4uLiePPNNzl06BDW1tbs2rVLb7z/8OHDGT16NB999BFarZaTJ09y+vRptm/fXup2zpo1i06dOgH5nyB/+OGHfP/997Ru3Vpp1+HDh1m1ahUdO3bEzs4OyJ/0sLiu/lWrViU+Pp5u3brRqVMnJkyYAEDdunXx8/PD399fbzhIbm4uERERSk+It956i3379j1yMaJLly7KPBKTJ09m8eLFxMTEUK9ePaKiosjNzWXNmjWYmprSsGFDrl69ypgxY4o934IFC2jevDkrVqxQthVMdgnQu3dvvf3Xrl1LpUqVSEhIoFGjRsp4/E2bNtGgQQNlv3bt2jFw4ECCgoKws7Nj/vz5xMTEEBYWxvLly5X9/P39S73ayuXLl+nduzeNGzcG8vNXoKjc3bt3j5UrVxIREUHnzp0BWL16Nbt372bw4MGMGDGC0NBQduzYwd69ezE2NqZKlSpF9lrZunUrgwYN4rPPPqNfv36lbm9gYCD169cH0CvC2NjYoNFo9Cam/PXXX/nuu+84duyYUpxbs2aNMtlnUaZOnUpAQIDyOjU1FScnJyIj62Bu3qRU7XwWpadfJCVlCuvWzVN67zwtsq62+iQH6pL4q09yoC6Jv/okB+qTHKirIP4FvcfLiyrFiKSkJDIzM2nZsqWyzc7OTm8Vg59++omQkBBOnTrF7du3lVUDjI2NqVOnDlevXgXyHyhtbW0LjWHp0aMH48aNY+vWrfTv35+IiAg8PT2LXTaxKPf3qrhw4QLp6elKcaJAZmamMsSgNIyMjKhTpw5arRY7Ozvq1KmjvOfl5VVoXgoXFxe9h1tHR8cSP+l+GHd3d+XrgofZgvMlJibi7u6u18OgoPBSnPj4ePr06VPs++fPnyc4OJi4uDj++usvJY+XL1+mUaNGyn41atRQYpGamsrNmzfp3r27UiQAaNu2LadOndI7//05epgJEyYwZswY9u7di5eXF71799aLx4OSkpLIysqibdu2yjZjY2Nat27Nn3/+SZ3/x969x+V8/g8cf92d7s6l26lINUQkchpiQuQ8MacYOZ8PixxqS2FzmCbsKJTDrB0cNoc5zDSWyTZjM60t02KYMUnKXarfH759fu5V5JAP9n4+Hh4P9+dwXdfn/SaP++36XFetWvzxxx+0b9/+jl/4k5KS2L59O5988gm9evUq83iDg4MZOXIk69evx8/Pj759+95x/YLk5GRMTExo0qSJcqxu3bp3XANDq9Wi1WqLHb9505i8vP/uD/7cXGNyc/OUGS9qkH211Sc5UJfEX32SA3VJ/NUnOVCf5EBd5R171V7TuJPr16/j7++Pv78/77//PpUqVSI9PR1/f39yc3PL1IaZmRlDhgwhNjaW3r17s3HjRpYtW3ZP47CyslJ+n5WVBcCOHTuoVq2awXUlfZm7nZGREf9eJ7Sk929u76/Iv/8AFL0acL8ednslvYpyux49euDi4kJMTAxOTk4UFBTg6elZ5jzeTUkxK83IkSPx9/dnx44d7NmzhwULFhAVFcWkSZPuu/+7PT9AzZo10el0rFmzhm7dupX5L3VERASBgYHs2LGDzz//nDlz5hAfH09AQMB9j7escnLOUVBw951qnlY5OWfUHoIQQgghhBBPNVWKETVr1sTU1JSkpCRq1Li1SN6VK1f49ddfadu2Lb/88guXL19m4cKFODs7A/Ddd9/dcz8jR47E09OTt99+m5s3b5Z5On9J6tWrh1arJT09nbZt25Z4jZmZGfD/61kUqVSpEufPn1c+Z2Zm3nGLULV4eHiwfv16bty4ocyOOHz48B3v8fLyYt++fSWuO3D58mVSUlKIiYmhTZs2AHz99dcG15QUM1tbW5ycnEhMTDSIdWJi4gNvZens7MzYsWMZO3Yss2fPJiYmhkmTJpU4jpo1a2JmZkZiYiIuLi7ArSLSt99+qyxG6uXlxdq1a++4k0fFihXZvHkzvr6+9OvXj48++qjMBQl3d3fc3d156aWXGDhwILGxsQQEBGBmZlbsz1ndunW5efMm33//vfKaRkpKyn3tMKPXv0dOzj3f9lTR6bTlsmqwEEIIIYQQQqVihLW1NSNGjCAkJASdTkflypUJCwtTFpasUaMGZmZmrFixgrFjx3LixAnmzZt3z/14eHjQokULZs6cyfDhw8v0v9ilKdrx46WXXqKgoIDWrVtz9epVEhMTsbW1ZejQobi4uKDRaNi+fTtdu3bFwsICa2tr2rdvT1xcHD169MDe3p7w8HCMjY3veyzlJTAwkLCwMEaNGsXs2bNJS0szWGCzJLNnz6ZBgwaMHz+esWPHYmZmxv79++nbty8ODg7odDpWrlyJo6Mj6enpzJo1y+D+ypUrY2Fhwa5du6hevTrm5ubY2dkREhLCnDlzqFmzJo0aNSI2NpZjx47x/vvv3/fzTZ06lS5duuDu7s6VK1fYv3+/8npFabkbN24cISEhODg4UKNGDRYvXkx2djYjRowAYOLEiaxYsYIBAwYwe/Zs7OzsOHz4MM2bNzd47ahy5cp8+eWXtGvXjoEDBxIfH3/HrWJzcnIICQnhhRdewM3NjbNnz/Ltt98qa3C4urqSlZXFvn37aNiwIZaWltSpU4fOnTszZswY3nnnHUxMTJg6dep9/bkPDx+lLIr5NLO2tkan05V4ztbWVlnTRAghhBBCCPFwqfaaxuuvv05WVhY9evTAxsaGadOmcfXqVeDWTIK4uDhCQ0NZvnw5jRs3ZsmSJfTs2fOe+xkxYgSHDh1i+PDhDzzmefPmUalSJRYsWMDvv/+Ovb09jRs3JjQ0FLi1s0dkZCSzZs1i2LBhDBkyhLi4OGbPns3p06fp3r07dnZ2zJs377GcGWFtbc22bdsYO3Ys3t7e1KtXj0WLFhVbhPJ27u7u7Nmzh9DQUJo3b46FhQXPPvssAwcOxMjIiPj4eCZPnoynpyd16tRh+fLl+Pr6KvebmJiwfPly5s6dS3h4OG3atCEhIYHJkydz9epVpk2bxsWLF6lXrx6fffaZwSKO9yo/P58JEyZw9uxZbG1t6dy5M0uXLgVKz93ChQspKCjgxRdf5Nq1azRt2pTdu3crW4DqdDq+/PJLQkJCaNu2LcbGxjRq1MhgnYkiVatW5csvv8TX15dBgwaxcePGUotSxsbGXL58mSFDhvDXX39RsWJFevfurcxAadWqFWPHjqV///5cvnxZ2dozNjaWkSNH0rZtW6pUqcL8+fN55ZVX7jlWc+fG8ABv7zwxdDotGze+I0UHIYQQQgghHjFN4b8XM3jKzJs3j48//pgff/xR7aE8lnx9fWnQoAHGxsasXbsWMzMz5s+fT2BgIBMnTuSTTz6hSpUqrFixQtlR4quvviIkJITjx4/j4ODA0KFDmT9/vvI//b6+vspCmKtWrcLMzIyxY8cSERGh9JuRkcH06dP59NNP0ev1NG3alKVLl9KwYUPS0tJ45plnOHLkiMECldHR0SxdupTTp09z4MAB2rVrxxdffMHMmTM5efKkMoPi9hkJn376KZGRkZw8eRInJyeGDh1KWFgYJiYmFBYWKtuG/vXXX+h0Ol544QWWL18OwNtvv83SpUs5c+YMdnZ2tGnThk8++aRcYgpw4sQJQkJCOHjwIFZWVnTq1ImlS5dSsWJFAHbt2sX8+fM5ceIExsbGtGzZkmXLlimLWqalpeHm5samTZtYsWIFSUlJ1K5dm3ffffeuC5EWyczMxM7OjlattqHVlr4o59MgJ+cMen0UH38cfceFQR+1vLw8du7cSdeuXWXBJpVIDtQl8Vef5EBdEn/1SQ7UJzlQV1H8W7duTcWKFbl69Wq5vL78WC5g+TBkZWWRlpbGm2++yfz589UezmNt7dq1zJgxgyNHjvDhhx8ybtw4tmzZQkBAAKGhoSxdupQXX3yR9PR0rly5QteuXQkKCmLdunX88ssvjBo1CnNzc4Niw9q1awkODiYpKYlvvvmGoKAgfHx8lN1I+vbti4WFBZ9//jl2dna89957dOjQgV9//RVXV1f8/PyIjY01KEbExsYSFBSkvM4DEBYWRlRUFJUqVWLs2LEMHz6cxMREAA4ePMiQIUNYvnw5bdq04dSpU4wePRqAOXPmsGnTJpYuXUp8fDz169fnwoULym4d3333HZMnT2b9+vW0atWKf/75h4MHD5ZLTC0tLcnIyKB9+/aMHDmSpUuXkpOTw8yZM+nXrx9ffvklcGth1+DgYLy8vMjKyiI8PJyAgACOHTtWLCZLliyhdu3ahIWFMXDgQFJTU0t8LUSv16PX65XPmZmZANjYVMHSskaZn/dJZGaWT0aGKfn5+SUuKKuWorE8TmP6r5EcqEvirz7Jgbok/uqTHKhPcqCuRxX/p3ZmRFBQEB988AG9evUqNh1+7NixbNiwocT7Bg8ezLvvvvuohnnf0tPTqVevXqnnT548qSwOeie+vr7k5+crX7Tz8/Oxs7Ojd+/erFu3DoALFy7g6OjIN998w7Zt29i0aRPJycloNBrg1gyCmTNncvXqVYyMjIq1CdC8eXPat2/PwoUL+frrr+nWrRsXL1402ImkVq1azJgxg9GjR/PRRx8xduxYzp8/j1ar5ejRozRt2pTff/8dV1dXEhISlJkRHTp0AG5t8/n9999jaWmJRqMhJycHY2NjzMzMCA0NJTQ0lA0bNjBjxgzOnTvHG2+8wXvvvceJEyeKVVw3b97MsGHDOHv2rMHWqmVxLzE1NzfH2NiY3NxcCgoKlIVD33vvPdq2bYuzszMpKSm4u7sX6+fSpUtUqlSJn376CU9PT2VmxKpVq5Q1LU6ePEn9+vVJTk6mbt26xdqIiIgocfHRjRs3YmlpeU/PLYQQQgghhHh6ZGdnExgYKDMj7lVcXBxxcXElnps7dy7Tp08v8dyTsnq+k5MTx44du+P5svLy8lJ+b2xsjE6no0GDBsqxKlWqAHDx4kWSk5Np2bKlUogA8PHxISsri7NnzyoFkNvbBHB0dOTixYsAHD9+nKysrGILB+bk5HDq1CkAevXqxYQJE9iyZQsDBgwgLi6Odu3a4erqWurYX331VTp37sznn3+Ok5MTzZs3Jzs7m8LCQl577TVee+018vPzuXHjBtnZ2fTt25fo6GieeeYZOnfuTNeuXenRowcmJiZ07NgRFxcX5Vznzp0JCAgo8xf0ssY0OjqaDh06MGnSJPbt26dsATtmzBjl2lOnTuHu7s5vv/1GeHg4SUlJXLp0SdmSNT09HU9PzxL7dnR0BG7lrqRixOzZswkODlY+Z2Zm4uzszNq1tbC0bFSmZ31SZWefJiNjFuvWLcTNzU3t4Sjy8vLYu3cvHTt2lGmJKpEcqEvirz7Jgbok/uqTHKhPcqCuovi3a9euXPt5aosRd1K5cmUqV66s9jAeiImJCbVq1Xoobf37L7hGozE4VlR4KLiHFQ1LarPo/qysLBwdHUlISCh2n729PXBry88hQ4YQGxtL79692bhxI8uWLbtjP0Vf8GvUqIGrqys5OTnMnTu3xC1dzc3NlVkHX3zxBXv37mX8+PG8/vrrfPXVV9jY2HD06FESEhLYs2cP4eHhRERE8O233ypjvNfnLymmVapUUfLYo0cPFi1aVKytooJCjx49cHFxISYmBicnJwoKCvD09CQ3N7fUvu+WO61WazA7pcjNm8bk5T3dP/hzc43Jzc3D2Nj4sfxHztTU9LEc13+J5EBdEn/1SQ7UJfFXn+RAfZIDdZV37P+TxQhx/zw8PNi0aROFhYXKF93ExERsbGyoXr16mdpo3LgxFy5cwMTEpNhMh9uNHDkST09P3n77bW7evFliUeFu/aSkpNyxaGNhYUGPHj3o0aMHEyZMoG7duvz00080btwYExMT/Pz88PPzY86cOdjb2/Pll1/e8zjKOtZNmzbh6upa4toOly9fJiUlhZiYGNq0aQPA119//dDHUSQn5xwFBXbl1v7jICfnjNpDEEIIIYQQ4j9LihHinowfP57o6GgmTZrExIkTSUlJYc6cOQQHBxssongnfn5+tGzZkl69erF48WLc3d05d+4cO3bsICAgQFm00sPDgxYtWjBz5kyGDx+OhYXFPY01PDyc7t27U6NGDV544QWMjIw4fvw4J06cYP78+cTFxZGfn8+zzz6LpaUlGzZswMLCAhcXF7Zv387vv//Oc889R4UKFdi5cycFBQUGO3U8TBMmTCAmJoaBAwcyY8YMHBwcSE1NJT4+nlWrVlGhQgV0Oh0rV67E0dGR9PR0Zs2addd209PTAUhNTTXYUvVusrKiych4evb2NDIywdS0+AwQnU77xLyaJYQQQgghxNNEihHinlSrVo2dO3cSEhJCw4YNcXBwYMSIEbz88stlbkOj0bBz507CwsIYNmwYf//9N1WrVuW5555TXrUoMmLECA4dOsTw4cPveaz+/v5s376duXPnsmjRIkxNTalbty4jR44Ebr0SsnDhQoKDg8nPz6dBgwZs27YNnU7HW2+9xa5du5S2zMzM6NOnD3Xq1FEWzyxSsWJFmjVrxqJFiwzWhcjNzSU6Opr333+f9PR0Xn75ZT7++GNGjhzJ4MGDDcbq5OREYmIiM2fOpFOnTuj1elxcXOjcuTNGRkZoNBri4+OZPHkynp6eWFpa3nEB0wdn9L9fTwc7OxPeeOOVYuuU2NraUqlSJZVGJYQQQgghxH+XFCP+40patyEtLa3Ysds3XWnbti1Hjhy5pza3bt1q8NnGxobly5ezfPnyO47vzz//pEGDBjRr1szguK+vL//eCKZRo0bFjvn7++Pv719i27169aJXr14lnqtSpQqdO3cmNjYWvV7Pzp07mTBhAt7e3rRs2RKAlJQUbG1tOXfuHCEhIXTr1o3U1FQSEhLIzc3F39+f48ePM2/ePHx8fLC1teXw4cMsWbIEb2/vYmOtXbs2mzdvLjUWfn5+nDx5Eri1W0xGRoZBG66ursXaLPpf/9u3SC0La+vJaLUe93TP4yon5wzZ2VHodDpq1qyp9nCEEEIIIYQQSDFCPKaysrJIS0vjzTffZP78+aqMQavVUrVqVQDGjRvHli1b+Oyzz5RiROXKlbG3t6dq1apMnTqVnj178ssvv+Dl5UV0dDQHDhzgu+++w9vbW2nzmWeeoW/fvsUWnSzJJ598QmRkJKmpqVhaWuLt7c2nn37K66+/ztq1a4H/X6By//79+Pr6cuTIEcaMGUNycjKenp6EhYXd17NbWDhhYfH0fHHX69UegRBCCCGEEOJ2UowQj6WJEyfywQcf0KtXr/t6RaM8WFhYcP78ebp06QLcemVFo9FQWFiI/n/fdi9dugTA+++/j5+fn0EhokhZVgU+f/48AwcOZPHixQQEBHDt2jUOHjxIYWEh06dPJzk5mczMTGJjYwFwcHAgKyuL7t2707FjRzZs2MDp06eZMmXKHfvR6/XK2OHW1p4AJib5mJrmlTEyjzczs3zMzEzJz88nL+/xf6aiMT4JY31aSQ7UJfFXn+RAXRJ/9UkO1Cc5UNejir+m8N/zuoUQymsQW7dupbCwkH379tG9e3cmTJhA48aNGTx4MJaWlgBkZ2cD0KFDB3bt2oWJiQmWlpaMGjWqxO1Iy+Lo0aM0adKEtLQ0XFxc7ji+IitXriQ0NJSzZ89ibm4OwLvvvsu4ceP44YcfaNSoUbF2IiIiiIyMLHZ848aNyvMJIYQQQggh/nuys7MJDAzk6tWr5bLou8yMEKIU27dvx9ramry8PAoKCggMDGTu3Ll8++23wK2tNS0tLTl8+DCvvfYa69evV7blfNAaX8OGDenQoQMNGjTA39+fTp068cILL1ChQoVS70lOTsbLy0spRADKKyWlmT17NsHBwcrnzMxMnJ2dWbu2FpaWjR7oGR4X2dmnyciYxbp1C3Fzc1N7OHeVl5fH3r176dixo+yrrRLJgbok/uqTHKhL4q8+yYH6JAfqKor/7Yv2lwcpRghRinbt2vHOO+9gZmaGk5OTUmgo4ubmhr29PXXq1OHixYv079+fAwcOAODu7s4vv/xy330bGxuzd+9eDh06xJ49e1ixYgVhYWEkJSU91C/UWq0Wrbb4lpfXrv1Fbm76Q+tHTTk558jNzcPY2PiJ+sesLK/ziPIlOVCXxF99kgN1SfzVJzlQn+RAXeUdeylGCFEKKysratWqVaZrJ0yYwIIFC9iyZQsBAQEEBgYSGhrKDz/8UGzdiLy8PHJzc7GysrpjmxqNBh8fH3x8fAgPD8fFxYUtW7YQHByMmZkZ+fn5Btd7eHiwfv16bty4ocyOOHz48D088f/T698jJ+e+bn0s6XTacplaJoQQQgghhLg/UowQ4iEoWiNizpw59OrVi6lTp7Jjxw46dOjAvHnzaN26NTY2Nnz33XcsWrSI1atXl7iGQ5GkpCT27dtHp06dqFy5MklJSfz99994eNzabtPV1ZXdu3eTkpKCTqfDzs6OwMBAwsLCGDVqFLNnzyYtLY0lS5bc1/OEh4/C2tr6vu593FhbW+Pm5kalSpXUHooQQgghhBDif6QYIcRDMnHiRN544w3atWvHV199xbx58+jatSvvvfce06dPx8TEhKysLCZMmECTJk1IT0+nWrVqxdqpXbs2Pj4+XLhwgYiICGUVWxMTE0aOHEnjxo3p3bs3derUoWnTpmRlZSlbe27btg1fX182bNhA/fr1WbRoEX369LnnZ5k7N4aCggcOyWNBp9OyceM7ag9DCCGEEEIIcRspRghRgri4uFLP+fr6lrhApbOzM3l5eQQFBZGUlERUVBS///47s2bNAmDr1q0EBASwdOlSPvroI9auXUtoaKhBGwcOHCA1NZWtW7dSv359fH19cXd3Z+7cudy8eZOzZ8+yZcsWxowZQ1BQEHv27DG4/+bNm1SpUoXWrVvj5eVF796972sxTa12DFqtxz3f97jJyTnD5ctRZGZmyswIIYQQQgghHiNSjBCiHPj5+ZGamsqCBQtYvHixwTlTU1NefPFF4uLiihUj1qxZw7PPPkv9+vWVY5aWllStWhWA6tWr06JFC+rWrcvw4cPp168ffn5+yrWrV68mMDCQtm3bMmXKFGbOnHlf47ewcMLCouZ93fu40evVHoEQQgghhBDi36QYIUQ5MDY25rXXXiMwMJDJkydTvXp1g/NdunThjTfewMLCAmNjY+DWdqDZ2dmYmZmRnp5OjRo1Sm1/6NChTJs2jc2bNyvFiGvXrvHxxx+TlJRE3bp1uXr1KgcPHqRNmzaltqPX69Hf9m09MzMTABOTfExN8+77+R8XZmb5mJmZkp+fr7zu8rgrGueTMt6nkeRAXRJ/9UkO1CXxV5/kQH2SA3U9qvhLMUKIchIQEECjRo2YM2cOq1evNjjn6+tLo0aNcHNzU2ZOfPzxx8ybN49Dhw7h5OR0x7aNjIxwd3cnLS1NORYfH0/t2rWVWRUDBgxg9erVdyxGLFiwgMjIyGLHhw5NxdLyXFkf9TE3lOTkZJKTk9UeyD3Zu3ev2kP4z5McqEvirz7Jgbok/uqTHKhPcqCu/fv3l2v7UowQohwtWrSI9u3bM336dIPjJiYmjB8/npdeeom1a9diY2PDjh076Nev3x132bhdYWEhGo1G+bxmzRoGDx6sfB48eDBt27ZlxYoV2NjYlNjG7NmzCQ4OVj5nZmbi7OzM2rW1sLQs2zgeZ9nZp8nImMW6dQtxc3NTezhlkpeXx969e+nYsaPsq60SyYG6JP7qkxyoS+KvPsmB+iQH6iqKf7t27cq1HylGCFGOnnvuOfz9/Zk9ezZBQUEG5wYMGMBLL73ERx99xHPPPUdiYiILFiwoU7v5+fn89ttvNGvWDICTJ09y+PBhjhw5YrBORH5+PvHx8YwaNarEdrRaLVqtttjxa9f+Ijc3vYxP+fjKyTlHbm4exsbGT9w/ZKampk/cmJ82kgN1SfzVJzlQl8RffZID9UkO1FXesZdihBDlbOHChTRq1Ig6deoYHLexsaFv376sWbOGU6dO4e7ufsdXKm63du1arly5omzbuXr1ap577jneeustg+tiY2NZvXp1qcWI0uj175GTc0+3PLZ0Oi22trZqD0MIIYQQQghxGylGiKeeq6srU6dOZerUqar036BBAwYNGsTy5cuLnRsxYgRt2rQhOTm51J0vsrOzuXDhgsHWnkuXLmXcuHG0a9eOvLw81q9fz9y5c/H09DS4d+TIkbzxxhv8/PPPBjt03E14+Cisra3v7UEfI9bW1uh0OgBsbW1lW08hhBBCCCEeM1KMEE+NuLg4pk6dSkZGhsHxb7/9FisrK3UG9T9z587lww8/LHa8devW1KlTh9TUVIYMGVLivTExMcTExGBmZoZOp6NJkyZ8+OGHBAQEAPDZZ59x+fJl5fPtPDw88PDwYPXq1bzxxhv3MN4YCgrKfPljR6fTsnHjO1KEEEIIIYQQ4jElxQjxUOTm5mJmZqb2MEr0qL+QxsXFFTvm6upqsIXm7X755ZdS20pISLhrf3369CE/P7/U8ydPnrxrG/+m1Y5Bq/W45/seBzk5Z7h8OYrMzEwpRgghhBBCCPGYMlJ7AOLx5Ovry8SJE5k4cSJ2dnZUrFiRV155hcLCQuDWl+t58+YxZMgQbG1tGT16NACJiYn4+vpiaWlJhQoV8Pf358qVK3ftT6/XM3nyZCpXroy5uTmtW7fm22+/Vc4nJCSg0WjYsWMHXl5emJub06JFC06cOKGcHzZsGFevXkWj0aDRaIiIiFDGGh0drbSVnp7O888/j7W1Nba2tvTr14+//vpLOR8REUGjRo1Yv349rq6u2NnZMWDAAK5du1bm2E2aNImpU6dSoUIFqlSpQkxMDNevX2fYsGHY2NhQq1YtPv/8c4P7Tpw4QZcuXbC2tqZKlSq8+OKLXLp0STm/a9cuWrdujb29PTqdju7du3Pq1CnlfFpaGhqNhs2bN9OuXTssLS1p2LAh33zzTZnGfTsLCyesrGo+kb8sLJzv+XmFEEIIIYQQj5bMjBClWrt2LSNGjODIkSN89913jB49mho1aiiLIS5ZsoTw8HDmzJkDwLFjx+jQoQPDhw9n2bJlmJiYsH///jv+r32RGTNmsGnTJtauXYuLiwuLFy/G39+f1NRUHBwclOtCQkJYtmwZVatWJTQ0lB49evDrr7/SqlUroqOjCQ8PJyUlBaDENQ8KCgqUQsRXX33FzZs3mTBhAv379zeYhXDq1Cm2bt3K9u3buXLlCv369WPhwoW8+uqrZY7djBkzOHLkCB9++CHjxo1jy5YtBAQEEBoaytKlS3nxxRdJT0/H0tKSjIwM2rdvz8iRI1m6dCk5OTnMnDmTfv368eWXXwJw/fp1goOD8fLyIisri/DwcAICAjh27BhGRv9fVwwLC2PJkiXUrl2bsLAwBg4cSGpqKiYmxf+66/V6gxkbmZmZAJiY5GNqmlemZ33cmJnlY2ZmSn5+Pnl5T94zFI35SRz700JyoC6Jv/okB+qS+KtPcqA+yYG6HlX8NYVF/9UtxG18fX25ePEiP//8MxqNBoBZs2bx2WefcfLkSVxdXfH29mbLli3KPYGBgaSnp/P111/fU1/Xr1+nQoUKxMXFERgYCNz6g1+08GRISAgJCQm0a9eO+Ph4+vfvD8A///xD9erViYuLo1+/fqWuGXH7ApZ79+6lS5cunD59GmfnW/+DfvLkSerXr8+RI0do1qwZERERvP7661y4cAEbGxvgVrHkwIEDHD58uEyxy8/P5+DBg8Ct7TXt7Ozo3bs369atA+DChQs4OjryzTff0KJFC+bPn8/BgwfZvXu30s7Zs2dxdnYmJSUFd3f3Yv1cunSJSpUq8dNPP+Hp6UlaWhpubm6sWrWKESNGGDxbcnIydevWLdZGREQEkZGRxY5v3LgRS0vLuz6rEEIIIYQQ4umUnZ1NYGAgV69eLZfd6WRmhChVixYtlEIEQMuWLYmKilJmOjRt2tTg+mPHjtG3b9977ufUqVPk5eXh4+OjHDM1NaV58+YkJycbXNuyZUvl9w4ODtSpU6fYNXeSnJyMs7OzUogAqFevHvb29iQnJ9OsWTPgVgGjqBAB4OjoyMWLF8vcj5eXl/J7Y2NjdDodDRo0UI5VqVIFQGnz+PHj7N+/v8TZHEXbfv7222+Eh4eTlJTEpUuXKPjfCpPp6ekGu2jc3rejo6PST0nFiNmzZxMcHKx8zszMxNnZmbVra2Fp2ajMz/s4yc4+TUbGLNatW4ibm5vaw7lneXl57N27l44dO8q+2iqRHKhL4q8+yYG6JP7qkxyoT3KgrqL4t2vXrlz7kWKEuG//3qHCwsJCpZE8fP/+oafRaJQv//d7/+3Hioo8RW1mZWXRo0cPFi1aVKytooJCjx49cHFxISYmBicnJwoKCvD09CQ3N7fUvv/dz79ptVq0Wm2x49eu/UVubvpdn/NxlJNzjtzcPIyNjZ/of7xMTU2f6PE/DSQH6pL4q09yoC6Jv/okB+qTHKirvGMvxQhRqqSkJIPPhw8fpnbt2hgbG5d4vZeXF/v27Stx2v+d1KxZEzMzMxITE3FxcQFuVeO+/fZbpk6dWmwMNWrUAODKlSv8+uuveHjc2vXBzMzsrutTeHh4cObMGc6cOWPwmkZGRgb16tW7p3E/TI0bN2bTpk24urqWuLbD5cuXSUlJISYmhjZt2gDc8+sw90Kvf4+cnHJrvtzpdNpymUomhBBCCCGEeDikGCFKlZ6eTnBwMGPGjOHo0aOsWLGCqKioUq+fPXs2DRo0YPz48fTo0YOuXbsqrwFUrFix1PusrKwYN24cISEhODg4UKNGDRYvXkx2dray9kGRuXPnotPpqFKlCmFhYVSsWJFevXoBt16tyMrKYt++fTRs2BBLS0s++ugj0tP//3/4/fz8aNCgAYMGDSI6OpqbN28yfvx42rZtW+y1k0dpwoQJxMTEMHDgQGbMmIGDgwOpqanEx8ezatUqKlSogE6nY+XKlTg6OpKens6sWbPKbTzh4aNKfGXkcWZtbY1OpwPA1tZWtvUUQgghhBDiMSbFCFGqIUOGkJOTQ/PmzTE2NmbKlCnKFp4lcXd3Z8+ePYSGhrJ69Wrg1pabM2bMuGtfCxcupKCggBdffJFr167RtGlTdu/eTYUKFYpdN2XKFH777TcaNWrEtm3bMDMzA24toNmqVSv69+/P5cuXmTNnDjNnzuSVV15R7tdoNHz66adMmjSJ5557DiMjIzp37syKFSvuJ0QPjZOTE4mJicycOZNOnTqh1+txcXGhc+fOGBkZodFoiI+PZ/LkyXh6elKnTh2WL1+Or69vuYxn7twY7uGtlMeCTqdl48Z3pAghhBBCCCHEE0CKEf9hubm5yhf5kpiamhIdHc0777xT7FxaWlqJ97Rt25bExERlZ4e3334be3v7u47F3Nyc5cuXs3z58jte17p1a06cOFHq+b59+xZ7tePMmTMGn2vUqMGnn35aahsRERFEREQYHCvajaMsbt8itEhJ8fr3Rja1a9dm8+bNpbbr5+fHyZMnS23D1dW1WJv29vbFjpWFVjsGrdbjnu9TS07OGS5fjiIzM1OKEUIIIYQQQjwBpBjxhPnkk0+IjIwkNTUVS0tLvL29+fTTT5kwYQIZGRl4e3vz5ptvotfrCQwMZPny5UrBwdfXF09PT0xMTNiwYQMNGjRg//79nDhxgpCQEA4ePIiVlRWdOnUy2FN2165dzJ8/nxMnTmBsbEzLli1ZtmwZNWvWVK45cuQIY8aMITk5GU9PT8LCwu7pub766itCQkI4fvw4Dg4ODB06lPnz5yvrJxQVAkJCQvjoo48wNTVl3LhxzJ07F41Gg6+vL3/88QcvvfQSL730EnDri3pJ232+8847LFmyhDNnzuDm5sbLL7/Miy++qJzXaDTExMSwY8cOdu/eTbVq1YiKiqJnz553fY6iLUh37drFrFmz+OWXX2jZsiXx8fF8//33BAcH8+eff9K9e3dWrVqlbJ9ZUFDAokWLWLlyJRcuXMDd3Z1XXnmFF154Abi1Pejo0aP58ssvuXDhAjVq1GD8+PFMmTJF6TsoKIiMjAxat25NVFQUubm5DBgwgOjo6FIXn9Hr9ej1euVzZmYmADY2VbC0rHHX531cmJnlk5FhSn5+/hO/H7Xsq60+yYG6JP7qkxyoS+KvPsmB+iQH6npU8ZdixBPk/PnzDBw4kMWLFxMQEMC1a9c4ePCg8j/f+/btw9zcnISEBNLS0hg2bBg6nY5XX31VaWPt2rWMGzeOxMREADIyMmjfvj0jR45k6dKl5OTkMHPmTE6ePKlsc3n9+nWCg4Px8vIiKyuL8PBwAgICOHbsGEZGRmRlZdG9e3c6duzIhg0bOH36tMGX5PT09DsuDvnll1/StWtXgoKCWLduHb/88gujRo3C3Ny82AwFExMTjhw5wnfffcfo0aOpUaMGo0aNYvPmzTRs2JDRo0czatSoUvvasmULU6ZMITo6Gj8/P7Zv386wYcOoXr26wdY1kZGRLF68mNdff50VK1YwaNAg/vjjD7Kysu74LEWvp0RERPDmm29iaWlJv3796NevH1qtlo0bN5KVlUVAQAArVqxg5syZACxYsIANGzbw7rvvUrt2bQ4cOMDgwYOpVKkSbdu2paCggOrVq/Pxxx+j0+k4dOgQo0ePxtHRkX79+in979+/H0dHR/bv309qair9+/enUaNGpcZkwYIFJS44OnRoKpaW50p9zsfTUJKTk+9pq9fH2d69e9Uewn+e5EBdEn/1SQ7UJfFXn+RAfZIDde3fv79c29cU3s8cbqGKo0eP0qRJE9LS0pRdJ4oEBQWxbds2zpw5o/xv+7vvvktISAhXr17FyMgIX19fMjMzOXr0qHLf/PnzOXjwILt371aOnT17FmdnZ1JSUnB3dy82jkuXLlGpUiV++uknPD09WblyJaGhoZw9exZzc3Ol73HjxvHDDz/g6elZ6msdcOsL/JYtW0hOTla2onz77beZOXOmwdgvXrzIzz//rFwza9YsPvvsM+XVBVdX12KvU/x7ZoSPjw/169dn5cqVyjX9+vXj+vXr7NixA7g1M+Lll19m3rx5wK1ijLW1NZ9//jl+fn53fJY//vgDPz8/vvjiCzp06ADcWudi9uzZnDp1imeeeQaAsWPHkpaWxq5du9Dr9Tg4OPDFF1/QsmVLpa2RI0eSnZ3Nxo0bS+xr4sSJXLhwgU8++QS49WcgISGBU6dOKTue9OvXDyMjI+Lj40tso6SZEc7Ozvj7H8HSslGpz/m4yc4+TUbGLNatW4ibm5vaw3kgsq+2+iQH6pL4q09yoC6Jv/okB+qTHKirKP7PPvssjo6OXL16tVx2qpOZEU+Qhg0b0qFDBxo0aIC/vz+dOnXihRdeUBZ5LNpBokjLli3JysrizJkzSvGiSZMmBm0eP36c/fv3l7hzwqlTp3B3d+e3334jPDycpKQkLl26RMH/VjZMT0/H09OT5ORkvLy8lEJEUd9FTExMqFWrVqnPlZKSQsuWLZUiA9wqGmRlZXH27FllK88WLVoYXNOyZUuioqLIz88vdbvRf0tOTi62CKePjw/Lli0zOObl5aX83srKCltbWy5evHjXZzl79myx+6tUqYKlpaVSiCg6duTIEQBSU1PJzs6mY8eOBm3l5ubi7e2tfH7rrbdYs2YN6enp5OTkkJubS6NGjQzuqV+/vkEsHB0d+emnn0odr1arRavVFjt+86YxeXlPzg/+3FxjcnPzMDY2fmr+wZJ9tdUnOVCXxF99kgN1SfzVJzlQn+RAXeUdeylGPEGMjY3Zu3cvhw4dYs+ePaxYsYKwsDCSkpLK3IaVlZXB56ysLHr06MGiRYuKXevo6AhAjx49cHFxISYmBicnJwoKCvD09CQ3N/fBHugx9u+/eBqNRinC3Ov9Go3mju1lZWUBsGPHDqpVq2ZwXVGhID4+nunTpxMVFUXLli2xsbHh9ddfL5b7Bx13kZyccxQU2N3zfWrJyTlz94uEEEIIIYQQjw0pRjxhNBoNPj4++Pj4EB4ejouLC1u2bAFuzXLIycnBwsICgMOHD2NtbY2zs3Op7TVu3JhNmzbh6uqqLBZ5u8uXL5OSkkJMTAxt2rQB4Ouvvza4xsPDg/Xr13Pjxg1ldsThw4fL/EweHh5s2rSJwsJCZeZDYmIiNjY23Lx5E41GQ5MmTYp98T58+DC1a9dWZgKYmZmRn59/174SExMZOnSociwxMfGO60DArVkK48ePJygoqMzPVVb16tVDq9WSnp5O27ZtS7wmMTGRVq1aMX78eOXYqVOn7tr2nj17uHjx4j2PSa9/j5yce75NVTqdtlymjwkhhBBCCCEePilGPEGSkpLYt28fnTp1onLlyiQlJfH333/j4eHBjz/+SG5uLiNGjODll18mLS2NOXPmMHHiRIyMjEptc8KECcTExDBw4EBmzJiBg4MDqampxMfHs2rVKipUqIBOp2PlypU4OjqSnp7OrFmzDNoIDAwkLCyMUaNGMXv2bNLS0liyZEmZn2v8+PFER0czadIkJk6cSEpKCnPmzCE4ONhg7Onp6QQHBzNmzBiOHj3KihUriIqKUs67urpy4MABBgwYgFarpWLFisX6CgkJoV+/fnh7e+Pn58e2bdvYvHkzX3zxhcF127Zto1evXspnU1NTZQ2Jh83Gxobp06fz0ksvUVBQQOvWrbl69SqJiYnY2toydOhQateuzbp169i9ezempqZ06NABKyurO74y8iDCw0eV+OrO48ba2hqdTgeAra2tbOsphBBCCCHEE0KKEU8QW1tbDhw4QHR0NJmZmbi4uBAVFUWXLl348MMP6dChA7Vr1+a5555Dr9czcODAYrtR/JuTkxOJiYnMnDmTTp06odfrcXFxoXPnzhgZGaHRaIiPj2fy5Ml4enpSp04dli9fjq+vr9KGmZkZ27ZtY+zYsXh7e1OvXj0WLVpEnz59yvRc1apVY+fOnYSEhNCwYUMcHByUokrRGgwAQ4YMIScnh+bNm2NsbMyUKVMM1n+YO3cuY8aMoWbNmuj1ekpam7VXr14sW7aMJUuWMGXKFNzc3IiNjTV4npJoNJpy/V/3efPmUalSJRYsWMDvv/+Ovb09jRs3JjQ0FIAxY8bwww8/0L9/f+W1i379+hksRvowzZ0bw3283fHI6XRaNm58R4oQQgghhBBCPGGkGPEE8fDwYNeuXXe8JjIyssStGgESEhKU33/yySdERkaSmpqKpaUl3t7enD17lgkTJpCRkYG9vT2VK1dGr9cTGBjIsWPHMDMzA8DX15cJEyaQkJDAyJEjadCgAfv372fDhg2EhIRw8OBBxo0bx+DBg6levbrS565du5g/fz4nTpzA2NiYli1bsmzZMmrWrEnbtm05cuQIR44cYcyYMURHR/PFF18QFham3G9qakp0dDTvvPNOic/XokULli9fTkhICMePH8fR0ZGhQ4dy6dIl5RpfX188PT3p0qUL69ev5/Lly/z666/KKyJFRYk1a9awZs0aAAoLC4mOjmbq1KkGr2m88847LFmyhDNnzuDm5sbLL7/Miy++qBRBNBoNMTEx7Nixg9zcXGrXrk1UVBQ9e/YkIiLCoFCk0WiYMmWKsiXqlStXmDhxIn369CErK4vq1asTGhpKbGys8ipLbGys8kwJCQmsXr2akJAQ7O3tMTY2ZsSIETRr1oyrV6+W+uelNFrtGLRaj3u+71HKyTnD5ctRZGZmSjFCCCGEEEKIJ4wUI/6Dzp8/z8CBA1m8eDEBAQFcu3aNgwcPKl+i9+3bh7m5OQkJCaSlpTFs2DB0Oh2vvvqq0sbatWsZN24ciYmJAGRkZNC+fXtGjhzJ0qVLycnJYebMmfTr148vv/wSuLVFZnBwMF5eXmRlZREeHk5AQADHjh3DyMiIrKwsunfvTseOHdmwYQOnT59WvpyXxZ9//knXrl0JCgpi3bp1/PLLL4waNQpzc3ODL/5r165lxIgRHDlyhO+++47Ro0dTo0YNRo0axebNm2nYsCGjR49m1KhRpfa1ZcsWpkyZQnR0NH5+fmzfvp1hw4ZRvXp12rVrp1wXGRnJ4sWLef3111mxYgWDBg3ijz/+wMHB4Y7P8sorr3Dy5Ek+//xzKlasSGpqKjn/W8ThyJEjNG/enC+++IL69esrRaKoqCji4uJYs2YNHh4eREVFsWXLFtq3b19qPyVt7QlgY1MFS8sadxyj2szM8snIMCU/P5+8vDy1h/PQFD3L0/RMTxrJgbok/uqTHKhL4q8+yYH6JAfqelTx1xSWNJddPHGCgoLIyMhg69atd7326NGjNGnShLS0NGXLz9vb2bZtG2fOnFG2CX333XcJCQnh6tWrGBkZ4evrS2ZmpsErAvPnz+fgwYPs3r1bOXb27FmcnZ3p378/27dvLzaOwsJCsrOz+emnn/D09GTlypWEhoZy9uxZZSHMd999l3HjxtGkSRNat25NdHR0qc8VFhbGpk2bSE5OVmYPvP3228ycOdNg7BcvXuTnn39Wrpk1axafffYZJ0+eBG6tPTF16lSmTp2qtB0XF8fUqVMZMGAAGzZsICcnByMjI4NtMatUqULdunXZsWMHcGu2w8svv6ysNXH9+nWsra35/PPP6dy58x1z1LNnTypWrKjMzrhdWloabm5u/PDDDwZbezo5OfHSSy8REhICwM2bN3Fzc6NJkyal/rmIiIgocSbNxo0bDbaJFUIIIYQQQvy3ZGdnExgYyNWrV8vllXWZGfGUiIuLK/O1DRs2pEOHDjRo0AB/f386derECy+8QIUKFZTzt38RbdmyJVlZWZw5c0YpXjRp0sSgzePHj7N///4SFz18/vnnmT9/PmlpaURHR3P8+HGuXLminE9PT8fT05Pk5GS8vLyUQkRR3wCrVq0y+OJdkuTkZFq2bKkUGQB8fHzIysri7Nmz1Khx63/6W7RoYXBNy5YtiYqKIj8/X9mZozRz585l+vTpNG3alNDQUHr37q2ci4+PL1Y88PLyUn5vZWWFra1tmXa3GDduHH369OHo0aN06tSJXr160apVq1Kvv3r1KufPn+fZZ59VjpmYmNC0adMS184oMnv2bIKDg5XPmZmZODs7s3ZtLSwtG911nGrKzj5NRsYs1q1biJubm9rDeWjy8vLYu3cvHTt2lH21VSI5UJfEX32SA3VJ/NUnOVCf5EBdRfG/fcZ3eZBixH+QsbExe/fu5dChQ+zZs4cVK1YQFhZWbOvMO7GysjL4nJWVRY8ePVi0aFGxax0dHbGysqJ79+64uLgQFxeHk5MTBQUFeHp6kpub+8DP9KhUrlyZypUrY2RkRJUqVQx2s7CxsSl2/b9/eGo0GmUByjvp0qULf/zxBzt37mTv3r106NCBCRMm3NMuJWWh1WoNZncUuXnTmLy8x/sHf26uMbm5eRgbGz+V/0iZmpo+lc/1JJEcqEvirz7Jgbok/uqTHKhPcqCu8o69FCP+ozQaDT4+Pvj4+BAeHo6LiwtbtmwBbs1yyMnJwcLCAoDDhw9jbW2Ns7Nzqe01btyYTZs24erqiolJ8T9Wly9fJiUlhZiYGNq0aQPA119/bXCNh4cH69ev58aNG8rsiMOHD5f5mTw8PNi0aZOyGCVAYmIiNjY2Bgtp/rvocvjwYWrXrq3MijAzMyM/P/+ufSUmJjJ06FDlWGJiIvXq1SvzeO+mUqVKDB06lKFDh9KmTRtCQkJYsmSJskbE7WO0s7PD0dGRpKQknnvuOeDWaxrff/89jRs3vue+c3LOUVBg93AepJzk5JxRewhCCCGEEEKI+yTFiP+gpKQk9u3bR6dOnahcuTJJSUn8/fffeHh48OOPP5Kbm6tsrZmWlsacOXOYOHEiRkZGpbY5YcIEYmJiGDhwIDNmzMDBwYHU1FTi4+NZtWoVFSpUQKfTsXLlShwdHUlPT2fWrFkGbQQGBhIWFsaoUaOYPXs2aWlp9zQTYPz48URHRzNp0iQmTpxISkoKc+bMITg42GDs6enpBAcHM2bMGI4ePcqKFSuIiopSzru6unLgwAEGDBiAVqulYsWKxfoKCQmhX79+eHt74+fnx7Zt29i8eTNffPFFmcd7J+Hh4TRp0oT69euj1+vZvn07Hh63dreoXLkyFhYW7Nq1i+rVq2Nubo6dnR1Tpkxh4cKF1K5dm7p16/LGG2+QkZFxX/1nZUWTkaH+3p5GRiaYmhafuVFEp9OW65arQgghhBBCiPIhxYj/IFtbWw4cOEB0dDSZmZm4uLgQFRVFly5d+PDDD+nQoQO1a9fmueeeQ6/XM3DgQIPdKEri5OREYmIiM2fOpFOnTuj1elxcXOjcuTNGRkZoNBri4+OZPHkynp6e1KlTh+XLlytbaQJYW1uzbds2xo4di7e3N/Xq1WPRokX06dOnTM9VrVo1du7cSUhICA0bNsTBwUEpqtxuyJAh5OTk0Lx5c4yNjZkyZQqjR49Wzs+dO5cxY8ZQs2ZN9Hp9iWsu9OrVi2XLlrFkyRKmTJmCm5sbsbGxBs/zb9988w1Xr15l6dKlBluE3u6DDz5g8ODBNG3alE8++YS0tDQsLCxo06YNU6dONVjrIjw8nJdffpnmzZuTlJTEtGnTePXVVxkwYAAWFhYMHz6cgICA+9raE4z+90tddnYmvPHGK+h0uhLP29rayraeQgghhBBCPIGkGPEf5OHhwa5du+54TWRkZIm7LAAkJCSUeLx27dps3ry51Db9/PyUHSuK/PuLfosWLTh27Ngdr7mTtm3bcuTIkTteY2pqSnR0NO+8806J51u0aMHx48cNjgUFBRUrIIwbN45x48aV2s+/x7169WqmTJnC6tWrOXfuHE5OTsXuWb16NTNmzOC9997j3LlzBot5FsU9JSUFGxsbfvvtN0aPHk1WVhb5+fmYmJjg4OBQbCeQ+2FtPRmt1uOB2nhQOTlnyM6OQqfTUbNmTVXHIoQQQgghhHi4pBghxCOQlZXFhx9+yHfffceFCxeIi4sjNDTU4JrTp09z6NAhNm3axP79+9m8eTOBgYHF2qpcuTL29vY4OjoSHh7OoEGDSE1NpU6dOg9tvBYWTlhYqF8A0OvVHoEQQgghhBCiPEgxQjwxxo4dy4YNG0o8N3jwYN59991HPKKy++ijj6hbty516tRh8ODBDBo0iFdffdXgtYvc3FwKCgqYOXMmgwcPZvXq1SUWI25XtMjo/e5Iotfr0d/2jT8zMxMAE5N8TE3z7qvNh8XMLB8zM1Py8/PJy1N3LI9S0bP+l575cSM5UJfEX32SA3VJ/NUnOVCf5EBdjyr+msJ7mQMvhIouXryofFn+N1tbWypXrvyIR1R2Pj4+9OvXjylTpnDz5k2qVq3KsmXLePbZZwEoKCjA19eX8PBwevfujZGREdWqVeOXX37Bzc0NuPWaRrt27bhy5Qr29vacP3+eF154gT/++IPff/8dMzMzXF1d7+k1jYiIiBJfx9m4cSOWlpYP7fmFEEIIIYQQT5bs7GwCAwO5evVquSwaLzMjxBOjcuXKj3XBoTQpKSkcOXJE2TrVxMSEAQMGsGvXLgYNGgTA7t270ev1jBgxQtnPt2PHjqxZs4Z58+YZtFe9enUKCwvJzs6mYcOGbNq0Sdnu817Nnj2b4OBg5XNmZibOzs6sXVsLS8tG99Xmw5KdfZqMjFmsW7dQKcj8F+Tl5bF37146duwo+2qrRHKgLom/+iQH6pL4q09yoD7JgbqK4t+uXbty7UeKEUKUs9WrV3Pz5k2DBSsLCwvRarW8+eab2NnZsXr1av755x/ltQu4NVvixx9/JDIy0mBr0oMHDyozQWxsbB5obFqtFq22+NaZ1679RW5u+gO1/aBycs6Rm5uHsbHxf/IfIVNT0//kcz9OJAfqkvirT3KgLom/+iQH6pMcqKu8Yy/FCCHK0c2bN1m3bh1RUVF06tTJ4FyvXr344IMP6Nu3L59++inx8fHUr19fOZ+fn0/r1q3Zs2cPnTt3Vo67ublhb29fruPW698jJ6dcuygTnU5bLlPChBBCCCGEEOqSYoQQ5Wj79u1cuXKFESNGYGdnR1BQEBkZGWzdupU+ffqwevVqbty4gU6no1+/fgYLWgJ07dqV1atXGxQj7ubPP/9Utkc9d+4c3bp146uvvuK5554rcxvh4aOwtrYu8/XlxdHRkUqVKqk9DCGEEEIIIcRDJsUI8VAFBQWxdu1a4Na0nho1ajBkyBBCQ0P5+uuvDd47qlixIs2aNWPRokU0aNBAOZ6bm0t0dDTvv/8+v/32G5aWltSpU4eRI0cyePDgcp8uFBERwdatW5Uv9A9i9erV+Pn5YWdnV+xcnz59WLx4Md9//z3jxo0rVogouubFF1/k0qVLBsdvL2r825IlS1iyZInBsYMHD95TMWLu3BgKCsp8ebnR6bRs3PiOFCSEEEIIIYR4ykgxQjx0nTt3JjY2Fr1ez86dO5kwYQKmpqa0bNkSuLWgo62tLefOnSMkJIRu3bqRmpqKmZkZubm5+Pv7c/z4cebNm4ePjw+2trYcPnyYJUuW4O3tTaNGjdR9wHuwbdu2Us81b96cu21m069fP/r16weAr6/vXa9PS0sr9tnNzY1u3bqVbcD/o9WOQav1uKd7HracnDNcvhxFZmamFCOEEEIIIYR4yhjd/RIh7o1Wq6Vq1aq4uLgwbtw4/Pz8+Oyzz5TzlStXpmrVqjRu3JipU6dy5swZfvnlFwCio6M5cOAA+/btY8KECTRq1IhnnnmGwMBAkpKSqF279l3737VrF61bt8be3h6dTkf37t05deqUwTVnz55l4MCBODg4YGVlRdOmTUlKSiIuLo7IyEiOHz+ORqNBo9EQFxdHWloaGo3GYLZERkYGGo2GhIQE4NYaDyNGjMDNzQ0LCwvq1KnDsmXL7juOn3zyCQ0aNMDCwgKdToefnx/Xr18nIiKCtWvX8umnnypjLBrDkSNH8Pb2xtzcnKZNm/LDDz/cV98WFk5YWdVU9ZeFhfN9x04IIYQQQgjxeJOZEaLcWVhYcPny5WLHr169Snx8PICyNeX777+Pn58f3t7exa4v62q6169fJzg4GC8vL7KysggPDycgIIBjx45hZGREVlYWbdu2pVq1anz22WdUrVqVo0ePUlBQQP/+/Tlx4gS7du3iiy++AMDOzo6//vrrrv0WFBRQvXp1Pv74Y3Q6HYcOHWL06NE4OjoqsxvK6vz58wwcOJDFixcTEBDAtWvXOHjwIIWFhUyfPp3k5GQyMzOJjY0FwMHBgaysLLp3707Hjh3ZsGEDp0+fZsqUKXfsR6/Xo9frlc+ZmZkAmJjkY2qad09jftjMzPIxMzMlPz+fvDx1x/IoFT3rf+mZHzeSA3VJ/NUnOVCXxF99kgP1SQ7U9ajiL8UIUW4KCwvZt28fu3fvZtKkScrx6tWrA7eKBgA9e/akbt26APz222/4+vo+UL99+vQx+LxmzRoqVarEyZMn8fT0ZOPGjfz99998++23ODg4AFCrVi3lemtra0xMTKhateo99WtqakpkZKTy2c3NjW+++YaPPvrovooRN2/epHfv3ri4uAAYrKthYWGBXq83GGNcXBwFBQWsXr0ac3Nz6tevz9mzZxk3blyp/SxYsMBgzEWGDk3F0vLcPY25fAwlOTmZ5ORktQfyyO3du1ftIfznSQ7UJfFXn+RAXRJ/9UkO1Cc5UNf+/fvLtX0pRoiHbvv27VhbW5OXl0dBQQGBgYFERETw7bffArcWU7S0tOTw4cO89tprvPvuu8q9d1sToSx+++03wsPDSUpK4tKlSxT8byXG9PR0PD09OXbsGN7e3koh4mF66623WLNmDenp6eTk5JCbm3tfa1w0bNiQDh060KBBA/z9/enUqRMvvPACFSpUKPWe5ORkvLy8MDc3V44VrdNRmtmzZxMcHKx8zszMxNnZmbVra2Fpee/jfpiys0+TkTGLdesW4ubmpupYHqW8vDz27t1Lx44dZV9tlUgO1CXxV5/kQF0Sf/VJDtQnOVBXUfxv33ygPEgxQjx07dq145133sHMzAwnJydMTAz/mLm5uWFvb0+dOnW4ePEi/fv358CBAwC4u7sr60fcrx49euDi4kJMTAxOTk4UFBTg6elJbm4ucGtWwb0yMrq1vMrtxZJ/T1uKj49n+vTpREVF0bJlS2xsbHj99ddJSkq65/6MjY3Zu3cvhw4dYs+ePaxYsYKwsDCSkpIe6hdzrVaLVqstdvzatb/IzU1/aP3cj5ycc+Tm5mFsbPyf/EeorK8lifIjOVCXxF99kgN1SfzVJzlQn+RAXeUdeylGiIfOysrK4LWHO5kwYQILFixgy5YtBAQEEBgYSGhoKD/88EOxdSPy8vLIzc3Fysqq1PYuX75MSkoKMTExtGnTBoCvv/7a4BovLy9WrVrFP//8U+LsCDMzM/Lz8w2OFe3mcP78eWVc/976MzExkVatWjF+/Hjl2L8XzrwXGo0GHx8ffHx8CA8Px8XFhS1bthAcHFziGD08PFi/fj03btxQZkccPnz4vvrW698jJ+e+h/7Q6HRabG1t1R6GEEIIIYQQ4iGTYoRQlaWlJaNGjWLOnDn06tWLqVOnsmPHDjp06MC8efNo3bo1NjY2fPfddyxatIjVq1crrz0UbVv5ww8/KMcqVKiATqdj5cqVODo6kp6ezqxZswz6HDhwIK+99hq9evViwYIFODo68sMPP+Dk5ETLli1xdXXl9OnTHDt2jOrVq2NjY4OFhQUtWrRg4cJbrwxcvHiRl19+2aDd2rVrs27dOnbv3o2bmxsjR44kMTHRYK2HskpKSmLfvn106tSJypUrk5SUxN9//42Hx63tNl1dXdm9ezcpKSnodDrs7OwIDAwkLCyMUaNGMXv2bNLS0pg6deo99w0QHj4Ka2vr+7r3QVhbW6PT6ZTPtra2sq2nEEIIIYQQTyEpRgjVTZw4kTfeeIOPP/6Yfv36sXfvXpYuXcp7773H9OnTsbS0xMPDg8mTJ+Pp6XnHtoyMjIiPj1eurVOnDsuXLzdYFNPMzIw9e/Ywbdo0unbtSm5uLjdu3GD9+vW0bNmSPn36sHnzZtq1a0dGRgaxsbEEBQWxZs0aRowYQZMmTahTpw6LFy+mU6dOSrtjxozhhx9+oH///mg0GmrVqkXFihXvKya2trYcOHCA6OhoMjMzcXFxISoqii5dupCQkEBYWBi+vr40bdqUrKws9u/fj6+vL9u2bWPs2LF4e3tTr149atasyc8//3zP/c+dG8P/ltp4pHQ6LRs3viMFCCGEEEIIIZ5yUowQD1VcXJzB59zcXGXbTl9f3xIXqHR2djZYf0Gr1TJr1qxiMxrKys/Pj5MnTxoc+3e/Li4ufPLJJ8D/z7AoKnRotVrl3O08PDw4dOhQqe1qtVpiY2OV7TYjIiLYunWrwesc/45PaTw8PNi1a9cdr9myZQv29vYGx1q0aGHQn6+vL1OmTLnnRTS12jFotR73dM+Dysk5w+XLUWRmZkoxQgghhBBCiKecFCNEMZ988gmRkZGkpqZiaWmJt7c3n376KRMmTCAjIwNvb2/efPNN9Ho9gYGBLF++3KDg4OnpiYmJCRs2bKBBgwbs37+fEydOEBISwsGDB7GysqJTp04sXbpUmTmwa9cu5s+fz4kTJzA2NqZly5YsW7aMmjVrKuM6cuQIY8aMITk5GU9PT8LCwsr8TFeuXGHixIns2bOHrKwsqlevTmhoKMOGDVMWhCxaC6Jt27YkJCRQUFDA/PnzWblypfKKxMKFC+ncubPS7tmzZwkJCWH37t3o9Xo8PDx46623ePbZZ4uN4dSpU3Ts2JGuXbuyYsUKNBpNqeP9448/mDhxIl9//TW5ubm4urry+uuvU69ePWVV26KdNYYOHUpcXBzXr19n3LhxbN68GRsbG6ZPn37XuOj1evR6vfI5MzMTABubKlha1rjr/Q+TmVk+GRmm5Ofn/6f3lJZ9tdUnOVCXxF99kgN1SfzVJzlQn+RAXY8q/lKMEAbOnz/PwIEDWbx4MQEBAVy7do2DBw8qMwD27duHubk5CQkJpKWlMWzYMHQ6Ha+++qrSxtq1axk3bhyJiYkAZGRk0L59e0aOHMnSpUvJyclh5syZ9OvXjy+//BKA69evExwcjJeXF1lZWYSHhxMQEMCxY8cwMjIiKyuL7t2706pVK1JSUjhx4gR9+vQBbm1faWxsDMDJkyepUaP4l+hXXnmFkydP8vnnn1OxYkVSU1PJ+d8KjUeOHKF58+Z88cUX1K9fXymsLFu2jKioKN577z28vb1Zs2YNPXv25Oeff6Z27dpkZWXRtm1bqlWrxmeffUbVqlU5evSospXo7X788Uf8/f0ZMWIE8+fPJz09nXr16pWah2effRZjY2MOHDiAlZUVJ0+exNraGmdnZzZt2kSfPn1ISUnB1tZW2R0kJCSEr776ik8//ZTKlSsTGhrK0aNH7zgrYsGCBURGRhY7PnRoKpaW50q9r/wMJTk5meTkZBX6frzIvtrqkxyoS+KvPsmBuiT+6pMcqE9yoK79+/eXa/uawpLmzYv/rKNHj9KkSRPS0tJwcXExOBcUFMS2bds4c+YMlpaWALz77ruEhIRw9epVjIyM8PX1JTMzk6NHjyr3zZ8/n4MHD7J7927l2NmzZ3F2diYlJQV3d/di47h06RKVKlXip59+wtPTk5UrVxIaGkpaWhoXLlwAYOPGjcyZM4dPP/1U+WLv6upabCtRgJ49e1KxYkXWrFlT7FxJC2ECVKtWjQkTJhAaGqoca968Oc2aNeOtt95i5cqVTJ8+nbS0tBJ35Sh6TePtt9+me/fuhIWFMW3aNABu3rxJWlpasXuKBAQE8MILLzBnzpxi5xISEmjXrh1XrlxRXtPIyspCp9OxYcMG+vbtC8A///xD9erVGT16NNHR0SX2U9LMCGdnZ/z9j2Bp2ajEe8pLdvZpMjJmsW7dwoe6femTRvbVVp/kQF0Sf/VJDtQl8Vef5EB9kgN1FcX/2WefxdHRkatXr5bLDncyM0IYaNiwIR06dKBBgwb4+/vTqVMnXnjhBeWVgIYNGyqFCLg1KyErK4szZ84oxYsmTZoYtHn8+HH2799f4u4Mp06dwt3dnd9++43w8HCSkpK4dOmSMrsgPT0dT09PkpOT8fLywtraWtk29Pnnn2fOnDnUqFHjrluJjhs3jj59+nD06FE6depEr169aNWqVanXZ2Zmcu7cOXx8fAyO+/j4cPz4ceDW1p7e3t4lFiKKpKen07FjR1599VWDnS1MTEzuOOYpU6Ywbtw49uzZg5+fH3369MHLy6vU60+dOkVubq7B6yEODg7UqVOn1Hvg1joXWq222PGbN43Jy3u0P/hzc43Jzc3D2NhY/tFB9tV+HEgO1CXxV5/kQF0Sf/VJDtQnOVBXecdeihHCgLGxMXv37uXQoUPs2bOHFStWEBYWRlJSUpnbsLKyMviclZVFjx49WLRoUbFrHR0dAejRowcuLi7ExMTg5OREQUEBnp6e5ObmPtgD/U+XLl34448/2LlzJ3v37qVDhw5MmDCBJUuW3HebRa9H3EmlSpVwcnLigw8+YPjw4WWuKI4cORJ/f3927NjBnj17WLBgAVFRUUyaNOm+x3svcnLOUVBg90j6+v8+zzzS/oQQQgghhBDqkWKEKEaj0eDj44OPjw/h4eG4uLiwZcsW4NYsh5ycHOWL+OHDh5W1DErTuHFjNm3aVOorFJcvXyYlJYWYmBjatGkDwNdff21wjYeHB+vXr+fGjRuYm5srfd+LSpUqMXToUIYOHUqbNm0ICQlhyZIlyhoR+fn5yrW2trY4OTmRmJhI27ZtleOJiYk0b94cAC8vL1atWsU///xT6uwICwsLtm/fTteuXfH392fPnj3Y2NiUabzOzs6MHTuWsWPHMnv2bGJiYpg0aVKJ461ZsyampqYkJSUpa2ZcuXKFX3/91WD8ZaXXv8f/ltR4pHQ6bblMARNCCCGEEEI8XqQYIQwkJSWxb98+OnXqROXKlUlKSlJ2kvjxxx/Jzc1lxIgRvPzyy6SlpTFnzhwmTpyIkZFRqW1OmDCBmJgYBg4cyIwZM3BwcODrr78mKCiI7777Dm9vb3Q6HStXrsTR0ZH09PRi23oGBgYSFhbGqFGjmD17Nmlpafc0qyE8PJwmTZpQv3599Ho927dvx8Pj1taVlStXxsLCgl27dlG9enXMzc1ZunQpAIsWLaJmzZo0atSI2NhYjh07xvvvvw/AwIEDee211+jVqxcLFizA0dGRH374AScnJ1q2bKn0bWVlxY4dO+jSpQtdunRh165dJb6ycrupU6fSpUsX3N3duXLlCvv371fG6+LigkajUYocFhYWWFtbM2LECEJCQtDpdFSuXJmwsLA75uXO8Rp11zE+LNbW1uh0OuBWEUi29RRCCCGEEOLpJ8UIYcDW1pYDBw4QHR1NZmYmLi4uREVF0aVLFz788EM6dOhA7dq1ee6559Dr9QwcOJCIiIg7tlk0w2DmzJl06tQJvV6vvJ5hZGSEkZER8fHxTJ48GU9PT+rUqcPy5cvx9fVV2rC2tmbbtm2MHTsWb29v6tWrx6JFi+jTpw/e3t7FFp/8NzMzM6WIYWFhQZs2bYiPjwdurd+wfPly5s6dS3h4OG3atMHX15dKlSoxevRopk2bxsWLF6lXrx6fffYZtWvXVtrcs2cP06ZNo2vXrty8eZN69erx1ltvFevf2tqazz//HH9/f7p168bOnTuLvc5yu/z8fCZMmMDZs2extbWlc+fOSoGkWrVqREZGMmvWLIYNG8aQIUOIi4vj9ddfV16JsbGxYdq0aVy9evWOuSnN3LkxlLApSLnQ6bRs3PiOFCGEEEIIIYT4D5HdNESpcnNzlVcC4NZuGhkZGWzduvWB2y5tBwu12vm3op0wjh079tDafBJkZmZiZ2dHq1bb0Go9yr2/nJwz6PVRfPxxNDVr1iz3/p4EeXl57Ny5k65du8qCTSqRHKhL4q8+yYG6JP7qkxyoT3KgrqL4t27dmooVK8puGqJsPvnkEyIjI0lNTcXS0hJvb28+/fRTJkyYQEZGBt7e3rz55pvo9XoCAwNZvny5UnDw9fXF09MTExMTNmzYQIMGDdi/fz8nTpwgJCSEL774AmNjY1588UWWLl1KxYoVAdi1axfz58/nxIkTGBsb07JlS5YtW2bw5fLIkSOMGTOG5ORkPD09CQsLK/MzXblyhYkTJ7Jnzx6ysrKoXr06oaGhDBs2TNkC0tvbG4C2bduSkJBAQUEB8+fPZ+XKlcprJgsXLqRz585Ku2fPniUkJITdu3ej1+vx8PDgrbfeMtiRosipU6fo2LEjXbt2ZcWKFWg0mlLHGxcXx9SpU9mwYQPTpk3jzJkzdO3alXXr1vHxxx8zZ84crl69qsTR2NgYuLXNZlhYGB988AEZGRl4enqyaNEiZYbI5cuXmThxIgcOHODKlSvUrFmT0NBQBg4cqPTt6+uLl5cX5ubmrFq1CjMzM8aOHVvq7JWStvYEsLGpgqVljTJk58GYmeWTkWFKfn4+eXl55d7fk6AoDhIP9UgO1CXxV5/kQF0Sf/VJDtQnOVDXo4q/FCOeIufPn2fgwIEsXryYgIAArl27xsGDByma/LJv3z7Mzc1JSEggLS2NYcOGodPpePXVV5U21q5dy7hx40hMTAQgIyOD9u3bM3LkSMzNzbly5Qp//fUX/fr148svvwTg+vXrBAcH4+XlRVZWFuHh4QQEBHDs2DGMjIzIysqie/fudOzYkQ0bNnD69GmmTJlS5ud65ZVXOHnyJJ9//jkVK1YkNTWVnP+trnjkyBGaN29Ot27d+PLLL/n222+xtrYmLy+P3NxctFotAQEBuLi40LNnT37++Wdq165NVlYWbdu2pVq1anz22WdUrVqVo0ePKluK3u7HH3/E39+fESNGMH/+/DKNOTs7m+XLlxMfH8+1a9fo3bs3AQEB2Nvbs3PnTl588UVWrFjBypUrlUU99Xo9BQUFjBgxgpkzZ7JlyxY6d+7MTz/9RO3atblx4wZNmjRh5syZ2NrasmPHDl588UVq1qypLKpZlMPg4GCSkpL45ptvCAoKwsfHh44dOxYb54IFC4iMjCx2fOjQVCwtz5XpWR/cUJKTk0lOTn5E/T0Z9u7dq/YQ/vMkB+qS+KtPcqAuib/6JAfqkxyoa//+/eXavrym8RQ5evQoTZo0IS0tDRcXF4NzQUFBbNu2jTNnzmBpaQnAu+++S0hICFevXsXIyAhfX18yMzM5evSoct/8+fM5ePAgu3fvVo6dPXsWZ2dnUlJScHd3LzaOS5cuUalSJX766Sc8PT1ZuXIloaGhnD17VtkJ491332XcuHFler2iZ8+eVKxYkTVr1hQ7V/Saxr59+5RdJABat27NoEGDGDduHLa2tlSuXJnmzZvTrFkz3nrrLVauXMn06dNJS0srcSeMotc03n77bbp3705YWBjTpk274ziLxMXFMWzYMFJTU5XZIWPHjmX9+vX89ddfWFtb8+effzJw4ECqVavGvHnzOHfuHO3bt+err77Cw8NDGZOfnx/NmzfntddeK7Gv7t27U7duXWUxT19fX/Lz8zl48KByTfPmzWnfvj0LFy4sdn9JMyOcnZ3x9z+CpWWjMj3vg8jOPk1GxizWrVuozHL5r8vLy2Pv3r107NhRpiWqRHKgLom/+iQH6pL4q09yoD7JgbqK4v/ss8/i6Ogor2mIu2vYsCEdOnSgQYMG+Pv706lTJ1544QUqVKignC8qRAC0bNmSrKwszpw5oxQvmjRpYtDm8ePH2b9/f4k7K5w6dQp3d3d+++03wsPDSUpK4tKlS8rsgvT0dDw9PUlOTlZeHbi977IaN24cffr04ejRo3Tq1IlevXrRqlUrg2scHByoVasWcOsL9V9//UXPnj2VYwA+Pj4cP34cgGPHjuHt7V3qlpxF4+/YsSOvvvoqU6dOLfN4ASwtLQ1eU6lSpQqurq5KHKtVq4abmxvXrl2jVq1apKSkkJ+fj7+/v0E7er1e2WkiPz+f1157jY8++og///yT3Nxc9Hq9QU7h1pajt3N0dOTixYsljlOr1aLVaosdv3nTmLy88v/Bn5trTG5uHsbGxvIPzb+YmppKTFQmOVCXxF99kgN1SfzVJzlQn+RAXeUdeylGPEWMjY3Zu3cvhw4dYs+ePaxYsYKwsDCSkpLK3Ma/d3go2p1h0aJFxa4t2hGjR48euLi4EBMTg5OTEwUFBXh6epKbm/tgD/Q/Xbp04Y8//mDnzp3s3buXDh06MGHChHva2vPfLCws7npNpUqVcHJy4oMPPmD48OH3VA38919cjUZT4rGiwk1WVhbGxsZ8//33yhoSRYoKGK+//jrLli0jOjqaBg0aYGVlxdSpU4vF+U79lFVOzjkKCuzu6Z77kZNzptz7EEIIIYQQQjx+pBjxlNFoNPj4+ODj40N4eDguLi5s2bIFuDXLIScnR/kifvjwYaytrXF2di61vcaNG7Np0yZq167Nli1b6NWrl8H5y5cvk5KSQkxMDG3atAHg66+/NrjGw8OD9evXc+PGDWV2xOHDh+/puSpVqsTQoUMZOnQobdq0ISQkhCVLliiLb+bn5yvX2traKtuJtm3bVjmemJiorK3g5eXFqlWr+Oeff0qdHWFhYcH27dvp2rUr9erVw8HBgR9//PGexl1W3t7e5Ofnc/HiRSWO/5aYmMjzzz/P4MGDASgoKODXX3+lXr16pbbr6+vLmTNnSm2zNHr9e/xvWY5yp9Npy2XalxBCCCGEEOLxJcWIp0hSUhL79u2jU6dOVK5cmaSkJGUniR9//JHc3FxGjBjByy+/TFpaGnPmzGHixIkYGRmV2uaECROIiYkB4LfffuPUqVOkpqYSHx/PqlWrqFChAjqdjpUrV+Lo6Eh6ejqzZs0yaCMwMJCwsDBGjRrF7NmzSUtLu6dZDeHh4TRp0oT69euj1+vZvn07Hh63tp2sXLkyFhYW7Nq1i+rVq2Nubo6dnR0hISHMmTOHmjVr0qhRI2JjYzl27Bjvv/8+AAMHDuS1116jV69eLFiwAEdHR3744QecnJxo1aoV/fv3B27NFNmxYwedOnUiPz+frKysEl9ZeVDu7u4MGjSIIUOGEBUVhbe3N3///Tf79u3Dy8uLbt26Ubt2bT755BPefPNNJk2axIsvvshff/11x2LE/QoPH1Uuz/lv1tbWuLm5UalSpXLvSwghhBBCCPH4kGLEU8TW1pYDBw4QHR1NZmYmLi4uREVF0aVLFz788EM6dOhA7dq1ee6559Dr9QwcOLDULR+LFM0wcHd3JyIigjlz5uDi4kLnzp0xMjJCo9EQHx/P5MmT8fT0pE6dOixfvlzZjhJufeHctm0bY8eOxdvbm3r16rFo0SL69OlTpucyMzNTihgWFha0adOG+Ph4AExMTFi+fDlz584lPDycNm3akJCQwOTJk7l69SrTpk3j4sWL1KtXj88++4zatWsrbe7Zs4dp06bRtWtXbt68Sb169XjrrbeK9W9tbc2ePXvw9/enW7du7Ny5s9jrLA9DbGws8+fPZ9q0afz5559UrFiRFi1a0L17dwBefvllfv/9d0JCQoBb61D06tWLq1evPvSxzJ0bwz2+2XFfdDotGze+U/4dCSGEEEIIIR4vheKp99577xVaWFgU9uzZ0+B4z549C4cNG1ZYWFhY+Pbbbxc+88wzhaampoXu7u6F69atM7gWKNyyZUthYWFh4f79+wuBwitXrijnf/jhh0Kg8PTp04WFhYWFsbGxhXZ2doXbtm0rdHd3L7SwsCjs06dP4fXr1wvj4uIKXVxcCu3t7QsnTZpUePPmTaWdGzduFE6bNq3Qycmp0NLSsrB58+aF+/fvL/OzfvLJJ4X16tUrNDMzK3RxcSlcsmSJwXkXF5fCuXPnFg4YMKDQ0tKy0MnJqfDNN980OA8ov1xcXAoLCwsL58yZU9iwYUPluvz8/MLIyMjCatWqFZqZmRU2bNiw8PPPP1fOnz59uhAo3LRpU6Gvr2+hhYVFoZeXV+GhQ4fK9BxpaWmF3bt3L7S3ty+0tLQsrFevXuGOHTuUdm//NXTo0MLCwsLCrKyswhdffLHQysqqsGrVqoVLliwpbNu2beGUKVPKHL+rV68WAoWtWm0rbNcutVx/tWixv9Dbu3thampqmcf3X5Cbm1u4devWwtzcXLWH8p8lOVCXxF99kgN1SfzVJzlQn+RAXUXxv3TpUiFQePXq1XLpR2ZG/Af07duXcePGcenSJeXYP//8w65du9i5cydbtmxhypQpREdH4+fnx/bt2xk2bBjVq1enXbt2991vdnY2y5cvJz4+nmvXrtG7d28CAgKwt7dn586d/P777/Tp0wcfHx/ltYiJEydy8uRJ4uPjcXJyYsuWLXTu3JmffvpJmdVQmu+//55+/foRERFB//79OXToEOPHj0en0xEUFKRc9/rrrxMaGkpkZCS7d+9mypQpuLu707FjR7799lsqV65MbGwsnTt3LraYZJFly5YRFRXFe++9h7e3N2vWrKFnz578/PPPBuMMCwtjyZIl1K5dm7CwMAYOHEhqaiomJnf+qzdhwgRyc3M5cOAAVlZWnDx5UlnfY9OmTfTp04eUlBRsbW2VNUBCQkL46quv+PTTT6lcuTKhoaEcPXr0jlunlrS1J4CNTRUsLWuUdttDYWaWT0aGKfn5+eTl5ZVrX0+SolhITNQjOVCXxF99kgN1SfzVJzlQn+RAXY8q/prCwsLCcu1BPBZq1KiBRqPhjz/+AGDlypVERkYqixvWr1+flStXKtf369eP69evs2PHDuDWwphFC1gmJCTQrl07rly5gr29PfD/W2WePn0aV1dX4uLiGDZsGKmpqcoWl2PHjmX9+vX89ddfynoEnTt3Jj09nfT0dAoKCpQFNovWsRg8eDCpqak0b96c11577Y7POGjQIP7++2/27NmjHJsxYwY7duzg559/BsDV1RUPDw8+//xz5ZoBAwaQmZnJzp07iz1rkYiICLZu3cqxY8fo0qULu3fvxsTERFlAEyAnJ4dmzZpx+PBh0tLScHNzY9WqVYwYMQKAkydPUr9+fZKTk6lbt+4dn8XLy4s+ffowZ86cYudKin9WVhY6nY4NGzbQt29f4FbBqXr16owePZro6OgS+4mIiCAyMrLY8Y0bNxbbMlQIIYQQQgjx35GdnU1gYCBXr14tlwXnZWbEf0RUVBSjRo1Cr9ej1Wp5//33GTBgAEZGRiQnJzN69GiD6318fFi2bNkD9WlpaakUIuDWGgeurq4GCyNWqVIFY2NjPvvsM/bv38/o0aPRaDQU1cjWr19Pbm4uOp3urv0lJyfz/PPPF3uO6Oho8vPzlVkOLVu2NLimZcuWpX5ZL8nSpUvx8PAgNjaWZ599Vjn+6quvkpqaanCtl5eX8vuirVAvXrx412LE5MmTGTduHHv27MHPz48+ffoYtPVvp06dIjc312A8Dg4O1KlT5479zJ49m+DgYOVzZmYmzs7OrF1bC0vLRne890FlZ58mI2MW69YtxM3NrVz7epLk5eWxd+9eOnbsKPtqq0RyoC6Jv/okB+qS+KtPcqA+yYG6iuL/ILPky0KKEf8RPXr0oLCwkB07dtCsWTMOHjzI0qVL76utolkLt0+qKWkKz79/cGg0mlKP1apVi++//x5jY2OOHj1a7PWIR7GzQ1k5OTkBUL16dWrVqqUct7e3L/Z8t3/WaDTArS0572bkyJH4+/uzY8cO9uzZw4IFC4iKimLSpEkP4xEUWq0WrVZb7PjNm8bk5ZXvD/7cXGNyc/MwNjaWf2RKYGpqKnFRmeRAXRJ/9UkO1CXxV5/kQH2SA3WVd+ylGPEfYW5uTu/evXn//fdJTU2lTp06NG7cGAAPDw8SExMZOnSocn1iYmKpW0YWbcN4/vx5KlSoANx6TeNBeXt7k5+fz8WLF2nTps0931/0HLcr2gnk9uLG4cOHDa45fPiwslUo3PpLl5+fX2o/tra2yi4jbdu2NeirefPm9zzu0jg7OzN27FjGjh3L7NmziYmJYdKkScqrIbePsWbNmpiampKUlESNGrfWerhy5Qq//vqrwRjLKifnHAUFdg/nQUrt40y5ti+EEEIIIYR4fEkx4il3+/oHgwYNonv37vz8888MHjxYuSYkJIR+/frh7e2Nn58f27ZtY/PmzXzxxRcltlmrVi2cnZ2JiIjg1Vdf5ddffyUqKuqBx+ru7s6gQYMYMmQIUVFReHt78/fff7Nv3z68vLzo1q3bHe+fNm0azZo1Y968efTv359vvvmGpUuXKq9HFElMTGTx4sX06tWLvXv38vHHHytrY8CtdSX27duHj48PWq1WKbjcLiQkhDlz5lCzZk0aNWpEbGwsx44d4/3333/gOABMnTqVLl264O7uzpUrV9i/f79SMHFxcUGj0bB9+3a6du2KhYUF1tbWjBgxgpCQEHQ6HZUrVyYsLEyZxXKvsrKiycgo/709K1a0Kpf3z4QQQgghhBCPt/v7piKeSO3bt8fBwYGUlBQCAwOV47169WLZsmUsWbKE+vXr89577xEbG4uvr2+J7ZiamvLBBx/wyy+/4OXlxaJFi5g/f/5DGWNsbCxDhgxh2rRp1KlTh169evHtt98q/9t/J02aNGH69OnEx8fj6elJeHg4ERER/PDDDwbXTZs2je+++w5vb2/mz5/PG2+8gb+/v3I+KiqKvXv34uzsjLe3d4l9TZ48meDgYKZNm0aDBg3YtWsXn3322V13/Cir/Px8JkyYgIeHB507d8bd3Z23334bgGrVqhEZGcmsWbOoUqUKEydOBG7tEtKmTRt69OiBn58frVu3pkmTJvc5AiNu1SrL+5fmPscnhBBCCCGEeJLJbhpPuZJ2hnhaleVZXV1dmTp1KlOnTn1k43qSZGZmYmdnR6tW29BqPe5+wwPIyTmDXh/Fxx9HGyx0+l+Xl5fHzp076dq1q7wjqRLJgbok/uqTHKhL4q8+yYH6JAfqKop/69atqVixYrntpiEzIx5jK1euxMnJqdiCh88//zzDhw8H4J133qFmzZqYmZlRp04d1q9fX2p7CQkJaDQaMjIylGPHjh1Do9GQlpYGQFxcHPb29mzfvp06depgaWnJCy+8QHZ2NmvXrsXV1ZUKFSowefJkgzUL9Ho906dPp1q1alhZWfHss8+SkJBQ5mfdtGkT9evXR6vV4urqWuy1D1dXV+bNm8fAgQOxsrKiWrVqvPXWWwbnAQICAtBoNMrniIgIGjVqpFxXWFjI7t27qV69OlqtlkaNGrFr1y7lfFpaGhqNhs2bN9OuXTssLS1p2LAh33zzTZmeo7zid/nyZQYOHEi1atWwtLSkQYMGfPDBBwZ9+/r6MnnyZGbMmIGDgwNVq1YlIiKiTOP+NwsLJ6ysapbrLwsL5/samxBCCCGEEOLJJ2tGPMb69u3LpEmT2L9/Px06dADgn3/+YdeuXezcuZMtW7YwZcoUoqOj8fPzY/v27QwbNozq1as/0DYs2dnZLF++nPj4eK5du0bv3r0JCAjA3t6enTt38vvvv9OnTx98fHzo378/ABMnTuTkyZPEx8fj5OTEli1b6Ny5Mz/99NNdX134/vvv6devHxEREfTv359Dhw4xfvx4dDodQUFBynWRkZEYGRlhYmLCpUuXmDhxItOnT8fY2JgpU6bw2muvERsbS+fOnYvtxlHk2rVrJCQkEBsbi7e3N2vWrKFnz578/PPPBuMMCwtjyZIl1K5dm7CwMAYOHEhqaiomJnf/K1OW+PXs2ZOVK1cq7en1egoKCjAzM2P8+PE4OjoaxO/GjRs0adKEmTNnYmtry44dO3jxxRepWbOmwaKZa9euJTg4mKSkJL755huCgoLw8fGhY8eOJY5Vr9ej1+uVz5mZmQCYmORjalp8h5SHycwsHzOzW4uFlrQby39VUSwkJuqRHKhL4q8+yYG6JP7qkxyoT3KgrkcVf3lN4zHXq1cvdDodq1evBm7NloiMjOTMmTO0adOG+vXrs3LlSuX6fv36cf36dWVBxttfXUhISKBdu3ZcuXIFe3t74NbMCG9vb06fPo2rqytxcXEMGzaM1NRUZer82LFjWb9+PX/99ZeyxWbnzp1xdXXl3XffJT09nWeeeYb09HRl20sAPz8/mjdvzmuvvXbHZxw0aBB///03e/bsUY7NmDGDHTt28PPPPwO3Zj64ubkRExOjXDN16lSysrJYtWoVDg4O6HS6Yq9pREREsHXrVmW3j2rVqjFhwgRCQ0OVa5o3b06zZs146623SEtLw83NjVWrVjFixAgATp48Sf369UlOTqZu3bp3fJayxs/X1xdHR0fmzZvHuXPnaN++PV999RVVqlTBwcEBBweHu8ave/fu1K1blyVLliht5ufnc/DgQYNna9++PQsXLiyxjYiICCIjI4sd37hxI5aWlnd8ViGEEEIIIcTTKzs7m8DAwHJ7TUNmRjzmBg0axKhRo3j77bfRarW8//77DBgwACMjI5KTkxk9erTB9T4+PixbtuyB+rS0tDR4h79KlSq4uroqX6SLjl28eBGAn376ifz8fNzd3Q3a0ev16HS6u/aXnJzM888/b3DMx8eH6Oho8vPzlVkO7dq1o1atWso1HTt2JDo62uDYnWRmZnLu3Dl8fHyK9XX8+HGDY15eXsrvi3bjuHjx4l2LEVC2+Lm4uHDt2jVq1apFSkoK+fn5BotogmH88vPzee211/joo4/4888/yc3NRa/XFysY3D7uorEX5akks2fPJjg4WPmcmZmJs7Mza9fWwtKy0V2f9UFkZ58mI2MW69YtxM3NrVz7epLk5eWxd+9eOnbsKO9IqkRyoC6Jv/okB+qS+KtPcqA+yYG6iuL/ILPty0KKEY+5Hj16UFhYyI4dO2jWrBkHDx5k6dKl99VW0TaPt0+GKWnqzb//wms0mhKPFa1lkZWVhbGxMd9//32x1yNu/wL+JLn9eTWaWzs+/HvtjrLcW3T/g8bv9ddfZ9myZURHR9OgQQOsrKyYOnUqubm5d+37TuPWarVotdpix69d+4vc3PS7POmDyck5R25uHsbGxvKPTAlMTU0lLiqTHKhL4q8+yYG6JP7qkxyoT3KgrvKOvRQjHnPm5ub07t2b999/n9TUVOrUqUPjxo0B8PDwIDExkaFDhyrXJyYmUq9evRLbqlSpEgDnz5+nQoUKAMrrCw/C29ub/Px8Ll68SJs2be75/qLnuF1iYiLu7u4GX84PHz5scM3hw4fx8Pj/HR9MTU0NFoX8N1tbW5ycnEhMTKRt27YGfd2+7sKjVpb4JSYm8vzzzzN48GDgVmHk119/LTXXD0qvf4+cnHJp2oBOpy2XKV9CCCGEEEKIx5sUI54AgwYNonv37vz888/Kl1GAkJAQ+vXrh7e3N35+fmzbto3NmzfzxRdflNhOrVq1cHZ2JiIigldffZVff/212K4V98Pd3Z1BgwYxZMgQoqKi8Pb25u+//2bfvn14eXnRrVu3O94/bdo0mjVrxrx58+jfvz/ffPMNb775Jm+//bbBdYmJiSxevJhevXqxd+9ePv74Y2VtDLi1rsS+ffvw8fFBq9UqBZfbhYSEMGfOHGrWrEmjRo2IjY3l2LFjvP/++w8ch/tVlvjVrl2bTz75hEOHDlGhQgXeeOMN/vrrr3IrRoSHjyqXWS3W1tYGr+7Y2toqRTIhhBBCCCHEf4cUI54A7du3x8HBgZSUFAIDA5XjvXr1YtmyZSxZsoQpU6bg5uZGbGwsvr6+JbZjamrKBx98wLhx4/Dy8qJZs2bMnz+fvn37PvAYY2NjmT9/PtOmTePPP/+kYsWKtGjRgu7du9/13saNG/PRRx8RHh7OvHnzcHR0ZO7cuQY7acCtosV3331HZGQktra2vPHGGwbrLERFRREcHExMTAzVqlVTtiu93eTJk7l69SrTpk3j4sWL1KtXj88+++yuO37cr6CgINauXVvi2hnHjx9Ho9EwdOhQYmNjmT17NkFBQVy7dg249QpFkyZNsLe35+WXX+b333+ndevWBq/ZfPrpp1SvXp2RI0fy1Vdf8dVXX5W4ZsjatWu5l7Vq586NoYxvpdwTnU7Lxo3vSAFCCCGEEEKI/zjZTUM8EVxdXZk6dSpTp05Veyj3JCgoiC+//JLMzEzOnz+PhYUFADdu3MDR0RFbW1vatWtHXFwczz33HLm5uSxYsIBnnnmGv/76i3379lG/fn169uwJ3IrDiBEjGDVqlNKHsbExFhYWZGVlKceaNWvG6NGjDa6rWrXqXcebmZmJnZ0drVptQ6v1uOv19yIn5wx6fRQffxxtsMCnMJSXl8fOnTvp2rWrvCOpEsmBuiT+6pMcqEvirz7JgfokB+oqin/r1q2pWLGi7KYhxJOqcePGnDp1is2bNzNo0CAANm/eTI0aNZRdJDIyMjh48CAJCQnKehYuLi4lrmVhY2NTYmHh9tcqjI2NS72uLCwsnLCwePgFA73+oTcphBBCCCGEeAJJMUKUuy5dunDw4MESz4WGhhIaGvqIR3T/7vdZhg8fTmxsrFKMWLNmDcOGDSMhIQG4VUiwtrZm69attGjRosQdLsqDXq9Hf1uFIDMzEwATk3xMTYvvtPIgzMzyMTO7tchoSbu4iFuKYiMxUo/kQF0Sf/VJDtQl8Vef5EB9kgN1Par4y2saotz9+eef5JSyNYODgwMODg6PeET3716fJSgoiIyMDGJiYnB2diYlJQWAunXrcubMGUaOHIm9vT1xcXFs2rSJUaNGkZOTQ+PGjWnbti0DBgzAy8tLac/V1ZXz588bTFd77bXXmDx5skG/ZX2tJSIigsjIyGLHN27ciKWl5R3vFUIIIYQQQjy9srOzCQwMlNc0xJOrWrVqag/hobnfZ6lUqRLdunUjLi6OwsJCunXrRsWKFQ2u6dOnD926dePgwYMcPnyYzz//nMWLF7Nq1SqDxTxDQkIMPv+7nXsxe/ZsgoODlc+ZmZk4Ozuzdm0tLC0b3Xe7JcnOPk1GxizWrVuovJ4iisvLy2Pv3r107NhR3pFUieRAXRJ/9UkO1CXxV5/kQH2SA3UVxb9du3bl2o8UI4R4RIYPH87EiRMBeOutt0q8xtzcnI4dO9KxY0deeeUVRo4cyZw5c4oVH2rVqvVQxqTVakt8JeTatb/IzU1/KH0Uyck5R25uHsbGxvKPShmYmppKnFQmOVCXxF99kgN1SfzVJzlQn+RAXeUdeylGCPGIdO7cmdzcXDQajcGWpHdSr149tm7dWr4DK4Fe/x6lvI3yQHQ6bblM8RJCCCGEEEI8WaQYIcQjYmxsTHJysvL7212+fJm+ffsyfPhwvLy8sLGx4bvvvmPx4sU8//zzj3ys4eGjDHbnuB/W1tbodDqDY7a2tlSqVOmB2hVCCCGEEEI8+aQYIUQ5CQoKYu3atbi6uirHimYFTJgwgbfffhtnZ2fat2/P1KlT2b9/P/v37zdo45lnnqFfv35oNBrl2EsvvcRLL71kcN3+/fvx9fXl7NmzPPPMMw889rlzYygoeLA2dDotGze+I8UHIYQQQgghRDFSjBCiHDk7O3PlyhVycnKwsLAA4MaNG2zcuJEaNWrQrl074uLiCAoKonPnzsTGxhrcr9VqsbKy4vz588qxKVOmkJmZaXBt0S4ecXFx9OvXjwMHDtCyZcv7HrdWOwat1uO+78/JOcPly1FkZmZKMUIIIYQQQghRjBQjhChHjRs35tSpU2zevJlBgwYBsHnzZmrUqFFsRwmtVkvVqlVLbOf24xYWFuj1+mLXFhYWEhsby9tvv0316tVZvXo1zz777B3Hp9fr0ev1yufMzEwAbGyqYGlZo+wP+i9mZvlkZJiSn58v+0PfI9lXW32SA3VJ/NUnOVCXxF99kgP1SQ7U9ajiryksLCws1x6E+I8KCgoiIyODtm3bsmPHDr744gsA/Pz86N69OwkJCdjb2yszIzIyMsq0WGVp13755ZcMGjSIs2fPkpycTKtWrTh//jxWVlalthUREUFkZGSx4xs3bsTS0vKenlcIIYQQQgjx9MjOziYwMJCrV6+WyyL0MjNCiHI2ePBgZs+ezR9//AFAYmIi8fHxJCQkGFy3ffv2YotGhoaGEhoaWqZ+Vq9ezYABAzA2NsbT05NnnnmGjz/+2GBb0H+bPXs2wcHByufMzEycnZ1Zu7YWlpaNytRvSbKzT5ORMYt16xYWmwEi7kz21Vaf5EBdEn/1SQ7UJfFXn+RAfZIDdRXFv127duXajxQjhChnlSpVolu3bsTFxVFYWEi3bt2oWLFisevatWvHO++8Y3CsaC2Iu8nIyGDz5s18/fXXyrHBgwezevXqOxYjtFotWq222PGbN43Jy7v/H/y5ucbk5uZhbGws/4DcJ9lXW32SA3VJ/NUnOVCXxF99kgP1SQ7UVd6xl2KEEI/A8OHDmThxIgBvvfVWiddYWVlRq1at+2p/48aN3Lhxw2CNiMLCQgoKCvj1119xd3e/p/Zycs5RUGB3X2O5df+Z+75XCCGEEEII8fSTYoQQj0Dnzp3Jzc1Fo9Hg7+//0NtfvXo106ZNM5gF8eeff9K5c2cWLFhQbJeOu9Hr3yMn58HGpNNpy+XdMiGEEEIIIcSTT4oRQjwCxsbGJCcnK78viV6v58KFCwbHTExMir3S8fXXX3P9+nXl87Fjxzh69Cjvv/8+devWVY4XrT+xbds2bt68iYlJ2f+6h4ePKrZ+xZ1YW1uj0+kMjtna2sq2nkIIIYQQQogSSTFCiEfkbrMEdu3ahaOjo8GxOnXq8Msvv9zxvtWrV1OvXj2DQsTt/vnnH3bu3EnPnj3LPNa5c2MoKCjz5eh0WjZufEeKD0IIIYQQQogyMVJ7AOLJ5+vry6RJk5g6dSoVKlSgSpUqxMTEcP36dYYNG4aNjQ21atXi888/V+756quvaN68OVqtFkdHR2bNmsXNmzcN2pw8eTIzZszAwcGBqlWrEhERYdBvRkYGI0eOpFKlStja2tK+fXuOHz8OQFpaGkZGRnz33XcG90RHR+Pi4kJBQQEJCQloNBr27dtH06ZNsbS0pFWrVqSkpBjc8+mnn9K4cWPMzc155plniIyMVMZaWFhIREQENWrUQKvV4uTkxOTJkwGIi4ujU6dO1K5dG3Nzc6pUqcILL7ygtLt161bi4uKUawsLC5VfH3/8MZ6envzxxx/odDr8/Py4fv06ERERnDp1igsXLqDRaNBoNPTp04eff/6ZI0eO4O3tjbm5OU2bNuWHH34A4OjRo/dUiADQasdgbx9dpl9a7TQuX9aTmZl5T30IIYQQQggh/rtkZoR4KNauXcuMGTM4cuQIH374IePGjWPLli0EBAQQGhrK0qVLefHFF0lPT+fKlSt07dqVoKAg1q1bxy+//MKoUaMwNzc3KDisXbuW4OBgkpKS+OabbwgKCsLHx4eOHTsC0LdvXywsLPj888+xs7Pjvffeo0OHDvz666+4urri5+dHbGwsTZs2VdqMjY0lKCgII6P/r8OFhYURFRVFpUqVGDt2LMOHDycxMRGAgwcPMmTIEJYvX06bNm04deoUo0ePBmDOnDls2rSJpUuXEh8fT/369blw4YJSEPnuu++YPHky69evp1WrVvzzzz8cPHjwrrE8f/48AwcOZPHixQQEBHDt2jUOHjxIYWEh06dPJzk5mczMTGUdCAcHB7KysujevTsdO3Zkw4YNnD59milTpty1L71ej16vVz4XFRRsbKpgaVnjrvcDmJnlk5FhSn5+Pnl5eWW6R5SuKIYSS/VIDtQl8Vef5EBdEn/1SQ7UJzlQ16OKv6awsLCwXHsQTz1fX1/y8/OVL9r5+fnY2dnRu3dv1q1bB8CFCxdwdHTkm2++Ydu2bWzatInk5GQ0Gg0Ab7/9NjNnzuTq1asYGRkVaxOgefPmtG/fnoULF/L111/TrVs3Ll68aLA1Za1atZgxYwajR4/mo48+YuzYsZw/fx6tVsvRo0dp2rQpv//+O66uriQkJNCuXTu++OILOnToAMDOnTvp1q0bOTk5mJub4+fnR4cOHZg9e7bSx4YNG5gxYwbnzp3jjTfe4L333uPEiRPFtr7ZvHkzw4YN4+zZs9jY2JQ5nkePHqVJkyakpaXh4uJS7HxQUBAZGRls3bpVObZy5UpCQ0M5e/Ys5ubmALz77ruMGzeOH374gUaNGpXYV0REBJGRkcWOb9y4EUtLyzKPWQghhBBCCPF0yc7OJjAwkKtXr5bLwvQyM0I8FF5eXsrvjY2N0el0NGjQQDlWpUoVAC5evEhycjItW7ZUChEAPj4+ZGVlcfbsWWrUqFGsTQBHR0cuXrwIwPHjx8nKyiq2aGJOTg6nTp0CoFevXkyYMIEtW7YwYMAA4uLiaNeuHa6urqWOvWjNhosXL1KjRg2OHz9OYmIir776qnJNfn4+N27cIDs7m759+xIdHc0zzzxD586d6dq1Kz169MDExISOHTvi4uKinOvcuTMBAQF3/ZLfsGFDOnToQIMGDfD396dTp0688MILVKhQodR7kpOT8fLyUgoRAC1btrxjPwCzZ88mODhY+ZyZmYmzszNr19bC0rLRXe8HyM4+TUbGLNatW4ibm1uZ7hGly8vLY+/evXTs2FH21VaJ5EBdEn/1SQ7UJfFXn+RAfZIDdRXFv127duXajxQjxEPx7x8SGo3G4FhR4aHgHlZFLKnNovuzsrJwdHQkISGh2H329vYAmJmZMWTIEGJjY+nduzcbN25k2bJld+zn3+PMysoiMjKS3r17F7vP3NwcZ2dnUlJS+OKLL9i7dy/jx4/n9ddf56uvvsLGxoajR4+SkJDAnj17CA8PJyIigm+//VYZY0mMjY3Zu3cvhw4dYs+ePaxYsYKwsDCSkpIe+pd9rVZrMLOkyM2bxuTlle0Hf26uMbm5eRgbG8s/Fg+RqampxFNlkgN1SfzVJzlQl8RffZID9UkO1FXesZdihHjkPDw82LRpE4WFhcqX/8TERGxsbKhevXqZ2mjcuDEXLlzAxMSk2EyH240cORJPT0/efvttbt68WWJR4W79pKSkUKtWrVKvsbCwoEePHvTo0YMJEyZQt25dfvrpJxo3boyJiQl+fn74+fkxZ84c7O3t+fLLL+86Do1Gg4+PDz4+PoSHh+Pi4sKWLVsIDg7GzMyM/Px8g+s9PDxYv349N27cUGZHHD58+J6e9XY5OecoKLAr47Vn7rsfIYQQQgghxH+TFCPEIzd+/Hiio6OZNGkSEydOJCUlhTlz5hAcHGywsOSd+Pn50bJlS3r16sXixYtxd3fn3Llz7Nixg4CAAGXRSg8PD1q0aMHMmTMZPnw4FhYW9zTW8PBwunfvTo0aNXjhhRcwMjLi+PHjnDhxgvnz5xMXF0d+fj7PPvsslpaWbNiwAQsLC1xcXNi+fTu///47zz33HBUqVGDnzp0UFBRQp06dO/aZlJTEvn376NSpE5UrVyYpKYm///4bDw8PAFxdXdm9ezcpKSnodDrs7OwIDAwkLCyMUaNGMXv2bNLS0liyZMk9Pevt9Pr3yMkp+/U6nbZc3iMTQgghhBBCPJ2kGCEeuWrVqrFz505CQkJo2LAhDg4OjBgxgpdffrnMbWg0Gnbu3ElYWBjDhg3j77//pmrVqjz33HPK+hRFRowYwaFDhxg+fPg9j9Xf35/t27czd+5cFi1ahKmpKXXr1mXkyJHArVdCFi5cSHBwMPn5+TRo0IBt27ah0+mwt7dn8+bNREREcOPGDWrXrs0HH3xA/fr179inra0tBw4cIDo6mszMTFxcXIiKiqJLly4AjBo1ioSEBJo2bUpWVhb79+/H19eXbdu2MXbsWLy9valXrx6LFi2iT58+9/zMACtXRmJnV7aZEUVjrlSp0n31JYQQQgghhPjvkWKEeGAlrduQlpZW7NjtG7e0bduWI0eO3FObt+8eAWBjY8Py5ctZvnz5Hcf3559/0qBBA5o1a2Zw3NfXl39vJtOoUaNix/z9/fH39y+x7V69etGrV68Sz7Vu3brE57gbDw8Pdu3aVer5SpUqsWfPnmLHW7RowbFjxwyO3e9mOS4uLsUWBxVCCCGEEEKIh6Vsc+KFeAJlZWVx4sQJ3nzzTSZNmqT2cIQQQgghhBBC/I8UI8RTa+LEiTRp0gRfX9/7ekWjvKSnp2NtbV3qr/T0dLWHKIQQQgghhBDlSl7TEE+tuLg44uLi1B5GMU5OTsVep/j3eSGEEEIIIYR4mkkxQohHzMTE5I5bhQohhBBCCCHE005e0xBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCCCGEEEIIIcQjZaL2AIQQj4/CwkIArl27hqmpqcqj+W/Ky8sjOzubzMxMyYFKJAfqkvirT3KgLom/+iQH6pMcqKso/teuXQP+/zvCwybFCCGE4vLlywC4ubmpPBIhhBBCCCHE4+DatWvY2dk99HalGCGEUDg4OACQnp5eLj9wxN1lZmbi7OzMmTNnsLW1VXs4/0mSA3VJ/NUnOVCXxF99kgP1SQ7UVRT/9PR0NBoNTk5O5dKPFCOEEAojo1vLyNjZ2ckPfpXZ2tpKDlQmOVCXxF99kgN1SfzVJzlQn+RAXeX9nUAWsBRCCCGEEEIIIcQjJcUIIYQQQgghhBBCPFJSjBBCKLRaLXPmzEGr1ao9lP8syYH6JAfqkvirT3KgLom/+iQH6pMcqOtRxV9TWF77dAghhBBCCCGEEEKUQGZGCCGEEEIIIYQQ4pGSYoQQQgghhBBCCCEeKSlGCCGEEEIIIYQQ4pGSYoQQQgghhBBCCCEeKSlGCPGUe+utt3B1dcXc3Jxnn32WI0eO3PH6jz/+mLp162Jubk6DBg3YuXOnwfnCwkLCw8NxdHTEwsICPz8/fvvtt/J8hCfew8xBXl4eM2fOpEGDBlhZWeHk5MSQIUM4d+5ceT/GE+th/x243dixY9FoNERHRz/kUT9dyiMHycnJ9OzZEzs7O6ysrGjWrBnp6enl9QhPtIcd/6ysLCZOnEj16tWxsLCgXr16vPvuu+X5CE+8e8nBzz//TJ8+fXB1db3jz5d7zet/2cOO//+1d+dBUZzpH8C/IyOXCAQQEF2BUkgAwSAEg2hgKyZkQcWkKhoVkDWLKcsLS6m4G0lcjBETj6i73i5QJpFYta7ionGNolGCEq4IygrEIwnFEY0h4onw/P7wR29GDkHpwRm/n6opme63337e95nDeaa7Z/ny5XjuuefQt29fODo6YsKECTh37pyKIzB8ajwHWqSkpECj0SAhIaF7gzYyauSgqqoK0dHRsLe3h4WFBXx9fZGfn9/5oISIjFZGRoaYmprKP/7xDzlz5ozEx8eLra2t1NbWttk+JydHTExM5MMPP5SzZ8/K4sWLpXfv3lJSUqK0SUlJERsbG9mzZ498++23Mn78eHF3d5ebN2/qa1gGpbtz8Msvv8iYMWPk888/l//+97+Sm5srQUFBEhAQoM9hGQw1ngMtdu/eLcOGDRMXFxdZs2aNyiMxXGrkoLKyUuzs7CQxMVEKCwulsrJS9u7d226fTzI15j8+Pl4GDx4s2dnZcuHCBdm8ebOYmJjI3r179TUsg9LVHOTl5cnChQtl586d4uzs3ObrS1f7fJKpMf/h4eGSmpoqpaWlUlxcLBERETJo0CBpaGhQeTSGSY0c/Latm5ub+Pn5ybx589QZgBFQIwc///yzuLq6SlxcnJw6dUrOnz8vBw8elMrKyk7HxWIEkRELCgqSWbNmKfebmprExcVFli9f3mb7iRMnSmRkpM6yESNGyFtvvSUiIs3NzeLs7CwfffSRsv6XX34RMzMz2blzpwojMHzdnYO25OXlCQC5dOlS9wRtRNSa/x9//FEGDBggpaWl4urqymJEB9TIwaRJkyQ6OlqdgI2MGvPv4+MjycnJOm2GDx8u77zzTjdGbjy6moPfau/15VH6fNKoMf/3q6urEwBy7NixRwnVaKmVg2vXromHh4ccOnRIQkNDWYzogBo5ePvtt2XUqFGPFBdP0yAyUnfu3EFBQQHGjBmjLOvVqxfGjBmD3NzcNrfJzc3VaQ8A4eHhSvsLFy6gpqZGp42NjQ1GjBjRbp9PMjVy0Jb6+npoNBrY2tp2S9zGQq35b25uRkxMDBITE+Hj46NO8EZCjRw0NzcjKysLnp6eCA8Ph6OjI0aMGIE9e/aoNg5DpdZzYOTIkcjMzERVVRVEBNnZ2SgvL8fLL7+szkAM2MPkoCf6NFb6mqv6+noAgJ2dXbf1aSzUzMGsWbMQGRnZ6jWLdKmVg8zMTAQGBuL111+Ho6Mj/P39sXXr1i71wWIEkZG6fPkympqa4OTkpLPcyckJNTU1bW5TU1PTYfuWf7vS55NMjRzc79atW3j77bcxefJkWFtbd0/gRkKt+V+xYgW0Wi3mzp3b/UEbGTVyUFdXh4aGBqSkpOCVV17Bf/7zH7z66qt47bXXcOzYMXUGYqDUeg6sX78e3t7eGDhwIExNTfHKK6/g73//O1544YXuH4SBe5gc9ESfxkofc9Xc3IyEhASEhIRg6NCh3dKnMVErBxkZGSgsLMTy5csfNUSjp1YOzp8/j40bN8LDwwMHDx7EzJkzMXfuXKSnp3e6D+1D752IiHpUY2MjJk6cCBHBxo0bezqcJ0JBQQHWrl2LwsJCaDSang7nidTc3AwAiIqKwvz58wEAzz77LL7++mts2rQJoaGhPRneE2H9+vU4efIkMjMz4erqiq+++gqzZs2Ci4sLv6GkJ86sWbNQWlqKEydO9HQoT4wffvgB8+bNw6FDh2Bubt7T4TyxmpubERgYiA8++AAA4O/vj9LSUmzatAnTpk3rVB88MoLISDk4OMDExAS1tbU6y2tra+Hs7NzmNs7Ozh22b/m3K30+ydTIQYuWQsSlS5dw6NAhHhXRBjXm//jx46irq8OgQYOg1Wqh1Wpx6dIlLFiwAG5ubqqMw5CpkQMHBwdotVp4e3vrtPHy8uKvadxHjfm/efMm/vKXv2D16tUYN24c/Pz8MHv2bEyaNAkrV65UZyAG7GFy0BN9Giu152r27Nn497//jezsbAwcOPCR+zNGauSgoKAAdXV1GD58uPJefOzYMaxbtw5arRZNTU3dEbrRUOt50L9//0d+L2YxgshImZqaIiAgAIcPH1aWNTc34/DhwwgODm5zm+DgYJ32AHDo0CGlvbu7O5ydnXXa/Prrrzh16lS7fT7J1MgB8L9CREVFBb788kvY29urMwADp8b8x8TE4PTp0yguLlZuLi4uSExMxMGDB9UbjIFSIwempqZ47rnnWv2MXnl5OVxdXbt5BIZNjflvbGxEY2MjevXS/S+kiYmJctQK/c/D5KAn+jRWas2ViGD27Nn417/+hSNHjsDd3b07wjVKauTgxRdfRElJic57cWBgIKZOnYri4mKYmJh0V/hGQa3nQUhIyKO/Fz/S5S+J6LGWkZEhZmZmkpaWJmfPnpUZM2aIra2t1NTUiIhITEyMLFq0SGmfk5MjWq1WVq5cKWVlZfLee++1+dOetra2snfvXjl9+rRERUXxpz070N05uHPnjowfP14GDhwoxcXFUl1drdxu377dI2N8nKnxHLgff02jY2rkYPfu3dK7d2/ZsmWLVFRUyPr168XExESOHz+u9/E97tSY/9DQUPHx8ZHs7Gw5f/68pKamirm5uWzYsEHv4zMEXc3B7du3paioSIqKiqR///6ycOFCKSoqkoqKik73Sf+jxvzPnDlTbGxs5OjRozrvwzdu3ND7+AyBGjm4H39No2Nq5CAvL0+0Wq0sW7ZMKioq5NNPPxVLS0v55JNPOh0XixFERm79+vUyaNAgMTU1laCgIDl58qSyLjQ0VKZNm6bTfteuXeLp6Smmpqbi4+MjWVlZOuubm5slKSlJnJycxMzMTF588UU5d+6cPoZisLozBxcuXBAAbd6ys7P1NCLD0t3PgfuxGPFgauRg+/btMmTIEDE3N5dhw4bJnj171B6Gweru+a+urpa4uDhxcXERc3Nzefrpp2XVqlXS3Nysj+EYpK7koL3X+dDQ0E73Sbq6e/7bex9OTU3V36AMjBrPgd9iMeLB1MjBvn37ZOjQoWJmZibPPPOMbNmypUsxaUREunhEBhERERERERHRQ+M1I4iIiIiIiIhIr1iMICIiIiIiIiK9YjGCiIiIiIiIiPSKxQgiIiIiIiIi0isWI4iIiIiIiIhIr1iMICIiIiIiIiK9YjGCiIiIiIiIiPSKxQgiIiIiIiIi0isWI4iIiIiMzJUrV+Do6IiLFy/2dCiPLCwsDAkJCcp9Nzc3fPzxx6rt7+LFi9BoNCguLlZtH12xaNEizJkzp6fDICLqdixGEBERUY+Ki4vDhAkTejqMdj1uH047Y9myZYiKioKbmxuA/43B0dER165d02n77LPPYsmSJfoP8iF98803mDFjRo/G0F0FkerqakyZMgWenp7o1auXTtGlxcKFC5Geno7z588/8v6IiB4nLEYQERERtePOnTs9HUKX3bhxA9u3b8ebb77Zat21a9ewcuXKbt1fU1MTmpubu7XPjvTr1w+WlpZ625+abt++jX79+mHx4sUYNmxYm20cHBwQHh6OjRs36jk6IiJ1sRhBREREj5WwsDDMmTMHCQkJeOqpp+Dk5IStW7fi+vXr+OMf/4i+fftiyJAhOHDggLLN0aNHodFokJWVBT8/P5ibm+P5559HaWmpTt///Oc/4ePjAzMzM7i5uWHVqlU6693c3LB06VLExsbC2toaM2bMgLu7OwDA398fGo0GYWFhAO59Q//SSy/BwcEBNjY2CA0NRWFhoU5/Go0G27Ztw6uvvgpLS0t4eHggMzNTp82ZM2cwduxYWFtbo2/fvhg9ejS+++47Zf22bdvg5eUFc3NzPPPMM9iwYUOH87d//36YmZnh+eefb7Vuzpw5WL16Nerq6trd/urVq4iNjcVTTz0FS0tL/OEPf0BFRYWyPi0tDba2tsjMzIS3tzfMzMzw/fffw83NDe+//z5iY2NhZWUFV1dXZGZm4qeffkJUVBSsrKzg5+eH/Px8pa8rV65g8uTJGDBgACwtLeHr64udO3d2OL7fHpWQlpYGjUbT6vbbIz0eNH95eXnw9/eHubk5AgMDUVRU1OH+w8LCcOnSJcyfP1/ZX4sHPb7aGsvatWsRGxsLGxubdtuNGzcOGRkZHfZFRGRoWIwgIiKix056ejocHByQl5eHOXPmYObMmXj99dcxcuRIFBYW4uWXX0ZMTAxu3Lihs11iYiJWrVqFb775Bv369cO4cePQ2NgIACgoKMDEiRPxxhtvoKSkBEuWLEFSUhLS0tJ0+li5ciWGDRuGoqIiJCUlIS8vDwDw5Zdforq6Grt37wZw7yiDadOm4cSJEzh58iQ8PDwQERHR6jSIv/71r5g4cSJOnz6NiIgITJ06FT///DMAoKqqCi+88ALMzMxw5MgRFBQUYPr06bh79y4A4NNPP8W7776LZcuWoaysDB988AGSkpKQnp7e7twdP34cAQEBba6bPHkyhgwZguTk5Ha3j4uLQ35+PjIzM5GbmwsRQUREhDKPwL2jL1asWIFt27bhzJkzcHR0BACsWbMGISEhKCoqQmRkJGJiYhAbG4vo6GgUFhZi8ODBiI2NhYgAAG7duoWAgABkZWWhtLQUM2bMQExMjDLnDzJp0iRUV1crt507d0Kr1SIkJKRT89fQ0ICxY8fC29sbBQUFWLJkCRYuXNjhPnfv3o2BAwciOTlZ2S/Q+cfXwwgKCsKPP/5oFNcAISJSCBEREVEPmjZtmkRFRSn3Q0NDZdSoUcr9u3fvSp8+fSQmJkZZVl1dLQAkNzdXRESys7MFgGRkZChtrly5IhYWFvL555+LiMiUKVPkpZde0tl3YmKieHt7K/ddXV1lwoQJOm0uXLggAKSoqKjDcTQ1NUnfvn1l3759yjIAsnjxYuV+Q0ODAJADBw6IiMif//xncXd3lzt37rTZ5+DBg+Wzzz7TWbZ06VIJDg5uN46oqCiZPn16u2P44osvpHfv3lJZWSkiIsOGDZP33ntPRETKy8sFgOTk5CjbXr58WSwsLGTXrl0iIpKamioApLi4WGcfrq6uEh0drdxvyVFSUpKyLDc3VwBIdXV1u/FHRkbKggULlPuhoaEyb948nf2sWbOm1XaVlZViZ2cnH374obLsQfO3efNmsbe3l5s3byrrN27c+MB8txVDZx5fHbl/nL9VX18vAOTo0aOd6ouIyBDwyAgiIiJ67Pj5+Sl/m5iYwN7eHr6+vsoyJycnAGh1ukFwcLDyt52dHZ5++mmUlZUBAMrKypRvzFuEhISgoqICTU1NyrLAwMBOxVhbW4v4+Hh4eHjAxsYG1tbWaGhowPfff9/uWPr06QNra2sl7uLiYowePRq9e/du1f/169fx3Xff4c0334SVlZVye//993VO47jfzZs3YW5u3u768PBwjBo1CklJSa3WlZWVQavVYsSIEcoye3t7nXkEAFNTU51xtTXWlhx1lLempiYsXboUvr6+sLOzg5WVFQ4ePNhqDh+kvr4eY8eORWRkJBITEwF0bv7KysqU03pa/PYx1BWdfXw9DAsLCwBodSQQEZEh0/Z0AERERET3u//DuUaj0VnWcp6+GhdO7NOnT6faTZs2DVeuXMHatWvh6uoKMzMzBAcHt7roZVtjaYm75UNmWxoaGgAAW7du1SkOAPcKNO1xcHDA1atXO4w9JSUFwcHBygf3rrKwsNC5VkKLtnLUUd4++ugjrF27Fh9//DF8fX3Rp08fJCQkdOnCoU1NTZg0aRKsra2xZcsWZfnDzt/jqOW0nn79+vVwJERE3YfFCCIiIjIaJ0+exKBBgwDcuxBjeXk5vLy8AABeXl7IycnRaZ+TkwNPT88OP5yampoCQKtvt3NycrBhwwZEREQAAH744Qdcvny5S/H6+fkhPT0djY2NrYoWTk5OcHFxwfnz5zF16tRO9+nv749PPvmkwzZBQUF47bXXsGjRIp3lXl5euHv3Lk6dOoWRI0cCuHeRyXPnzsHb27vTMXRWTk4OoqKiEB0dDeBekaK8vLxL+5o/fz5KSkqQn5+vc4RDZ+bPy8sLO3bswK1bt5RtT548+cB9mpqatno8POzjqzNKS0vRu3dv+Pj4PFI/RESPE56mQUREREYjOTkZhw8fRmlpKeLi4uDg4IAJEyYAABYsWIDDhw9j6dKlKC8vR3p6Ov72t7898IKFjo6OsLCwwBdffIHa2lrU19cDADw8PLBjxw6UlZXh1KlTmDp1aodHOrRl9uzZ+PXXX/HGG28gPz8fFRUV2LFjB86dOwfg3sUvly9fjnXr1qG8vBwlJSVITU3F6tWr2+0zPDwcZ86ceeDREcuWLcORI0eUfbWMKSoqCvHx8Thx4gS+/fZbREdHY8CAAYiKiurS2DrDw8MDhw4dwtdff42ysjK89dZbqK2t7fT2qamp2LBhAzZt2gSNRoOamhrU1NQoR0U8aP6mTJkCjUaD+Ph4nD17Fvv37+/UT5+6ubnhq6++QlVVlVKAetjHV3FxMYqLi9HQ0ICffvoJxcXFOHv2rE6b48ePY/To0V1+fBERPc5YjCAiIiKjkZKSgnnz5iEgIAA1NTXYt2+fcmTD8OHDsWvXLmRkZGDo0KF49913kZycjLi4uA771Gq1WLduHTZv3gwXFxflQ/n27dtx9epVDB8+HDExMZg7d67yqxKdZW9vjyNHjqChoQGhoaEICAjA1q1blaMk/vSnP2Hbtm1ITU2Fr68vQkNDkZaWpvzcaFt8fX2VsXbE09MT06dPx61bt3SWp6amIiAgAGPHjkVwcDBEBPv372/zuhaPavHixRg+fDjCw8MRFhYGZ2dnpXjUGceOHUNTUxPGjx+P/v37K7eWgsKD5s/Kygr79u1DSUkJ/P398c4772DFihUP3G9ycjIuXryIwYMHK6dOPOzjy9/fH/7+/igoKMBnn30Gf39/5WibFhkZGYiPj+/0vBARGQKNyP//thIRERGRgTp69Ch+//vf4+rVq7C1te3pcHpcVlYWEhMTUVpail69+N2TITtw4AAWLFiA06dPQ6vlGdZEZDz4ikZERERkZCIjI1FRUYGqqir87ne/6+lw6BFcv34dqampLEQQkdHhkRFERERk8HhkBBERkWFhMYKIiIiIiIiI9IonERIRERERERGRXrEYQURERERERER6xWIEEREREREREekVixFEREREREREpFcsRhARERERERGRXrEYQURERERERER6xWIEEREREREREekVixFEREREREREpFf/B2gUz/fcNU5qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_top_features(feature_importances, top_n=10):\n",
    "    \"\"\"\n",
    "    Select the top N features based on importance.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_importances (pd.DataFrame): A dataframe containing feature names and their importance.\n",
    "    - top_n (int): Number of top features to select.\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features (pd.DataFrame): A dataframe with the selected features and their importance.\n",
    "    \"\"\"\n",
    "    # Select the top N features\n",
    "    selected_features = feature_importances.iloc[:top_n].copy()\n",
    "\n",
    "    # Normalize the selected features' importance so that they sum to 1\n",
    "    selected_features['Importance'] /= selected_features['Importance'].sum()\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "selected_features_call_nn = select_top_features(feature_importances_call_nn, top_n=50)\n",
    "selected_features_put_nn = select_top_features(feature_importances_put_nn, top_n=50)\n",
    "\n",
    "# Plot Feature Importance for the top selected features\n",
    "def plot_feature_importance(feature_importances, title):\n",
    "    \"\"\"\n",
    "    Plot the feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_importances (pd.DataFrame): Feature importance dataframe.\n",
    "    - title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'], color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Importance (Normalized to 1)')\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # Reverse order for better readability\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the selected features for Call and Put options\n",
    "plot_feature_importance(selected_features_call_nn, \"Selected Features for Call Options (NN Model)\")\n",
    "plot_feature_importance(selected_features_put_nn, \"Selected Features for Put Options (NN Model)\")\n",
    "\n",
    "# Average Feature Importance for Calls and Puts\n",
    "def average_feature_importance(feature_importance_call, feature_importance_put):\n",
    "    \"\"\"\n",
    "    Calculate the average feature importance for Calls and Puts and plot the average features.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_importance_call (pd.DataFrame): Feature importance for Call options.\n",
    "    - feature_importance_put (pd.DataFrame): Feature importance for Put options.\n",
    "    \"\"\"\n",
    "    # Merge call and put feature importance\n",
    "    combined_importance = pd.merge(feature_importance_call[['Feature', 'Importance']],\n",
    "                                   feature_importance_put[['Feature', 'Importance']],\n",
    "                                   on='Feature', how='outer', suffixes=('_call', '_put')).fillna(0)\n",
    "\n",
    "    # Calculate average importance\n",
    "    combined_importance['Average'] = (combined_importance['Importance_call'] + combined_importance['Importance_put']) / 2\n",
    "\n",
    "    # Normalize the average importance so they sum to 1\n",
    "    combined_importance['Average'] /= combined_importance['Average'].sum()\n",
    "\n",
    "    # Sort by average importance and plot\n",
    "    combined_importance = combined_importance.sort_values(by='Average', ascending=False).head(10)\n",
    "\n",
    "    # Plot the average feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(combined_importance['Feature'], combined_importance['Average'], color='Blue', alpha=0.55, edgecolor='black')\n",
    "    # plt.xlabel('Average Importance (Normalized to 1)')\n",
    "    plt.title(\"NN (Put & Calls)\")\n",
    "    plt.gca().invert_yaxis()  # Reverse order for better readability\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return combined_importance\n",
    "\n",
    "# Plot the average feature importance for Calls and Puts\n",
    "avg_featimport = average_feature_importance(selected_features_call_nn, selected_features_put_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance_call</th>\n",
       "      <th>Importance_put</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.249665</td>\n",
       "      <td>0.306055</td>\n",
       "      <td>0.277860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.128674</td>\n",
       "      <td>0.123391</td>\n",
       "      <td>0.126032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.087864</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0.093985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.071578</td>\n",
       "      <td>0.102666</td>\n",
       "      <td>0.087122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.070516</td>\n",
       "      <td>0.072661</td>\n",
       "      <td>0.071589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T</td>\n",
       "      <td>0.069011</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>0.070178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.077270</td>\n",
       "      <td>0.054480</td>\n",
       "      <td>0.065875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.097286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIDLO</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Importance_call  Importance_put   Average\n",
       "10   prev_day_iv         0.249665        0.306055  0.277860\n",
       "2        FF_rate         0.128674        0.123391  0.126032\n",
       "11    reces_indi         0.087864        0.100107  0.093985\n",
       "9   prev2_day_iv         0.071578        0.102666  0.087122\n",
       "7     gold_price         0.070516        0.072661  0.071589\n",
       "5              T         0.069011        0.071345  0.070178\n",
       "8    hi-lo_stock         0.077270        0.054480  0.065875\n",
       "3       OPEN_vix         0.097286        0.000000  0.048643\n",
       "12    spread_vix         0.077726        0.000000  0.038863\n",
       "0          BIDLO         0.070411        0.000000  0.035205"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_featimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.249665</td>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.128674</td>\n",
       "      <td>0.003608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.097286</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.087864</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.002712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.077270</td>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.071578</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.070516</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BIDLO</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.002673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T</td>\n",
       "      <td>0.069011</td>\n",
       "      <td>0.003905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Importance  Importance_std\n",
       "0   prev_day_iv    0.249665        0.005350\n",
       "1       FF_rate    0.128674        0.003608\n",
       "2      OPEN_vix    0.097286        0.002761\n",
       "3    reces_indi    0.087864        0.002408\n",
       "4    spread_vix    0.077726        0.002712\n",
       "5   hi-lo_stock    0.077270        0.002896\n",
       "6  prev2_day_iv    0.071578        0.001803\n",
       "7    gold_price    0.070516        0.002149\n",
       "8         BIDLO    0.070411        0.002673\n",
       "9             T    0.069011        0.003905"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_call_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Top features for Call and Put options\n",
    "# top_features_c = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv', 'BIDLO', 'OPEN_vix'] used first\n",
    "# top_features_c = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv','gold_price', 'hi-lo_stock']\n",
    "# top_features_p = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'vol_stock', 'prev2_day_iv', 'hi-lo_stock', '5_day_rolling_return_stock']\n",
    "# top_features_p = ['cp_flag', 'Ticker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv', 'cumulative_return', 'BIDLO'] used first\n",
    "\n",
    "\n",
    "# top_features_c = ['cp_flag', 'Tiker', 'date', 'impl_volatilicker', 'date', 'impl_volatility', 'prev_day_iv', 'T', 'prev2_day_iv', 'BIDLO', 'OPEN_vix','hi-lo_stock','FF_rate', 'gold_price', 'reces_indi','spread_vix' ]\n",
    "# top_features_p = ['cp_flag', 'Ticty', 'prev_day_iv', 'T', 'prev2_day_iv', 'cumulative_return', 'gold_price', 'reces_indi','FF_rate','hi-lo_stock', 'PRC_actual' , 'CLOSE_vix' ]\n",
    "\n",
    "\n",
    "# # Prepare train data for Call and Put options\n",
    "# data_train_c = data_train[data_train['cp_flag'] == 'C'][top_features_c]\n",
    "# data_train_p = data_train[data_train['cp_flag'] == 'P'][top_features_p]\n",
    "\n",
    "# # Prepare validation data for Call and Put options\n",
    "# data_validate_c = data_val[data_val['cp_flag'] == 'C'][top_features_c]\n",
    "# data_validate_p = data_val[data_val['cp_flag'] == 'P'][top_features_p]\n",
    "\n",
    "# # Prepare the total train data for Call and Put options\n",
    "# data_train_tot_c = tot_data_train[tot_data_train['cp_flag'] == 'C'][top_features_c]\n",
    "# data_train_tot_p = tot_data_train[tot_data_train['cp_flag'] == 'P'][top_features_p]\n",
    "\n",
    "# # Prepare test data for Call and Put options\n",
    "# data_test_c = data_test[data_test['cp_flag'] == 'C'][top_features_c]\n",
    "# data_test_p = data_test[data_test['cp_flag'] == 'P'][top_features_p]\n",
    "\n",
    "# # Prepare the total train data for Call and Put options\n",
    "# data_train_tot_c = tot_data_train[tot_data_train['cp_flag'] == 'C']\n",
    "# data_train_tot_p = tot_data_train[tot_data_train['cp_flag'] == 'P']\n",
    "\n",
    "# # Prepare test data for Call and Put options\n",
    "# data_test_c = data_test[data_test['cp_flag'] == 'C']\n",
    "# data_test_p = data_test[data_test['cp_flag'] == 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>impl_volatility_mean</th>\n",
       "      <th>moneyness_mean</th>\n",
       "      <th>moneyness_std</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>volume_option_mean</th>\n",
       "      <th>volume_option_std</th>\n",
       "      <th>spread_option_mean</th>\n",
       "      <th>spread_option_std</th>\n",
       "      <th>...</th>\n",
       "      <th>prev2_iv_std</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>10Y_RIR</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>hi-lo_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.479429</td>\n",
       "      <td>-1.558174</td>\n",
       "      <td>-0.573249</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.648503</td>\n",
       "      <td>-0.483160</td>\n",
       "      <td>0.444798</td>\n",
       "      <td>0.423291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475013</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.479940</td>\n",
       "      <td>-1.231237</td>\n",
       "      <td>0.025769</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.266864</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.324876</td>\n",
       "      <td>0.253570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636105</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.445119</td>\n",
       "      <td>-0.875225</td>\n",
       "      <td>-0.092094</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>0.878495</td>\n",
       "      <td>0.650266</td>\n",
       "      <td>-0.008032</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806542</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.421343</td>\n",
       "      <td>-0.519891</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>0.299428</td>\n",
       "      <td>0.104081</td>\n",
       "      <td>-0.145870</td>\n",
       "      <td>-0.095167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835290</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>0.437297</td>\n",
       "      <td>-0.168351</td>\n",
       "      <td>-0.533852</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.213639</td>\n",
       "      <td>-0.264423</td>\n",
       "      <td>-0.123177</td>\n",
       "      <td>-0.165621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971770</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.397993</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>-0.803586</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>1.305590</td>\n",
       "      <td>1.189302</td>\n",
       "      <td>-0.494659</td>\n",
       "      <td>-0.568396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052023</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.458480</td>\n",
       "      <td>0.508151</td>\n",
       "      <td>-0.739018</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>1.292262</td>\n",
       "      <td>1.155390</td>\n",
       "      <td>-0.587900</td>\n",
       "      <td>-0.589187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094125</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.438479</td>\n",
       "      <td>0.877727</td>\n",
       "      <td>1.205688</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>-0.290051</td>\n",
       "      <td>-0.549276</td>\n",
       "      <td>-0.577244</td>\n",
       "      <td>-0.612072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.497671</td>\n",
       "      <td>1.216140</td>\n",
       "      <td>-2.082956</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>0.998866</td>\n",
       "      <td>1.236708</td>\n",
       "      <td>-0.610988</td>\n",
       "      <td>-0.588507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169813</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7539</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>C</td>\n",
       "      <td>0.570479</td>\n",
       "      <td>1.561152</td>\n",
       "      <td>0.684634</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>-0.517895</td>\n",
       "      <td>-0.577232</td>\n",
       "      <td>-0.579020</td>\n",
       "      <td>-0.570065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date cp_flag  impl_volatility_mean  moneyness_mean  moneyness_std  \\\n",
       "5040 2021-01-04       C              0.479429       -1.558174      -0.573249   \n",
       "5041 2021-01-04       C              0.479940       -1.231237       0.025769   \n",
       "5042 2021-01-04       C              0.445119       -0.875225      -0.092094   \n",
       "5043 2021-01-04       C              0.421343       -0.519891       0.324400   \n",
       "5044 2021-01-04       C              0.437297       -0.168351      -0.533852   \n",
       "...         ...     ...                   ...             ...            ...   \n",
       "7535 2021-12-30       C              0.397993        0.168960      -0.803586   \n",
       "7536 2021-12-30       C              0.458480        0.508151      -0.739018   \n",
       "7537 2021-12-30       C              0.438479        0.877727       1.205688   \n",
       "7538 2021-12-30       C              0.497671        1.216140      -2.082956   \n",
       "7539 2021-12-30       C              0.570479        1.561152       0.684634   \n",
       "\n",
       "        T_mean  volume_option_mean  volume_option_std  spread_option_mean  \\\n",
       "5040  1.519695           -0.648503          -0.483160            0.444798   \n",
       "5041  1.519695           -0.266864           0.008727            0.324876   \n",
       "5042  1.519695            0.878495           0.650266           -0.008032   \n",
       "5043  1.519695            0.299428           0.104081           -0.145870   \n",
       "5044  1.519695           -0.213639          -0.264423           -0.123177   \n",
       "...        ...                 ...                ...                 ...   \n",
       "7535 -0.760782            1.305590           1.189302           -0.494659   \n",
       "7536 -0.760782            1.292262           1.155390           -0.587900   \n",
       "7537 -0.760782           -0.290051          -0.549276           -0.577244   \n",
       "7538 -0.760782            0.998866           1.236708           -0.610988   \n",
       "7539 -0.760782           -0.517895          -0.577232           -0.579020   \n",
       "\n",
       "      spread_option_std  ...  prev2_iv_std   FF_rate  gold_price  reces_indi  \\\n",
       "5040           0.423291  ...     -0.475013 -1.162816    1.451941    0.266074   \n",
       "5041           0.253570  ...     -0.636105 -1.162816    1.451941    0.266074   \n",
       "5042          -0.003739  ...     -0.806542 -1.162816    1.451941    0.266074   \n",
       "5043          -0.095167  ...     -0.835290 -1.162816    1.451941    0.266074   \n",
       "5044          -0.165621  ...     -0.971770 -1.162816    1.451941    0.266074   \n",
       "...                 ...  ...           ...       ...         ...         ...   \n",
       "7535          -0.568396  ...     -0.052023 -1.172726    0.958946   -0.822889   \n",
       "7536          -0.589187  ...     -0.094125 -1.172726    0.958946   -0.822889   \n",
       "7537          -0.612072  ...     -0.005873 -1.172726    0.958946   -0.822889   \n",
       "7538          -0.588507  ...      0.169813 -1.172726    0.958946   -0.822889   \n",
       "7539          -0.570065  ...      0.139577 -1.172726    0.958946   -0.822889   \n",
       "\n",
       "       10Y_RIR   1Y_bond   2Y_bond  OPEN_vix  CLOSE_vix  hi-lo_vix  \n",
       "5040 -0.801314 -1.218487 -1.213376 -0.071108  -0.041412  -0.407989  \n",
       "5041 -0.801314 -1.218487 -1.213376 -0.071108  -0.041412  -0.407989  \n",
       "5042 -0.801314 -1.218487 -1.213376 -0.071108  -0.041412  -0.407989  \n",
       "5043 -0.801314 -1.218487 -1.213376 -0.071108  -0.041412  -0.407989  \n",
       "5044 -0.801314 -1.218487 -1.213376 -0.071108  -0.041412  -0.407989  \n",
       "...        ...       ...       ...       ...        ...        ...  \n",
       "7535  0.047437 -0.812020 -0.455627 -0.568767  -0.630316  -0.381699  \n",
       "7536  0.047437 -0.812020 -0.455627 -0.568767  -0.630316  -0.381699  \n",
       "7537  0.047437 -0.812020 -0.455627 -0.568767  -0.630316  -0.381699  \n",
       "7538  0.047437 -0.812020 -0.455627 -0.568767  -0.630316  -0.381699  \n",
       "7539  0.047437 -0.812020 -0.455627 -0.568767  -0.630316  -0.381699  \n",
       "\n",
       "[2500 rows x 51 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Prepare the total train data for Call and Put options\n",
    "# data_train_tot_c = tot_data_train[tot_data_train['cp_flag'] == 'C']\n",
    "# data_train_tot_p = tot_data_train[tot_data_train['cp_flag'] == 'P']\n",
    "\n",
    "# Prepare test data for Call and Put options\n",
    "data_test_c = data_test[data_test['cp_flag'] == 'C']\n",
    "data_test_p = data_test[data_test['cp_flag'] == 'P']\n",
    "\n",
    "data_test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train, validation, and test data for Call options\n",
    "# train_x_c = data_train_c.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])\n",
    "# train_y_c = data_train_c['impl_volatility']\n",
    "\n",
    "# validate_x_c = data_validate_c.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])\n",
    "# validate_y_c = data_validate_c['impl_volatility']\n",
    "\n",
    "combined_x_c = data_train_tot_c.drop(columns=['impl_volatility_mean', 'date', 'cp_flag'])\n",
    "combined_y_c = data_train_tot_c['impl_volatility_mean']\n",
    "\n",
    "test_x_c = data_test_c.drop(columns=['impl_volatility_mean', 'date', 'cp_flag'])\n",
    "test_y_c = data_test_c['impl_volatility_mean']\n",
    "\n",
    "# Prepare train, validation, and test data for Put options\n",
    "# train_x_p = data_train_p.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])\n",
    "# train_y_p = data_train_p['impl_volatility']\n",
    "\n",
    "# validate_x_p = data_validate_p.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])\n",
    "# validate_y_p = data_validate_p['impl_volatility']\n",
    "\n",
    "combined_x_p = data_train_tot_p.drop(columns=['impl_volatility_mean', 'date', 'cp_flag'])\n",
    "combined_y_p = data_train_tot_p['impl_volatility_mean']\n",
    "\n",
    "test_x_p = data_test_p.drop(columns=['impl_volatility_mean', 'date', 'cp_flag'])\n",
    "test_y_p = data_test_p['impl_volatility_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moneyness_mean</th>\n",
       "      <th>moneyness_std</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>volume_option_mean</th>\n",
       "      <th>volume_option_std</th>\n",
       "      <th>spread_option_mean</th>\n",
       "      <th>spread_option_std</th>\n",
       "      <th>prc_option_mean</th>\n",
       "      <th>prc_option_std</th>\n",
       "      <th>PRC_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>prev2_iv_std</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>10Y_RIR</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>hi-lo_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>-1.558174</td>\n",
       "      <td>-0.573249</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.648503</td>\n",
       "      <td>-0.483160</td>\n",
       "      <td>0.444798</td>\n",
       "      <td>0.423291</td>\n",
       "      <td>1.560488</td>\n",
       "      <td>1.066929</td>\n",
       "      <td>1.244845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475013</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>-1.231237</td>\n",
       "      <td>0.025769</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.266864</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.324876</td>\n",
       "      <td>0.253570</td>\n",
       "      <td>0.998968</td>\n",
       "      <td>0.624974</td>\n",
       "      <td>1.124845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636105</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>-0.875225</td>\n",
       "      <td>-0.092094</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>0.878495</td>\n",
       "      <td>0.650266</td>\n",
       "      <td>-0.008032</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.473121</td>\n",
       "      <td>0.300945</td>\n",
       "      <td>1.218837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806542</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>-0.519891</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>0.299428</td>\n",
       "      <td>0.104081</td>\n",
       "      <td>-0.145870</td>\n",
       "      <td>-0.095167</td>\n",
       "      <td>0.139564</td>\n",
       "      <td>0.068362</td>\n",
       "      <td>1.467864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835290</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>-0.168351</td>\n",
       "      <td>-0.533852</td>\n",
       "      <td>1.519695</td>\n",
       "      <td>-0.213639</td>\n",
       "      <td>-0.264423</td>\n",
       "      <td>-0.123177</td>\n",
       "      <td>-0.165621</td>\n",
       "      <td>-0.060525</td>\n",
       "      <td>-0.163955</td>\n",
       "      <td>1.316600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971770</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>0.168960</td>\n",
       "      <td>-0.803586</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>1.305590</td>\n",
       "      <td>1.189302</td>\n",
       "      <td>-0.494659</td>\n",
       "      <td>-0.568396</td>\n",
       "      <td>-0.490883</td>\n",
       "      <td>-0.562857</td>\n",
       "      <td>1.546873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052023</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>0.508151</td>\n",
       "      <td>-0.739018</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>1.292262</td>\n",
       "      <td>1.155390</td>\n",
       "      <td>-0.587900</td>\n",
       "      <td>-0.589187</td>\n",
       "      <td>-0.549189</td>\n",
       "      <td>-0.566990</td>\n",
       "      <td>2.506755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094125</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>0.877727</td>\n",
       "      <td>1.205688</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>-0.290051</td>\n",
       "      <td>-0.549276</td>\n",
       "      <td>-0.577244</td>\n",
       "      <td>-0.612072</td>\n",
       "      <td>-0.555250</td>\n",
       "      <td>-0.599648</td>\n",
       "      <td>3.664669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>1.216140</td>\n",
       "      <td>-2.082956</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>0.998866</td>\n",
       "      <td>1.236708</td>\n",
       "      <td>-0.610988</td>\n",
       "      <td>-0.588507</td>\n",
       "      <td>-0.580448</td>\n",
       "      <td>-0.596725</td>\n",
       "      <td>1.548882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169813</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7539</th>\n",
       "      <td>1.561152</td>\n",
       "      <td>0.684634</td>\n",
       "      <td>-0.760782</td>\n",
       "      <td>-0.517895</td>\n",
       "      <td>-0.577232</td>\n",
       "      <td>-0.579020</td>\n",
       "      <td>-0.570065</td>\n",
       "      <td>-0.588059</td>\n",
       "      <td>-0.604244</td>\n",
       "      <td>4.009750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      moneyness_mean  moneyness_std    T_mean  volume_option_mean  \\\n",
       "5040       -1.558174      -0.573249  1.519695           -0.648503   \n",
       "5041       -1.231237       0.025769  1.519695           -0.266864   \n",
       "5042       -0.875225      -0.092094  1.519695            0.878495   \n",
       "5043       -0.519891       0.324400  1.519695            0.299428   \n",
       "5044       -0.168351      -0.533852  1.519695           -0.213639   \n",
       "...              ...            ...       ...                 ...   \n",
       "7535        0.168960      -0.803586 -0.760782            1.305590   \n",
       "7536        0.508151      -0.739018 -0.760782            1.292262   \n",
       "7537        0.877727       1.205688 -0.760782           -0.290051   \n",
       "7538        1.216140      -2.082956 -0.760782            0.998866   \n",
       "7539        1.561152       0.684634 -0.760782           -0.517895   \n",
       "\n",
       "      volume_option_std  spread_option_mean  spread_option_std  \\\n",
       "5040          -0.483160            0.444798           0.423291   \n",
       "5041           0.008727            0.324876           0.253570   \n",
       "5042           0.650266           -0.008032          -0.003739   \n",
       "5043           0.104081           -0.145870          -0.095167   \n",
       "5044          -0.264423           -0.123177          -0.165621   \n",
       "...                 ...                 ...                ...   \n",
       "7535           1.189302           -0.494659          -0.568396   \n",
       "7536           1.155390           -0.587900          -0.589187   \n",
       "7537          -0.549276           -0.577244          -0.612072   \n",
       "7538           1.236708           -0.610988          -0.588507   \n",
       "7539          -0.577232           -0.579020          -0.570065   \n",
       "\n",
       "      prc_option_mean  prc_option_std  PRC_mean  ...  prev2_iv_std   FF_rate  \\\n",
       "5040         1.560488        1.066929  1.244845  ...     -0.475013 -1.162816   \n",
       "5041         0.998968        0.624974  1.124845  ...     -0.636105 -1.162816   \n",
       "5042         0.473121        0.300945  1.218837  ...     -0.806542 -1.162816   \n",
       "5043         0.139564        0.068362  1.467864  ...     -0.835290 -1.162816   \n",
       "5044        -0.060525       -0.163955  1.316600  ...     -0.971770 -1.162816   \n",
       "...               ...             ...       ...  ...           ...       ...   \n",
       "7535        -0.490883       -0.562857  1.546873  ...     -0.052023 -1.172726   \n",
       "7536        -0.549189       -0.566990  2.506755  ...     -0.094125 -1.172726   \n",
       "7537        -0.555250       -0.599648  3.664669  ...     -0.005873 -1.172726   \n",
       "7538        -0.580448       -0.596725  1.548882  ...      0.169813 -1.172726   \n",
       "7539        -0.588059       -0.604244  4.009750  ...      0.139577 -1.172726   \n",
       "\n",
       "      gold_price  reces_indi   10Y_RIR   1Y_bond   2Y_bond  OPEN_vix  \\\n",
       "5040    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5041    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5042    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5043    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5044    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "7535    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7536    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7537    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7538    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7539    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "\n",
       "      CLOSE_vix  hi-lo_vix  \n",
       "5040  -0.041412  -0.407989  \n",
       "5041  -0.041412  -0.407989  \n",
       "5042  -0.041412  -0.407989  \n",
       "5043  -0.041412  -0.407989  \n",
       "5044  -0.041412  -0.407989  \n",
       "...         ...        ...  \n",
       "7535  -0.630316  -0.381699  \n",
       "7536  -0.630316  -0.381699  \n",
       "7537  -0.630316  -0.381699  \n",
       "7538  -0.630316  -0.381699  \n",
       "7539  -0.630316  -0.381699  \n",
       "\n",
       "[2500 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras.backend as K\n",
    "# from keras import regularizers\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.models import Sequential\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from scikeras.wrappers import KerasRegressor  # Use SciKeras instead\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# # Define the model function with variable neurons, layers, and dropout rate\n",
    "# def create_model(neurons=32, layers=1, dropout_rate=0.0, bias=0.01, activity=0.01):\n",
    "#     model = Sequential()\n",
    "#     # Input layer (first hidden layer)\n",
    "#     model.add(Dense(neurons, activation='relu', input_dim=train_x.shape[1],\n",
    "#                     bias_regularizer=regularizers.L2(bias),\n",
    "#                     activity_regularizer=regularizers.L2(activity)))\n",
    "#     model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "#     # Additional hidden layers\n",
    "#     for _ in range(layers - 1):\n",
    "#         model.add(Dense(neurons, activation='relu',\n",
    "#                         bias_regularizer=regularizers.L2(bias),\n",
    "#                         activity_regularizer=regularizers.L2(activity)))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer\n",
    "#     model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "#                   loss='mean_squared_error',\n",
    "#                   metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "# # Wrapping the model in KerasRegressor\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # Define the parameter grid for trials\n",
    "# param_grid = {\n",
    "#     'neurons': [8, 16, 32, 64],   # Number of neurons in each hidden layer\n",
    "#     'layers': [1, 2, 3, 4],       # Number of hidden layers\n",
    "#     'dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "#     'batch_size': [32, 64],       # Batch size for training\n",
    "#     'epochs': [50, 100],          # Number of epochs\n",
    "# }\n",
    "\n",
    "# # Function to perform hyperparameter tuning, retrain the model, and test\n",
    "# def train_and_evaluate(train_x, train_y, validate_x, validate_y, combined_x, combined_y, test_x, test_y):\n",
    "#     # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "#     grid_search = GridSearchCV(estimator=model,\n",
    "#                                param_grid=param_grid,\n",
    "#                                scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "#                                cv=3,  # 3-fold cross-validation\n",
    "#                                verbose=1)  # Verbose for tracking progress\n",
    "\n",
    "#     # Hyperparameter tuning on training and validation sets\n",
    "#     print(\"Running hyperparameter tuning...\")\n",
    "#     grid_search.fit(train_x, train_y, validation_data=(validate_x, validate_y))\n",
    "\n",
    "#     # Get the best estimator and parameters\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "#     # Retrain on the combined training and validation set\n",
    "#     best_model.fit(combined_x, combined_y)\n",
    "\n",
    "#     # Make predictions on the test set\n",
    "#     predictions = best_model.predict(test_x)\n",
    "\n",
    "#     # Calculate R² and RMSE for the best model\n",
    "#     r2 = r2_score(test_y, predictions)\n",
    "#     rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "#     # Print the results\n",
    "#     print(f\"R²: {r2:.4f}\")\n",
    "#     print(f\"RMSE: {rmse:.4f}\")\n",
    "#     return best_model\n",
    "\n",
    "# # Call the function for Call options data\n",
    "# print(\"\\nEvaluating Call options...\")\n",
    "# best_model_call = train_and_evaluate(train_x_c, train_y_c, validate_x_c, validate_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c)\n",
    "\n",
    "# # Call the function for Put options data\n",
    "# print(\"\\nEvaluating Put options...\")\n",
    "# best_model_put = train_and_evaluate(train_x_p, train_y_p, validate_x_p, validate_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras import regularizers\n",
    "# from keras.layers import Dense, Dropout, Input\n",
    "# from keras.models import Sequential\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from keras.optimizers import RMSprop\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the model function with variable neurons, layers, and dropout rate\n",
    "# def create_model(input_dim, neurons=32, layers=1, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     # Input layer using Input instead of input_dim argument\n",
    "#     model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "#     # First hidden layer\n",
    "#     model.add(Dense(neurons, activation='relu'))\n",
    "#     model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "#     # Additional hidden layers\n",
    "#     for _ in range(layers - 1):\n",
    "#         model.add(Dense(neurons, activation='relu'))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer\n",
    "#     model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "#                   loss='mean_squared_error',\n",
    "#                   metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "# # Wrapping the model in KerasRegressor\n",
    "# def create_keras_regressor(input_dim):\n",
    "#     return KerasRegressor(model=create_model, input_dim=input_dim, verbose=1)\n",
    "\n",
    "# # Define the parameter grid for trials\n",
    "# param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [64]}  # Put\n",
    "# param_grid_call = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [32]}  # Call\n",
    "\n",
    "# # Function to perform hyperparameter tuning, retrain the model, and test\n",
    "# def train_and_evaluate(train_x, train_y, combined_x, combined_y, test_x, test_y, param_grid, option_type):\n",
    "#     # Get input dimension from the training data\n",
    "#     input_dim = combined_x.shape[1]\n",
    "    \n",
    "#     # Create KerasRegressor with the correct input dimension\n",
    "#     model = create_keras_regressor(input_dim)\n",
    "\n",
    "#     # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "#     grid_search = GridSearchCV(estimator=model,\n",
    "#                                param_grid=param_grid,\n",
    "#                                scoring='neg_mean_squared_error',\n",
    "#                                verbose=3,\n",
    "#                                cv=5, \n",
    "#                                n_jobs=-1)\n",
    "\n",
    "#     # Hyperparameter tuning using validation data\n",
    "#     print(f\"Running hyperparameter tuning with validation data for {option_type}...\")\n",
    "#     grid_search.fit(combined_x, combined_y, verbose=1)\n",
    "\n",
    "#     # Get the best estimator and parameters\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     print(f\"Best Parameters for {option_type}: {best_params}\")\n",
    "\n",
    "#     # In-sample evaluation on the combined training and validation set\n",
    "#     predictions_combined = best_model.predict(combined_x)\n",
    "#     r2_combined = r2_score(combined_y, predictions_combined)\n",
    "#     rmse_combined = np.sqrt(mean_squared_error(combined_y, predictions_combined))\n",
    "#     print(f\"In-sample R² ({option_type}): {r2_combined:.4f}\")\n",
    "#     print(f\"In-sample RMSE ({option_type}): {rmse_combined:.4f}\")\n",
    "\n",
    "#     # Out-of-sample evaluation on the test set\n",
    "#     predictions_test = best_model.predict(test_x)\n",
    "#     r2_test = r2_score(test_y, predictions_test)\n",
    "#     rmse_test = np.sqrt(mean_squared_error(test_y, predictions_test))\n",
    "#     print(f\"Out-of-sample R² ({option_type}): {r2_test:.4f}\")\n",
    "#     print(f\"Out-of-sample RMSE ({option_type}): {rmse_test:.4f}\")\n",
    "\n",
    "#     return best_model, predictions_test\n",
    "\n",
    "# # Extract feature importances based on model weights\n",
    "# def extract_feature_importances(model, X_train, option_type):\n",
    "#     \"\"\"\n",
    "#     Extract feature importance from the weights of the first hidden layer.\n",
    "#     This is a rough approximation based on the magnitude of weights.\n",
    "#     \"\"\"\n",
    "#     # Get the weights of the first hidden layer\n",
    "#     first_layer_weights = model.model_.layers[0].get_weights()[0]\n",
    "\n",
    "#     # Compute the importance as the sum of absolute weights across the neurons\n",
    "#     feature_importances = np.sum(np.abs(first_layer_weights), axis=1)\n",
    "\n",
    "#     # Normalize the importances so they sum to 1\n",
    "#     feature_importances = feature_importances / np.sum(feature_importances)\n",
    "\n",
    "#     # Create a pandas Series for easy handling\n",
    "#     feature_importances = pd.Series(feature_importances, index=X_train.columns)\n",
    "    \n",
    "#     print(f\"Feature importances for {option_type}:\\n\", feature_importances)\n",
    "    \n",
    "#     return feature_importances\n",
    "\n",
    "# # Plot Feature Importance for Keras Neural Network\n",
    "# def plot_feature_importance(feature_importances, option_type, top_n=5):\n",
    "#     \"\"\"\n",
    "#     Create a bar plot showing the top N features based on Keras model weights.\n",
    "#     \"\"\"\n",
    "#     # Select the top N features\n",
    "#     top_features = feature_importances.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "#     # Plot the top N feature importances\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = top_features.sort_values(ascending=True).plot(kind='barh', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "#     plt.grid(True)  # Add grid\n",
    "#     ax.set_title(f'Top {top_n} Feature Importance ({option_type})')\n",
    "#     plt.show()\n",
    "\n",
    "# # Combine feature importances from Call and Put options and plot the top 5\n",
    "# def plot_combined_feature_importance(feature_importances_call, feature_importances_put, top_n=5):\n",
    "#     \"\"\"\n",
    "#     Create a bar plot showing the top N average feature importance of both Call and Put options.\n",
    "#     \"\"\"\n",
    "#     # Combine the feature importances from Call and Put options\n",
    "#     combined_importance = pd.concat([feature_importances_call, feature_importances_put], axis=1, keys=[\"Call\", \"Put\"]).fillna(0)\n",
    "\n",
    "#     # Calculate the average importance\n",
    "#     combined_importance['Average'] = combined_importance.mean(axis=1)\n",
    "\n",
    "#     # Select the top N features based on the average importance\n",
    "#     top_features = combined_importance['Average'].sort_values(ascending=False).head(top_n)\n",
    "\n",
    "#     # Plot the top N combined feature importance\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = top_features.sort_values(ascending=True).plot(kind='barh', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "#     plt.grid(True)  # Add grid\n",
    "#     ax.set_title('NN (Put and Call)')\n",
    "#     plt.show()\n",
    "\n",
    "# # # Example usage\n",
    "# # print(\"\\nEvaluating Call options...\")\n",
    "# # best_model_call, predictions_call = train_and_evaluate(train_x_c, train_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c, param_grid_call, 'Call')\n",
    "\n",
    "# # print(\"\\nEvaluating Put options...\")\n",
    "# # best_model_put, predictions_put = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p, param_grid, 'Put')\n",
    "\n",
    "# # # Extract and plot feature importance for Call options\n",
    "# # feature_importances_call = extract_feature_importances(best_model_call, combined_x_c, 'Call')\n",
    "# # plot_feature_importance(feature_importances_call, 'Call')\n",
    "\n",
    "# # # Extract and plot feature importance for Put options\n",
    "# # feature_importances_put = extract_feature_importances(best_model_put, combined_x_p, 'Put')\n",
    "# # plot_feature_importance(feature_importances_put, 'Put')\n",
    "\n",
    "# # # Plot combined feature importance for both Call and Put options\n",
    "# # plot_combined_feature_importance(feature_importances_call, feature_importances_put, top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to calculate permutation importance on the training set\n",
    "# def permutation_importance(model, X_train, y_train, metric=mean_squared_error, option_type=\"Call\"):\n",
    "#     \"\"\"\n",
    "#     Calculate permutation feature importance by shuffling one feature at a time and measuring the impact on the model's performance.\n",
    "    \n",
    "#     Parameters:\n",
    "#     model: The trained neural network model.\n",
    "#     X_train (pd.DataFrame): Training feature set.\n",
    "#     y_train (pd.Series): Training target variable.\n",
    "#     metric: The metric to measure performance, defaults to mean_squared_error.\n",
    "#     option_type (str): To indicate if it is Call or Put.\n",
    "    \n",
    "#     Returns:\n",
    "#     pd.Series: Normalized feature importances (how much each feature influences model performance, scaled to sum to 1).\n",
    "#     \"\"\"\n",
    "#     # Baseline performance with no shuffling\n",
    "#     baseline_performance = metric(y_train, model.predict(X_train))\n",
    "\n",
    "#     # Initialize an empty dictionary to store the performance drop for each feature\n",
    "#     performance_drop = {}\n",
    "\n",
    "#     # Loop over each feature in the training set\n",
    "#     for feature in X_train.columns:\n",
    "#         # Shuffle the feature\n",
    "#         X_train_shuffled = X_train.copy()\n",
    "#         X_train_shuffled[feature] = np.random.permutation(X_train_shuffled[feature])\n",
    "\n",
    "#         # Measure the model performance on the shuffled training set\n",
    "#         shuffled_performance = metric(y_train, model.predict(X_train_shuffled))\n",
    "\n",
    "#         # The importance of the feature is the drop in performance\n",
    "#         performance_drop[feature] = shuffled_performance - baseline_performance\n",
    "\n",
    "#     # Convert to pandas Series for easier handling and sorting\n",
    "#     feature_importance = pd.Series(performance_drop).abs().sort_values(ascending=False)\n",
    "\n",
    "#     # Normalize the feature importance to sum to 1\n",
    "#     feature_importance = feature_importance / feature_importance.sum()\n",
    "\n",
    "#     print(f\"Normalized Permutation Feature Importance for {option_type}:\\n\", feature_importance)\n",
    "\n",
    "#     return feature_importance\n",
    "\n",
    "# # Plot Feature Importance for Keras Neural Network\n",
    "# def plot_feature_importance(feature_importances, option_type, top_n=5):\n",
    "#     \"\"\"\n",
    "#     Create a bar plot showing the top N features based on permutation importance.\n",
    "#     \"\"\"\n",
    "#     # Select the top N features\n",
    "#     top_features = feature_importances.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "#     # Plot the top N feature importances\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = top_features.sort_values(ascending=True).plot(kind='barh', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "#     plt.grid(True)  # Add grid\n",
    "#     ax.set_title(f'Top {top_n} Feature Importance ({option_type})')\n",
    "#     plt.show()\n",
    "\n",
    "# # Combine feature importances from Call and Put options and plot the top 5\n",
    "# def plot_combined_feature_importance(feature_importances_call, feature_importances_put, top_n=5):\n",
    "#     \"\"\"\n",
    "#     Create a bar plot showing the top N average feature importance of both Call and Put options.\n",
    "#     \"\"\"\n",
    "#     # Combine the feature importances from Call and Put options\n",
    "#     combined_importance = pd.concat([feature_importances_call, feature_importances_put], axis=1, keys=[\"Call\", \"Put\"]).fillna(0)\n",
    "\n",
    "#     # Calculate the average importance\n",
    "#     combined_importance['Average'] = combined_importance.mean(axis=1)\n",
    "\n",
    "#     # Select the top N features based on the average importance\n",
    "#     top_features = combined_importance['Average'].sort_values(ascending=False).head(top_n)\n",
    "\n",
    "#     # Plot the top N combined feature importance\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = top_features.sort_values(ascending=True).plot(kind='barh', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "#     plt.grid(True)  # Add grid\n",
    "#     ax.set_title('Combined Feature Importance (Put and Call)')\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# print(\"\\nEvaluating Call options...\")\n",
    "# best_model_call, predictions_call = train_and_evaluate(train_x_c, train_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c, param_grid_call, 'Call')\n",
    "\n",
    "# print(\"\\nEvaluating Put options...\")\n",
    "# best_model_put, predictions_put = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p, param_grid, 'Put')\n",
    "\n",
    "# # Calculate and plot permutation feature importance for Call options\n",
    "# feature_importances_call = permutation_importance(best_model_call, combined_x_c, combined_y_c, option_type='Call')\n",
    "# plot_feature_importance(feature_importances_call, 'Call')\n",
    "\n",
    "# # Calculate and plot permutation feature importance for Put options\n",
    "# feature_importances_put = permutation_importance(best_model_put, combined_x_p, combined_y_p, option_type='Put')\n",
    "# plot_feature_importance(feature_importances_put, 'Put')\n",
    "\n",
    "# # Plot combined feature importance for both Call and Put options\n",
    "# plot_combined_feature_importance(feature_importances_call, feature_importances_put, top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_day_iv</th>\n",
       "      <th>T</th>\n",
       "      <th>prev2_day_iv</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>hi-lo_stock</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>cumulative_return</th>\n",
       "      <th>spread_vix</th>\n",
       "      <th>vol_stock</th>\n",
       "      <th>5_day_rolling_return_stock</th>\n",
       "      <th>spread_stock</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>RET</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>10Y_RIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542073</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-1.519873</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.699846</td>\n",
       "      <td>-0.133918</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>-1.651490</td>\n",
       "      <td>1.562822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.759052</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-1.519873</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.699846</td>\n",
       "      <td>-0.133918</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>-1.062773</td>\n",
       "      <td>1.562822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.716917</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-1.519873</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.699846</td>\n",
       "      <td>-0.133918</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>-0.482466</td>\n",
       "      <td>1.562822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.693295</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-1.519873</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.699846</td>\n",
       "      <td>-0.133918</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>0.088029</td>\n",
       "      <td>1.562822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.674080</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-1.519873</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.699846</td>\n",
       "      <td>-0.133918</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>0.650114</td>\n",
       "      <td>1.562822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72342</th>\n",
       "      <td>0.024429</td>\n",
       "      <td>1.331335</td>\n",
       "      <td>-0.140819</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-1.160795</td>\n",
       "      <td>1.438222</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>6.899552</td>\n",
       "      <td>-0.552678</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.168781</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>-1.213802</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>1.060814</td>\n",
       "      <td>-0.800536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72343</th>\n",
       "      <td>0.024429</td>\n",
       "      <td>1.331335</td>\n",
       "      <td>-0.140819</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-1.160795</td>\n",
       "      <td>1.438222</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>6.899552</td>\n",
       "      <td>-0.552678</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.168781</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>-1.213802</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>1.156130</td>\n",
       "      <td>-0.800536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72344</th>\n",
       "      <td>0.110670</td>\n",
       "      <td>1.331335</td>\n",
       "      <td>-0.071801</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-1.160795</td>\n",
       "      <td>1.438222</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>6.899552</td>\n",
       "      <td>-0.552678</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.168781</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>-1.213802</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>1.345361</td>\n",
       "      <td>-0.800536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72345</th>\n",
       "      <td>0.158024</td>\n",
       "      <td>1.331335</td>\n",
       "      <td>-0.037014</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-1.160795</td>\n",
       "      <td>1.438222</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>6.899552</td>\n",
       "      <td>-0.552678</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.168781</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>-1.213802</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>1.533190</td>\n",
       "      <td>-0.800536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72346</th>\n",
       "      <td>0.208890</td>\n",
       "      <td>1.331335</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-1.160795</td>\n",
       "      <td>1.438222</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>6.899552</td>\n",
       "      <td>-0.552678</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.168781</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>-1.213802</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>1.718215</td>\n",
       "      <td>-0.800536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72347 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prev_day_iv         T  prev2_day_iv     BIDLO  OPEN_vix  hi-lo_stock  \\\n",
       "0        -1.542073 -0.854054     -1.519873 -0.567166  0.674867    -0.484127   \n",
       "1        -0.759052 -0.854054     -1.519873 -0.567166  0.674867    -0.484127   \n",
       "2        -0.716917 -0.854054     -1.519873 -0.567166  0.674867    -0.484127   \n",
       "3        -0.693295 -0.854054     -1.519873 -0.567166  0.674867    -0.484127   \n",
       "4        -0.674080 -0.854054     -1.519873 -0.567166  0.674867    -0.484127   \n",
       "...            ...       ...           ...       ...       ...          ...   \n",
       "72342     0.024429  1.331335     -0.140819  0.072540 -0.057404    -0.090463   \n",
       "72343     0.024429  1.331335     -0.140819  0.072540 -0.057404    -0.090463   \n",
       "72344     0.110670  1.331335     -0.071801  0.072540 -0.057404    -0.090463   \n",
       "72345     0.158024  1.331335     -0.037014  0.072540 -0.057404    -0.090463   \n",
       "72346     0.208890  1.331335      0.001623  0.072540 -0.057404    -0.090463   \n",
       "\n",
       "        FF_rate  gold_price  reces_indi  cumulative_return  spread_vix  \\\n",
       "0      1.124610   -1.353864   -0.709827          -0.699846   -0.133918   \n",
       "1      1.124610   -1.353864   -0.709827          -0.699846   -0.133918   \n",
       "2      1.124610   -1.353864   -0.709827          -0.699846   -0.133918   \n",
       "3      1.124610   -1.353864   -0.709827          -0.699846   -0.133918   \n",
       "4      1.124610   -1.353864   -0.709827          -0.699846   -0.133918   \n",
       "...         ...         ...         ...                ...         ...   \n",
       "72342 -1.160795    1.438222    0.268029           6.899552   -0.552678   \n",
       "72343 -1.160795    1.438222    0.268029           6.899552   -0.552678   \n",
       "72344 -1.160795    1.438222    0.268029           6.899552   -0.552678   \n",
       "72345 -1.160795    1.438222    0.268029           6.899552   -0.552678   \n",
       "72346 -1.160795    1.438222    0.268029           6.899552   -0.552678   \n",
       "\n",
       "       vol_stock  5_day_rolling_return_stock  spread_stock   1Y_bond  \\\n",
       "0       0.737871                   -0.286276     -0.125902  1.371916   \n",
       "1       0.737871                   -0.286276     -0.125902  1.371916   \n",
       "2       0.737871                   -0.286276     -0.125902  1.371916   \n",
       "3       0.737871                   -0.286276     -0.125902  1.371916   \n",
       "4       0.737871                   -0.286276     -0.125902  1.371916   \n",
       "...          ...                         ...           ...       ...   \n",
       "72342   0.003482                    0.168781     -0.047492 -1.213802   \n",
       "72343   0.003482                    0.168781     -0.047492 -1.213802   \n",
       "72344   0.003482                    0.168781     -0.047492 -1.213802   \n",
       "72345   0.003482                    0.168781     -0.047492 -1.213802   \n",
       "72346   0.003482                    0.168781     -0.047492 -1.213802   \n",
       "\n",
       "       CLOSE_vix       RET  moneyness   10Y_RIR  \n",
       "0       0.476238 -0.080584  -1.651490  1.562822  \n",
       "1       0.476238 -0.080584  -1.062773  1.562822  \n",
       "2       0.476238 -0.080584  -0.482466  1.562822  \n",
       "3       0.476238 -0.080584   0.088029  1.562822  \n",
       "4       0.476238 -0.080584   0.650114  1.562822  \n",
       "...          ...       ...        ...       ...  \n",
       "72342  -0.034979  0.020966   1.060814 -0.800536  \n",
       "72343  -0.034979  0.020966   1.156130 -0.800536  \n",
       "72344  -0.034979  0.020966   1.345361 -0.800536  \n",
       "72345  -0.034979  0.020966   1.533190 -0.800536  \n",
       "72346  -0.034979  0.020966   1.718215 -0.800536  \n",
       "\n",
       "[72347 rows x 19 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moneyness_mean</th>\n",
       "      <th>moneyness_std</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>volume_option_mean</th>\n",
       "      <th>volume_option_std</th>\n",
       "      <th>spread_option_mean</th>\n",
       "      <th>spread_option_std</th>\n",
       "      <th>prc_option_mean</th>\n",
       "      <th>prc_option_std</th>\n",
       "      <th>PRC_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>prev2_iv_std</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>10Y_RIR</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>hi-lo_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>-1.583860</td>\n",
       "      <td>-0.487562</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>-0.877439</td>\n",
       "      <td>-0.858837</td>\n",
       "      <td>-0.485643</td>\n",
       "      <td>-0.495661</td>\n",
       "      <td>-0.443406</td>\n",
       "      <td>-0.421574</td>\n",
       "      <td>0.256616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371799</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>-1.216221</td>\n",
       "      <td>1.280503</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>-0.772302</td>\n",
       "      <td>-0.700220</td>\n",
       "      <td>-0.439883</td>\n",
       "      <td>-0.439156</td>\n",
       "      <td>-0.406164</td>\n",
       "      <td>-0.373867</td>\n",
       "      <td>0.660443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752631</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>-0.865971</td>\n",
       "      <td>0.199870</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>-0.719237</td>\n",
       "      <td>-0.690382</td>\n",
       "      <td>-0.361681</td>\n",
       "      <td>-0.397490</td>\n",
       "      <td>-0.295805</td>\n",
       "      <td>-0.266617</td>\n",
       "      <td>1.800703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256859</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>-0.522997</td>\n",
       "      <td>-0.191891</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>-0.630035</td>\n",
       "      <td>-0.814728</td>\n",
       "      <td>-0.327492</td>\n",
       "      <td>-0.321930</td>\n",
       "      <td>-0.226844</td>\n",
       "      <td>-0.137906</td>\n",
       "      <td>0.965974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450171</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.510639</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>-0.534790</td>\n",
       "      <td>-0.744032</td>\n",
       "      <td>-0.181918</td>\n",
       "      <td>-0.211518</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>0.040999</td>\n",
       "      <td>1.365983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106734</td>\n",
       "      <td>-1.162816</td>\n",
       "      <td>1.451941</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.801314</td>\n",
       "      <td>-1.218487</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.071108</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>-0.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>0.181550</td>\n",
       "      <td>0.237646</td>\n",
       "      <td>-0.757755</td>\n",
       "      <td>4.186096</td>\n",
       "      <td>3.167768</td>\n",
       "      <td>-0.287673</td>\n",
       "      <td>-0.370265</td>\n",
       "      <td>-0.196717</td>\n",
       "      <td>-0.214028</td>\n",
       "      <td>1.578397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436048</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>0.511030</td>\n",
       "      <td>0.265937</td>\n",
       "      <td>-0.757755</td>\n",
       "      <td>3.796540</td>\n",
       "      <td>3.256683</td>\n",
       "      <td>-0.078624</td>\n",
       "      <td>-0.094334</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.145317</td>\n",
       "      <td>2.259480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537905</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>0.861979</td>\n",
       "      <td>-1.010289</td>\n",
       "      <td>-0.757755</td>\n",
       "      <td>3.046870</td>\n",
       "      <td>1.637046</td>\n",
       "      <td>0.299275</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>0.528917</td>\n",
       "      <td>1.423552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450505</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>1.214787</td>\n",
       "      <td>-1.080205</td>\n",
       "      <td>-0.757755</td>\n",
       "      <td>3.186761</td>\n",
       "      <td>3.633091</td>\n",
       "      <td>4.100742</td>\n",
       "      <td>6.256574</td>\n",
       "      <td>1.013222</td>\n",
       "      <td>1.103365</td>\n",
       "      <td>2.200422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355298</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7539</th>\n",
       "      <td>1.555450</td>\n",
       "      <td>0.455627</td>\n",
       "      <td>-0.757755</td>\n",
       "      <td>-0.769856</td>\n",
       "      <td>-0.866448</td>\n",
       "      <td>5.026732</td>\n",
       "      <td>7.992911</td>\n",
       "      <td>1.554065</td>\n",
       "      <td>1.643785</td>\n",
       "      <td>1.644838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332371</td>\n",
       "      <td>-1.172726</td>\n",
       "      <td>0.958946</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.812020</td>\n",
       "      <td>-0.455627</td>\n",
       "      <td>-0.568767</td>\n",
       "      <td>-0.630316</td>\n",
       "      <td>-0.381699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2498 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      moneyness_mean  moneyness_std    T_mean  volume_option_mean  \\\n",
       "5040       -1.583860      -0.487562  1.515971           -0.877439   \n",
       "5041       -1.216221       1.280503  1.515971           -0.772302   \n",
       "5042       -0.865971       0.199870  1.515971           -0.719237   \n",
       "5043       -0.522997      -0.191891  1.515971           -0.630035   \n",
       "5044       -0.175572      -0.510639  1.515971           -0.534790   \n",
       "...              ...            ...       ...                 ...   \n",
       "7535        0.181550       0.237646 -0.757755            4.186096   \n",
       "7536        0.511030       0.265937 -0.757755            3.796540   \n",
       "7537        0.861979      -1.010289 -0.757755            3.046870   \n",
       "7538        1.214787      -1.080205 -0.757755            3.186761   \n",
       "7539        1.555450       0.455627 -0.757755           -0.769856   \n",
       "\n",
       "      volume_option_std  spread_option_mean  spread_option_std  \\\n",
       "5040          -0.858837           -0.485643          -0.495661   \n",
       "5041          -0.700220           -0.439883          -0.439156   \n",
       "5042          -0.690382           -0.361681          -0.397490   \n",
       "5043          -0.814728           -0.327492          -0.321930   \n",
       "5044          -0.744032           -0.181918          -0.211518   \n",
       "...                 ...                 ...                ...   \n",
       "7535           3.167768           -0.287673          -0.370265   \n",
       "7536           3.256683           -0.078624          -0.094334   \n",
       "7537           1.637046            0.299275           0.540500   \n",
       "7538           3.633091            4.100742           6.256574   \n",
       "7539          -0.866448            5.026732           7.992911   \n",
       "\n",
       "      prc_option_mean  prc_option_std  PRC_mean  ...  prev2_iv_std   FF_rate  \\\n",
       "5040        -0.443406       -0.421574  0.256616  ...      0.371799 -1.162816   \n",
       "5041        -0.406164       -0.373867  0.660443  ...      0.752631 -1.162816   \n",
       "5042        -0.295805       -0.266617  1.800703  ...      0.256859 -1.162816   \n",
       "5043        -0.226844       -0.137906  0.965974  ...      0.450171 -1.162816   \n",
       "5044        -0.065441        0.040999  1.365983  ...     -0.106734 -1.162816   \n",
       "...               ...             ...       ...  ...           ...       ...   \n",
       "7535        -0.196717       -0.214028  1.578397  ...     -0.436048 -1.172726   \n",
       "7536         0.075989        0.145317  2.259480  ...     -0.537905 -1.172726   \n",
       "7537         0.429161        0.528917  1.423552  ...     -0.450505 -1.172726   \n",
       "7538         1.013222        1.103365  2.200422  ...     -0.355298 -1.172726   \n",
       "7539         1.554065        1.643785  1.644838  ...     -0.332371 -1.172726   \n",
       "\n",
       "      gold_price  reces_indi   10Y_RIR   1Y_bond   2Y_bond  OPEN_vix  \\\n",
       "5040    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5041    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5042    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5043    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "5044    1.451941    0.266074 -0.801314 -1.218487 -1.213376 -0.071108   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "7535    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7536    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7537    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7538    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "7539    0.958946   -0.822889  0.047437 -0.812020 -0.455627 -0.568767   \n",
       "\n",
       "      CLOSE_vix  hi-lo_vix  \n",
       "5040  -0.041412  -0.407989  \n",
       "5041  -0.041412  -0.407989  \n",
       "5042  -0.041412  -0.407989  \n",
       "5043  -0.041412  -0.407989  \n",
       "5044  -0.041412  -0.407989  \n",
       "...         ...        ...  \n",
       "7535  -0.630316  -0.381699  \n",
       "7536  -0.630316  -0.381699  \n",
       "7537  -0.630316  -0.381699  \n",
       "7538  -0.630316  -0.381699  \n",
       "7539  -0.630316  -0.381699  \n",
       "\n",
       "[2498 rows x 48 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Call options...\n",
      "Running hyperparameter tuning with validation data...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 0.4795 - mse: 0.4795 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - loss: 0.3102 - mse: 0.3102\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - loss: 0.5695 - mse: 0.5695 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1664 - mse: 1.1664\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4433 - mse: 0.4433\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2389 - mse: 0.2389\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3097 - mse: 0.3097\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0720 - mse: 0.0720 Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0632 - mse: 0.06328\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3155 - mse: 0.3155\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0605 - mse: 0.0605\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.1755 - mse: 0.1755\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0845 - mse: 0.0845\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.0786 - mse: 0.0786\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0491 - mse: 0.0491\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0393 - mse: 0.0393 Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0358 - mse: 0.0358\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.0337 - mse: 0.0337\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0810 - mse: 0.0810\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.0251 - mse: 0.0251\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0160 - mse: 0.0160Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - mse: 0.0194 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mse: 0.02466\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0236 - mse: 0.0236Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 6/50\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0384 - mse: 0.0384Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.0347 - mse: 0.0347\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0181 - mse: 0.0181Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.0371 - mse: 0.0371\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0272 - mse: 0.0272  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0132 - mse: 0.0132\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0184 - mse: 0.0184Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0153 - mse: 0.0153 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0149 - mse: 0.0149\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0268 - mse: 0.0268Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.01471\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0191 - mse: 0.0191Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132 - mse: 0.0132  \n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0121 - mse: 0.0121Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 12/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 13/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0138 - mse: 0.0138\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 14/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.00999\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0094 - mse: 0.0094\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089 Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 15/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.0054 - mse: 0.0054Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.0120 - mse: 0.0120\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0080 - mse: 0.0080Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0084 - mse: 0.0084\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0081 - mse: 0.0081Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0064 - mse: 0.0064Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0106 - mse: 0.0106Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0058 - mse: 0.0058\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 25/50\n",
      "Epoch 25/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 26/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0069 - mse: 0.0069Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.00947\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 31/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0076 - mse: 0.0076Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.00788\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.0062 - mse: 0.0062Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 31/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0064 - mse: 0.0064Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0046 - mse: 0.0046\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066 Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.007361\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0116 - mse: 0.0116Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.005483\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0060 - mse: 0.0060\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 39/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0052 - mse: 0.0052\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059 Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0056 - mse: 0.0056Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.005362 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.008662\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - mse: 0.0081 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - mse: 0.0067Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - mse: 0.0043 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 39/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0052 - mse: 0.0052\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0046 - mse: 0.0046Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.00806\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0046 - mse: 0.0046\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0030 - mse: 0.0030Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0026 - mse: 0.0026Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0127 - mse: 0.0127Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 42/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0072 - mse: 0.0072Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0046 - mse: 0.0046\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 46/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.00394\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.006258\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.00466\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.0070 - mse: 0.0070 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0039 - mse: 0.0039\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.063 total time=   7.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.0064\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.019 total time=   7.0s\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 46/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 50/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 47/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0073 - mse: 0.0073[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.026 total time=   7.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 48/50\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.0056 - mse: 0.0056Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046 \n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 49/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - mse: 0.0036[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.050 total time=   7.3s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.114 total time=   7.3s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.478 total time=   7.4s\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0041 - mse: 0.0041Epoch 1/50\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041  Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 492ms/step - loss: 0.8687 - mse: 0.8687Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2039 - mse: 0.2039\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5681 - mse: 0.5681\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.0041 - mse: 0.0041\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9524 - mse: 0.9524\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 3/50\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.0545 - mse: 0.0545[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=nan total time=   0.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 4/50\n",
      "\u001b[1m 1/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 49ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 17:49:09.992825: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Trying to assign to variable with tensor with wrong shape. Expected [] got [0]\n",
      "\t [[{{function_node __inference_one_step_on_data_119054}}{{node AssignVariableOp_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.043 total time=   7.7s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0195 - mse: 0.0195Epoch 1/50\n",
      "\u001b[1m 18/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - mse: 0.0264 Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steposs: 0.3878 - mse: 0.38980.0255\n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - mse: 0.0152[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.031 total time=   7.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.016093\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - mse: 0.0247Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - loss: 0.0098 - mse: 0.0098Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1664 - mse: 0.1664\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1642 - mse: 0.1642\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1756 - mse: 0.1756\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0217 - mse: 0.0217 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0265 - mse: 0.0265\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 4/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0100 - mse: 0.0100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - loss: 0.1832 - mse: 0.1832\n",
      "Epoch 11/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.0097 - mse: 0.0097\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0051 - mse: 0.0051Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0120 - mse: 0.0120\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 9/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - loss: 0.1466 - mse: 0.1466\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - loss: 0.1025 - mse: 0.1025\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0258 - mse: 0.0258Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0097 - mse: 0.0097\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0253 - mse: 0.0253Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0250 - mse: 0.02508\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 4/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.0086 - mse: 0.0086 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 14/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.0134 - mse: 0.0134 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0094 - mse: 0.0094\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 0.0119 - mse: 0.0119Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0077 - mse: 0.0077Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063 Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 22/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.0053 - mse: 0.0053\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0056 - mse: 0.0056\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0045 - mse: 0.0045Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 27/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0056 - mse: 0.0056\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0038 - mse: 0.0038Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0051 - mse: 0.0051Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0050 - mse: 0.0050Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0050 - mse: 0.0050Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mse: 0.0039  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047 Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.00483\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0031 - mse: 0.0031 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0041 - mse: 0.0041\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 35/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0049 - mse: 0.0049\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.00343\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.00343\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 25/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.00364\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.00444 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0035 - mse: 0.0035Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 38/50\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.0033 - mse: 0.0033 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0038 - mse: 0.0038Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.003636\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046 44\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0044 - mse: 0.0044 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 42/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0036 - mse: 0.0036Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0046 - mse: 0.0046Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 37/50\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0026 - mse: 0.0026     \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 38/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 36/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0042 - mse: 0.0042      \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 37/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0028 - mse: 0.0028Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022   \n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0029 - mse: 0.0029Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 39/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0028 - mse: 0.0028\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030 \n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.0040 - mse: 0.004\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021Epoch 49/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.028 total time=   6.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 41/50\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0034 - mse: 0.0034Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0019 - mse: 0.001038\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 43/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.052 total time=   7.1s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepstep - loss: 0.0017 - mse: 0.00\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0036 - mse: 0.0036\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=-0.051 total time=   7.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mse: 0.0016Epoch 1/50\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014         Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m44/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step Epoch 44/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0028 - mse: 0.002\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 0.0016 - mse: 0.0016[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.283 total time=   7.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 48/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030       \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step 0.0053 - mse: 0.005e: 0.1573    \n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=-0.106 total time=   7.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.00272\n",
      "Epoch 47/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1043 - mse: 0.1043Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016 \n",
      "Epoch 47/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0950 - mse: 0.0950\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027       \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018    \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0864 - mse: 0.0864   \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2932 - mse: 0.2932\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mse: 0.0400\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 50/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/stepstep - loss: 0.0015 - mse: 0.001 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015  \n",
      "Epoch 50/50\n",
      "\u001b[1m 31/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.016 total time=   8.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2997 - mse: 0.2997\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0132 - mse: 0.0132Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0823 - mse: 0.08230\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0015 - mse: 0.0015\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0055 - mse: 0.0086\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0332 - mse: 0.0332[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.075 total time=   8.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mse: 0.0325 \n",
      "Epoch 3/50\n",
      "\u001b[1m 62/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0084 - mse: 0.005\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.031 total time=   8.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.0196 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 7/50\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.0140  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - mse: 0.00700 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 8/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0852 - mse: 0.0852\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.009326\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0063 - mse: 0.0063\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 12/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.00906\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - loss: 0.1349 - mse: 0.1349\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 13/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.00930\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 11/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 14/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0685 - mse: 0.0685\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 8/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0090 - mse: 0.0090Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.00918\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0105 - mse: 0.0105Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.0076 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 14/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.00665\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 17/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0053 - mse: 0.0053Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.007460\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.00685\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037 \n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.0040 - mse: 0.0040Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.00664\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.003866\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - mse: 0.00366 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0046 - mse: 0.0046 Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.00433\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.00363\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053  \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mse: 0.0049  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0033 - mse: 0.0033\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0053 - mse: 0.0053\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 26/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029   \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046 1\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 34/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0025 - mse: 0.0025Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0031 - mse: 0.0031\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 29/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mse: 0.0033   \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027 \n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027  Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - mse: 0.0053         \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.00222\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0048 - mse: 0.0048\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.00312\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.00233\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.00433      \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039   \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.004719      \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0042 - mse: 0.0042Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0041 - mse: 0.0041\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019 Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0037 - mse: 0.0037 Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0028 - mse: 0.0028\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 40/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.004817       \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0038 - mse: 0.0038Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 34/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0034 - mse: 0.0034Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0027 - mse: 0.0027Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mse: 0.00287\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 49/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mse: 0.00366\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0026 - mse: 0.0026  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012         Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 42/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.003626\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 38/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.017 total time=  10.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mse: 0.0026Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0026 - mse: 0.0004\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.065 total time=  11.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027        \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024  \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 44/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - mse: 0.0020Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mse: 0.00142       \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mse: 0.0018        \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - mse: 0.00382\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0022 - mse: 0.0022Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016 Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0035 - mse: 0.0035\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1009 - mse: 0.1009 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 2/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0018 - mse: 0.0018     \n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/steps: 0.0011 - mse: 0.00\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - mse: 0.0022[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.030 total time=  11.2s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0118 - mse: 0.0118[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.092 total time=  11.9s\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142 Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.054 total time=  11.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018   \n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0025 - mse: 0.0025Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0772 - mse: 0.0772\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 48/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.123 total time=  10.9s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0049 - mse: 0.0049[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.031 total time=  11.0s\n",
      "\u001b[1m 22/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1614 - mse: 0.1614    Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012   \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0773 - mse: 0.0773\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1011 - mse: 0.1011\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3555 - mse: 0.3555\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0013 - mse: 0.0013\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - mse: 0.0224\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054  Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0254 - mse: 0.0254  \n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0182 - mse: 0.01\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0134 - mse: 0.0134[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.022 total time=  11.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 4/50\n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mse: 0.0200   \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 2/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0615 - mse: 0.061596\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.0190  \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.01406\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.01190\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0049 - mse: 0.0049\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 10/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.0108 - mse: 0.0108 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.011012\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0103 - mse: 0.0103Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.009354\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0156 - mse: 0.0156\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0113 - mse: 0.0113 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - loss: 0.0605 - mse: 0.0605\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0120 - mse: 0.0120Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.00903\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.01421\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 4/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0084 - mse: 0.0084 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m 20/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mse: 0.0070 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 212ms/step - loss: 0.0083 - mse: 0.0083Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0074 - mse: 0.0074Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0101 - mse: 0.0101 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073   Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 15/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mse: 0.0065 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 9/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.006765\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 17/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.006449\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.00585\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0024 - mse: 0.0024 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.005725\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026   \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 20/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035        \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042 9\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0041 - mse: 0.0041\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 16/50\n",
      "Epoch 20/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020  \n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.00722\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0056 - mse: 0.0056      \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058  \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.00564\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040  \n",
      "Epoch 22/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.0034\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - loss: 0.0031 - mse: 0.0031Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014          \n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042  Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027   Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.005240\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mse: 0.00373\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - mse: 0.0064Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 29/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mse: 0.0028\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0059 - mse: 0.0059Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0032 - mse: 0.0032\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0051 - mse: 0.0051Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0049 - mse: 0.0049\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 28/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.00283\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0031 - mse: 0.0031      \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 150ms/step - loss: 0.0048 - mse: 0.0048Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m 31/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060   Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.0017 - mse: 0.0017        \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049 5\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 34/50\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046         \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063       \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0023 - mse: 0.0023       \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012          \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030          \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mse: 0.00314\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - mse: 0.0054 Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - mse: 0.0045 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mse: 0.0056 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "\u001b[1m 26/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044 Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.00411\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.00213 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - loss: 0.0017 - mse: 0.0017Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012   \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043  \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0021 - mse: 0.0021Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mse: 0.0014Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - mse: 0.00401\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.00426533e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056       \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 40/50\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.00227332e-0\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 37/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 144ms/step - loss: 7.0687e-04 - mse: 7.0687e-04Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0055 - mse: 0.0055       \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - loss: 0.0018 - mse: 0.0018Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0018 - mse: 0.0018 Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0017 - mse: 0.0017Epoch 41/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0019 - mse: 0.0019 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0030 - mse: 0.0030Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.00497273e-0\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019       \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.00531\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━��━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032 Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 50/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.00351\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.00199.0534e-0\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 9.2594e-04 - mse: 9.2594e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 50/50\n",
      "\u001b[1m  7/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0033 - mse: 0.0033Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.001938 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0010 - mse: 0.0010        \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.00340\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.00181\n",
      "\u001b[1m39/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   Epoch 44/50023 - mse: 0.0023\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mse: 0.0036 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - mse: 0.00504\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 43/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.032 total time=  12.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 45/50\n",
      "\u001b[1m  7/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - mse: 0.0025 Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/stepep - loss: 0.0041 - mse: 0.001      \n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mse: 0.0020[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.070 total time=  12.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 50/50\n",
      "Epoch 46/50\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.0026 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - mse: 0.0040[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.024 total time=  11.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mse: 0.0033\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.00222\n",
      "Epoch 49/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - mse: 0.0017Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mse: 0.00171\n",
      "Epoch 48/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steps: 8.6389e-04 - mse: 8.6389e-\n",
      "\u001b[1m38/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.050 total time=  11.9s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0022 - mse: 0.0013        \n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017Epoch 50/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.039 total time=  12.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 47/50\n",
      "\u001b[1m 18/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0712 - mse: 0.0712\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0571 - mse: 0.0571\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/stepep - loss: 0.0191 - mse: 0.0119\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0191 - mse: 0.0191[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.024 total time=  12.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mse: 0.0015\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 689ms/step - loss: 1.6448 - mse: 1.6448Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mse: 0.0179   \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7917 - mse: 0.7917\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0785 - mse: 0.0785\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1321 - mse: 1.1321\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steps: 0.2801 - mse: 0.28se: 0.0016\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.039 total time=  12.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.2558 - mse: 0.2558\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 5/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.3316 - mse: 0.3316\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.1354 - mse: 0.1354\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0043 - mse: 0.00se: 0.0147 \n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0835 - mse: 0.0835[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.081 total time=  12.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0794 - mse: 0.0794\n",
      "Epoch 5/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0897 - mse: 0.0897\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0634 - mse: 0.0634   \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6013 - mse: 0.6013\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0589 - mse: 0.0589\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1307 - mse: 0.1307\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mse: 0.033535 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1185 - mse: 1.1185\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0694 - mse: 0.0694\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.00742\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.0327 - mse: 0.0327\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0194 - mse: 0.0194Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2534 - mse: 0.2534\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0415 - mse: 0.0415\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.1357 - mse: 0.1357\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - mse: 0.0063  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mse: 0.0043   \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1187 - mse: 1.118742\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0883 - mse: 0.0883\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0061 - mse: 0.0061 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.3080 - mse: 0.3080\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.003889\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 12/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.023633\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1466 - mse: 0.1466 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0408 - mse: 0.04080\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.01674\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0969 - mse: 0.0969\n",
      "Epoch 11/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0181 - mse: 0.0181Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0197 - mse: 0.0197\n",
      "\u001b[1m 32/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0312 - mse: 0.0312 Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.01647\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 16/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mse: 0.0295\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 8/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.003970\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.00356\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.00379\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 17/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.00297\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.01809\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 16/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0148 - mse: 0.0148\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 13/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0195 - mse: 0.0195\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 15/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.00297\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0010 - mse: 0.0010Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.0136  \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mse: 0.0017   \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.0136��━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0161 - mse: 0.0161\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 26/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 28/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.00215\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━���━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0025 - mse: 0.0025 Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.002484\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.00231  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0120 - mse: 0.0120Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.00151\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0156 - mse: 0.0156 Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 29/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019001\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.0103 - mse: 0.0103 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 30/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.002144\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 35/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102         \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.01383\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.00136\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━��━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.0173 - mse: 0.0173     \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 33/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0085 - mse: 0.0085     \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012  \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0080 - mse: 0.0080      \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0160 - mse: 0.0160      \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.001501\n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0110 - mse: 0.0110Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0158 - mse: 0.0158        \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.0082Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.00828\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0131 - mse: 0.0131Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.4375e-04 - mse: 7.4375e-04Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.011783       \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.014705\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - mse: 0.00799        \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.01136905e-04 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0099 - mse: 0.009913e-\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mse: 0.0010 mse: 0.0010        \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.00154144e-0\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0086 - mse: 0.008662e-0\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3393e-04 - mse: 9.3393e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.0143 - mse: 0.014317e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0125 - mse: 0.0125     \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0088 - mse: 0.008821e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.001563\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0092 - mse: 0.00926147e-0\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.012614      \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7821e-04 - mse: 9.7821e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 43/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0014 - mse: 0.001491e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0151 - mse: 0.015142e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.00766935e-0\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9500e-04 - mse: 9.9500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0109 - mse: 0.010941e-0\n",
      "Epoch 47/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.032 total time=   9.2s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.032 total time=   9.3s\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 44/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.00815745e-0\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5928e-04 - mse: 9.5928e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - mse: 0.01179110e-0 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.00839427e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9435e-04 - mse: 8.9435e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mse: 0.0141 Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.01318504e-0\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8257e-04 - mse: 8.8257e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.0116 - mse: 0.0116     \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9165e-04 - mse: 7.9165e-04  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 0.5636 - mse: 0.5636\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 2/50\n",
      "Epoch 49/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.0121 - mse: 0.0121\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - loss: 0.8495 - mse: 0.8495\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111 308e-04 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0014 - mse: 0.001.0137e-0   \n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1726 - mse: 0.1726[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.558 total time=   9.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9024e-04 - mse: 8.9024e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 50/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━���━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1648 - mse: 0.1648\n",
      "Epoch 3/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.2187e-04 - mse: 6.2187e-04Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2173 - mse: 0.2173 \n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 8.8615e-04 - mse: 8.8615e- \n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.043 total time=   9.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8642e-04 - mse: 8.8642e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0788 - mse: 0.0788\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - loss: 0.0018 - mse: 0.0018Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1211 - mse: 0.1211 \n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0542 - mse: 0.051\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0640 - mse: 0.064\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.032 total time=   9.1s\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.031 total time=  11.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 5/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0411 - mse: 0.0411Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0677 - mse: 0.0677\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/stepp - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 5/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 444ms/step - loss: 0.4711 - mse: 0.4711[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.037 total time=  12.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "Epoch 50/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0334 - mse: 0.0334 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3818 - mse: 0.3818       \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4204 - mse: 0.4204 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0596 - mse: 0.0596\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6617 - mse: 0.6617\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2891 - mse: 0.2891\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0228 - mse: 0.0228Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1101 - mse: 0.1101\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1238 - mse: 0.1238\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1410 - mse: 0.1410\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0955 - mse: 0.0955\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0740 - mse: 0.0740  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0685 - mse: 0.0685\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━���━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0324 - mse: 0.032\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0518 - mse: 0.0518[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.060 total time=  12.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206 \n",
      "Epoch 8/50\n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mse: 0.0515 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0599 - mse: 0.0599\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mse: 0.0507Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0759 - mse: 0.0759\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0496 - mse: 0.0496 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0453 - mse: 0.0453\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0287 - mse: 0.0287   \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0327 - mse: 0.0327\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0230 - mse: 0.0230 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0353 - mse: 0.035383\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.01616\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - mse: 0.021064\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0569 - mse: 1.0569\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1338 - mse: 0.133854\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0253 - mse: 0.0253\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 8/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132 - mse: 0.01327\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0678 - mse: 0.0678\n",
      "Epoch 14/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0476 - mse: 0.0476\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4771 - mse: 0.4771\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0279 - mse: 0.0279 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 16/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0428 - mse: 0.04286\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0073 - mse: 0.0073Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.1203 - mse: 0.1203 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0125 - mse: 0.0125\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.0222 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0239 - mse: 0.02392\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0705 - mse: 0.0705\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.01585\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0337 - mse: 0.0337\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0553 - mse: 0.0553\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - mse: 0.024806\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 9/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0387 - mse: 0.0387\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0097 - mse: 0.0097Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0329 - mse: 0.0329\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0121 - mse: 0.0121Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mse: 0.0246\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0292 - mse: 0.0292 Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━���━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0031 - mse: 0.0031Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.0114 - mse: 0.0114\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - loss: 0.0283 - mse: 0.0283Epoch 18/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 0.0100 - mse: 0.0100Epoch 23/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0156 - mse: 0.0156 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 18/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - mse: 0.0143 \n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.0087  Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.022438\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.00892\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 20/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mse: 0.0215 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - mse: 0.0104  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213 Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mse: 0.00790\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 14/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0073 - mse: 0.0073Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0224 - mse: 0.0224\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 26/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0098 - mse: 0.0098Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0130 - mse: 0.0130\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0098 - mse: 0.0098 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0183 - mse: 0.0183 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0081 - mse: 0.0081 \n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0112 - mse: 0.0112Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0187 - mse: 0.0187  \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0191 - mse: 0.0191  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 28/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 18/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.0094 - mse: 0.0094\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.00756\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mse: 0.01281\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0074 - mse: 0.0074\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0175 - mse: 0.0175Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0162 - mse: 0.0162\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 20/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0139 - mse: 0.0139.0058 - mse: 0.005\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mse: 0.00997\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.015990\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - mse: 0.0094 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.007335\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0192 - mse: 0.0192  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0073 - mse: 0.00737\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0161 - mse: 0.0161Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0070 - mse: 0.0070Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.01387\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.0053 - mse: 0.0053Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0074 - mse: 0.0074\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0116 - mse: 0.0116Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0175 - mse: 0.017560\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.0096 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149   \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0150 - mse: 0.01502\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.00871\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0158 - mse: 0.0158Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.006969\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0118 - mse: 0.0118\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0178 - mse: 0.0178Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.0177 - mse: 0.0177\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0116 - mse: 0.0116Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 43/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 42/50\n",
      "Epoch 48/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0046 - mse: 0.0046Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0128 - mse: 0.0128Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0137 - mse: 0.0137\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0049 - mse: 0.0049Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mse: 0.007165\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.01358 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 45/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.510 total time=  15.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mse: 0.0167/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 45/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0131 - mse: 0.0131Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0166 - mse: 0.0166Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 48/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0135 - mse: 0.013752\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 40/50\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132 - mse: 0.0132 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.029 total time=  15.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 47/50\n",
      "\u001b[1m 17/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0154 - mse: 0.0154 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 47/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.01286   \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5866 - mse: 0.5866\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.1058 - mse: 0.1058\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 40/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.031 total time=  15.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 44/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1004 - mse: 0.1004   \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121  \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5915 - mse: 0.5915\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1342 - mse: 0.1342[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.041 total time=  15.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0327 - mse: 0.0327[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.751 total time=  15.8s\n",
      "Epoch 1/50\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0937 - mse: 0.0937\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mse: 0.0387\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0138 - mse: 0.013\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0515 - mse: 0.0515[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.013 total time=  15.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0516 - mse: 0.0516\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 47/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0214 - mse: 0.0214Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mse: 0.0392   \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3221 - mse: 0.3221  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2289 - mse: 0.22894  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0831 - mse: 0.0831\n",
      "Epoch 46/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2791 - mse: 0.2791  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0559 - mse: 0.0559\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mse: 0.0490\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - mse: 0.014317\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0884 - mse: 1.088458\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/stepp - loss: 0.1858 - mse: 0.185779\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - mse: 0.0116[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.047 total time=  17.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1633 - mse: 0.1633\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0333 - mse: 0.0333\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0170 - mse: 0.0170Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0264 - mse: 0.0264  \n",
      "Epoch 5/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0141 - mse: 0.0141Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mse: 0.0239  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0983 - mse: 0.0983\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 6/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0080 - mse: 0.0080Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - mse: 0.01121 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mse: 0.0197\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0704 - mse: 0.0704\n",
      "Epoch 7/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - mse: 0.016389\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0161 - mse: 0.0161Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0191 - mse: 0.0191 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.01517\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "\u001b[1m26/53\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mse: 0.016017\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steps: 0.0094 - mse: 0.0002\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 9/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.016 total time=  18.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 16/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.0098 - mse: 0.0098Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.0746 - mse: 0.0746\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.01411\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0428 - mse: 0.0428Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129 Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mse: 0.0342\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mse: 0.0333Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.011014\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0143 - mse: 0.0143\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0133 - mse: 0.0133Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0102 - mse: 0.0102 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 15/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118  \n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.0309 - mse: 0.0309\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7617 - mse: 0.7617\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0344 - mse: 0.0344 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1017 - mse: 0.1017   \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0323 - mse: 0.0323\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0255 - mse: 0.02551\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.013634\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - mse: 0.0131  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 23/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - mse: 0.0097\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - mse: 0.0088Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0684 - mse: 0.0684\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0494 - mse: 0.0494\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101   \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 20/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0363 - mse: 0.03636\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.012214\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0125 - mse: 0.0125Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0115 - mse: 0.0115\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0102 - mse: 0.0102Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089  \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 13/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0272 - mse: 0.0272 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.0294 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - mse: 0.010083\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.0107 - mse: 0.0107\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 22/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.0251 - mse: 0.0251\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 19/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0196 - mse: 0.01961\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0309 - mse: 0.0309Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0307 - mse: 0.0307 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 20/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 16/50\n",
      "Epoch 24/50\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mse: 0.02069\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071 - mse: 0.0071 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0240 - mse: 0.0240 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 22/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.00968\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0075 - mse: 0.0075Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mse: 0.0087  \n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mse: 0.0243Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - mse: 0.02425\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - mse: 0.008049\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.01738\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.00878\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 22/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0214 - mse: 0.02149\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mse: 0.0092Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - mse: 0.0107 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065  \n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.009002\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.01906\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.0222 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mse: 0.0246\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060Epoch 42/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 35/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.00826\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101  \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.01100\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0216Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088   \n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - mse: 0.0234Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 34/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.01258\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0204 - mse: 0.0204  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - mse: 0.0224  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0087 - mse: 0.0087 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mse: 0.0099Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0088 - mse: 0.0088\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.0095 - mse: 0.0095Epoch 39/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0093 - mse: 0.0093 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0202 - mse: 0.0202\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0123 - mse: 0.0123Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.005479\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - mse: 0.0190  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mse: 0.01008\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0087 - mse: 0.0087 Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - mse: 0.007991\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0076 - mse: 0.0076 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078 135 - mse: 0.0135\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 43/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193  \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0061 - mse: 0.0061Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.01748\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0214 - mse: 0.02\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0063 - mse: 0.0063[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.028 total time=  19.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - mse: 0.0134  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.01920180\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0054 - mse: 0.0054Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 46/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0231 - mse: 0.0231Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.01786\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepstep - loss: 0.0059 - mse: 0.00\n",
      "\u001b[1m 20/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0144 - mse: 0.0144   [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.027 total time=  19.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - mse: 0.00585\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138059\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 48/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0191 - mse: 0.0191Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.013371\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.00715\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145 Epoch 47/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0118 - mse: 0.0118Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 47/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0130 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0083 - mse: 0.0083[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.018 total time=  20.4s\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mse: 0.0065Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "\u001b[1m 1/53\u001b[0m \u001b[37m���━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 39ms/stepEpoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0116 - mse: 0.011\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 48/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0117 - mse: 0.0117[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.034 total time=  20.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2695 - mse: 0.2695\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154    \n",
      "Epoch 38/50\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2192 - mse: 0.2192Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1661 - mse: 0.166163\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0097 - mse: 0.0097Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0776 - mse: 0.0776 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 470ms/step - loss: 0.7979 - mse: 0.7979Epoch 3/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0182 - mse: 0.0182\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1466 - mse: 0.1466 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.2106 - mse: 0.2106\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0600 - mse: 0.0600\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0576 - mse: 0.057665\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0351 - mse: 0.0351Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0559 - mse: 0.0559\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0611 - mse: 0.0611\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0116 - mse: 0.0109\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0398 - mse: 0.0398 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.014 total time=  24.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0384 - mse: 0.0384\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0302 - mse: 0.0302Epoch 1/50\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.041 total time=  24.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 49/50\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - mse: 0.0297Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0298 - mse: 0.0298[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.034 total time=  22.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 45/50\n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233    \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mse: 0.0252   \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1598 - mse: 0.1598 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1310 - mse: 0.1310\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0282 - mse: 0.02825\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 9/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mse: 0.02090\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0461 - mse: 0.0461 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - mse: 0.02050 �━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.017\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - mse: 0.02850\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - mse: 0.0336\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0257 - mse: 0.02575\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155   \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.0162 - mse: 0.01624\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199 \n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0338 - mse: 0.033e: 0.0197\n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5236 - mse: 1.5236 [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.060 total time=  23.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.9266 - mse: 0.9266\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 16/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0044 - mse: 0.0044Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154 \n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1112 - mse: 0.1112  \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.01573  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0760 - mse: 0.0760\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 17/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0619 - mse: 0.0619 4\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0173 - mse: 0.0173Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.01356 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0508 - mse: 0.0508\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.01502\n",
      "Epoch 6/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.01363\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.016679\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127   \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0196 - mse: 0.0196Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0140 - mse: 0.01409\n",
      "\u001b[1m 26/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.2552 - mse: 0.2552Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0193 - mse: 0.0193\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0140 - mse: 0.0140 Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0129 - mse: 0.0129\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0123 - mse: 0.0123Epoch 21/50\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1978 - mse: 0.1978Epoch 14/50\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0123 - mse: 0.0123 Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0417 - mse: 0.0417\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0168 - mse: 0.0168  \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.01286\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 22/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0623 - mse: 0.0623\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0116 - mse: 0.0116\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 23/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0340 - mse: 0.0340 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114 Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0336 - mse: 0.0336\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 26/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0105 - mse: 0.0105 \n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.0096   Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0318 - mse: 0.0318\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0336 - mse: 0.0336\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mse: 0.0295\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122 Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - mse: 0.01174\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 29/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0262 - mse: 0.0262 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 30/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0280 - mse: 0.0280  \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mse: 0.0255 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mse: 0.01276\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 30/50\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0250 - mse: 0.0250Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━��━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mse: 0.00873ms/step - loss: 0.0275 - mse: 0.027\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0168 - mse: 0.0168Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mse: 0.0095 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.01515�━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0285 - mse: 0.028\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - mse: 0.0112 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.01084\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213   \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.01100 ━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.007\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.010678\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0214 - mse: 0.0214\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mse: 0.0079Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0250 - mse: 0.0250 9\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195 - mse: 0.01951 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0104 - mse: 0.01040.0147 - mse: 0.014\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.0272 - mse: 0.02729\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0110 - mse: 0.01102\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 35/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0102 - mse: 0.0102 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0244 - mse: 0.0244\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0110 - mse: 0.0110\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0047 - mse: 0.0047Epoch 37/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0080 - mse: 0.0080\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 28/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - mse: 0.00914\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mse: 0.0095Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mse: 0.01407\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0232 - mse: 0.0232\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mse: 0.0098Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 38/50\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100 - mse: 0.0100 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - mse: 0.0100 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179 - mse: 0.0179 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - mse: 0.0094�━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.013\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0134 - mse: 0.0134 \n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - mse: 0.0246Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0089 - mse: 0.0089 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mse: 0.0088   0.0071\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 20/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 40/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - mse: 0.00808 �━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0138 - mse: 0.013\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mse: 0.0114Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.0086 - mse: 0.0086Epoch 40/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0241 - mse: 0.02410\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093  \n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━��━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078 Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - mse: 0.01734━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0172 - mse: 0.017\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - mse: 0.0074\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - mse: 0.0103Epoch 43/50\n",
      "Epoch 33/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0221 - mse: 0.0221 1 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0103 - mse: 0.0103 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - mse: 0.0176 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━��━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0091 - mse: 0.0091p - loss: 0.0091 - mse: 0.00\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 43/50\n",
      "Epoch 35/50\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0187 - mse: 0.0187Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0186 - mse: 0.0186��━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.006\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0201 - mse: 0.02016 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - mse: 0.0186 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.01127�━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - mse: 0.008\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.0073\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - mse: 0.0081Epoch 47/50\n",
      "Epoch 45/50\n",
      "Epoch 37/50\n",
      "Epoch 46/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mse: 0.0167\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0128 - mse: 0.0128[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - mse: 0.007\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mse: 0.01831 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120  mse: 0.020\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mse: 0.00844 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086 \n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mse: 0.0091Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.00921\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - mse: 0.0091 ━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - mse: 0.007\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204   \n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0077 - mse: 0.0077 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "\u001b[1m 2/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 378ms/stepEpoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━�━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0076 - mse: 0.007e: 0.0204�━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/stepp - loss: 0.0070 - mse: 0.00707\n",
      "\u001b[1m 18/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0070 - mse: 0.0070[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.014 total time=  36.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 42/50\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - mse: 0.00773 \u001b[0m 11ms/step - loss: 0.0164 - mse: 0.0164Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0078 - mse: 0.0078 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0087 - mse: 0.0087\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0071 - mse: 0.0071━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - mse: 0.0072 \n",
      "Epoch 43/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/stepep - loss: 0.0068 - mse: 0.0063 \n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - loss: 0.2312 - mse: 0.2312 [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.046 total time=  36.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/steptep - loss: 0.2666 - mse: 0.2666\n",
      "Epoch 1/50\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - mse: 0.0065[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.042 total time=  37.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 38/50\n",
      "\u001b[1m 18/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.2600 - mse: 0.2600Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/steptep - loss: 0.0148 - mse: 0.0148\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.014 total time=  36.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1991 - mse: 0.1991 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - mse: 0.0183 ━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mse: 0.0191\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062Epoch 1/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━��━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.0030 - mse: 0.0030Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0064 - mse: 0.0064498 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0581 - mse: 0.0581  \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mse: 0.0176/step - loss: 0.0064 - mse: 0.006\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mse: 0.0066\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1276 - mse: 0.1276\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1821 - mse: 0.1821\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0439 - mse: 0.0439Epoch 2/50\n",
      "Epoch 42/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mse: 0.01918\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - mse: 0.01600\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 36/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━��━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0827 - mse: 0.0827  ━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mse: 0.0392 Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0511 - mse: 0.0511  \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1076 - mse: 0.1076\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197 - mse: 0.0197━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - mse: 0.039299\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mse: 0.0412Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0518 - mse: 0.05180\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0404 - mse: 0.0404 loss: 0.0409 - mse: 0.0409\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0061 - mse: 0.00617\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - mse: 0.00767 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mse: 0.0492\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mse: 0.0338\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0148 - mse: 0.0148 m 6ms/step - loss: 0.0330 - mse: 0.033\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0326 - mse: 0.0326 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0202 - mse: 0.0202 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0339 - mse: 0.03393 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0070 - mse: 0.0070   \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0491 - mse: 0.0491\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0373 - mse: 0.0373Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0336 - mse: 0.0336\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0417 - mse: 0.0417\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 47/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━�━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0076 - mse: 0.0073�━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - mse: 0.0226 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mse: 0.03238  ━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0247 - mse: 0.024\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.0309 - mse: 0.0309\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - mse: 0.0234Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0287 - mse: 0.0280 \n",
      "\u001b[1m 18/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0182 - mse: 0.0182[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.036 total time=  39.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - mse: 0.00795\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 10/50\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0239 - mse: 0.02394\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0298 - mse: 0.0298 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174 - mse: 0.01744 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0269 - mse: 0.0269\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0271 - mse: 0.0271Epoch 49/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 376ms/step - loss: 0.0251 - mse: 0.0251[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.032 total time=  39.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mse: 0.02060 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━�━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.014�━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 13/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184 - mse: 0.0184\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1213 - mse: 0.1213 \n",
      "Epoch 2/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180 - mse: 0.0180\n",
      "\u001b[1m 23/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0255 - mse: 0.0255  Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - mse: 0.0244 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0183\u001b[0m 5ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179 - mse: 0.01798  \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - mse: 0.02469\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0155 - mse: 0.0155[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.013 total time=  41.1s\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0157 - mse: 0.0157Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0227 - mse: 0.0227\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0159 - mse: 0.0159\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0221 - mse: 0.0221\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0432 - mse: 0.0432 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1646 - mse: 0.1646\n",
      "Epoch 15/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━���━━\u001b[0m \u001b[1m49s\u001b[0m 477ms/step - loss: 1.0391 - mse: 1.0391Epoch 14/50\n",
      "Epoch 4/50\n",
      "Epoch 14/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0207 - mse: 0.0207  \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mse: 0.0235loss: 0.3485 - mse: 0.3485\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mse: 0.03621  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - mse: 0.0237\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0439 - mse: 0.0439\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2219 - mse: 0.2219Epoch 15/50\n",
      "Epoch 15/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0190 - mse: 0.0190Epoch 5/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1871 - mse: 0.18712 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mse: 0.0185\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - mse: 0.0237\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.0093 - mse: 0.0093Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0293 - mse: 0.0293\n",
      "\u001b[1m 22/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0444 - mse: 0.0444  Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0431 - mse: 0.0431\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0150 - mse: 0.0150Epoch 18/50\n",
      "Epoch 3/50\n",
      "Epoch 17/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0291 - mse: 0.0291 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0275 - mse: 0.027507m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.013\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182 - mse: 0.01826\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0313 - mse: 0.0313\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 16/50\n",
      "Epoch 4/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0144 - mse: 0.0144\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mse: 0.0184 loss: 0.0235 - mse: 0.0235\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mse: 0.0281 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/stepep - loss: 0.0233 - mse: 0.0283\n",
      "Epoch 5/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - mse: 0.0214[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.045 total time=  42.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0212 - mse: 0.02120\n",
      "Epoch 19/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.0181 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.0141 ��━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0126 - mse: 0.012\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - mse: 0.0202\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226 Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━��━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mse: 0.02335\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0224 - mse: 0.0224 ��━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0171 - mse: 0.017\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.0350 - mse: 2.0350\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0222 - mse: 0.02225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - mse: 0.0210 Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5262 - mse: 0.5262\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170 - mse: 0.01706 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 05\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0202 - mse: 0.02\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0202 - mse: 0.0202\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0214 - mse: 0.0214\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 8/50\n",
      "Epoch 12/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2836 - mse: 0.28362  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0121 - mse: 0.01215tep - loss: 0.0176 - mse: 0.01737m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.1431 - mse: 0.14\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0200 - mse: 0.0200\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0157 - mse: 0.0157 Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0157 - mse: 0.0157\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 279ms/step - loss: 0.0053 - mse: 0.0053Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1613 - mse: 0.1613  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.0193 - mse: 0.0193step - loss: 0.0142 - mse: 0.014\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.014631\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197 - mse: 0.01972\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1404 - mse: 0.1404 Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1299 - mse: 0.1299\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0188 - mse: 0.01310188\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0148 - mse: 0.01483\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.0141\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0640 - mse: 0.0640\n",
      "Epoch 23/50\n",
      "Epoch 7/50\n",
      "Epoch 15/50\n",
      "Epoch 12/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173 - mse: 0.0173 1m0s\u001b[0m 9ms/step - loss: 0.0591 - mse: 0.059\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0593 - mse: 0.0593\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mse: 0.01349\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0487 - mse: 0.0487 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 9/50\n",
      "Epoch 27/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - mse: 0.018765m 2ms/step - loss: 0.0148 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mse: 0.0170\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0139 - mse: 0.0139\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - mse: 0.0417\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.011543\n",
      "Epoch 28/50\n",
      "Epoch 28/50\n",
      "Epoch 10/50\n",
      "Epoch 28/50\n",
      "Epoch 26/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mse: 0.0142 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0412 - mse: 0.0412\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142�━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - mse: 0.009\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0107 - mse: 0.01079\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0107 - mse: 0.0104 - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0364 - mse: 0.0364\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mse: 0.01420\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178 - mse: 0.0178 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.0338 - mse: 0.0338\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 30/50\n",
      "Epoch 13/50\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0183 - mse: 0.0183Epoch 15/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0110 - mse: 0.01107\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0101 - mse: 0.0101━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.013\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m���━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mse: 0.0341Epoch 31/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0148 - mse: 0.01483 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mse: 0.0348\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.0112\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.0141\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140Epoch 18/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.01463 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0111 - mse: 0.0111 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153 - mse: 0.0153\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mse: 0.01347 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mse: 0.03513\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━���━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 16/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0157 - mse: 0.01574\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0116 - mse: 0.0116\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0299 - mse: 0.0299Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0301 - mse: 0.0301\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0125 - mse: 0.01250.0115 - mse: 0.0115\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0103 - mse: 0.01032\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0276 - mse: 0.0276  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177 - mse: 0.01779 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0124 - mse: 0.01242\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0287 - mse: 0.0287\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0100 - mse: 0.0179 00\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - mse: 0.01011\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0107 - mse: 0.0107Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0191 - mse: 0.0191\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0107 - mse: 0.0107Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0150 - mse: 0.0150━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0092 - mse: 0.00\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.01034\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 36/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mse: 0.02734263 - mse: 0.016\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.0112\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - loss: 0.0074 - mse: 0.0074Epoch 21/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.0141\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 21/50\n",
      "Epoch 34/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166 - mse: 0.01663 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - mse: 0.0091 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - mse: 0.0100━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.0099 - mse: 0.0099Epoch 35/50\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.0181 [0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.018\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0148 - mse: 0.014811\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159 - mse: 0.0159 ━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - mse: 0.011\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0152 - mse: 0.01521\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 37/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0124 - mse: 0.01247\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 24/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - mse: 0.0176 9\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mse: 0.01676\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0102 - mse: 0.0102  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[\u001b[0m 73ms/step - loss: 0.0052 - mse: 0.005e: 0.0148 0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0139 - mse: 0.0139Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mse: 0.0147\n",
      "\u001b[1m 46/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100 Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━��━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.00862105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0149 - mse: 0.0149 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.009202\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0131 - mse: 0.0131Epoch 43/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mse: 0.00859 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0280 - mse: 0.028\u001b[0m 5ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mse: 0.0277 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.0117  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.0092   \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mse: 0.02775\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163 - mse: 0.0163 \n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.0082 - mse: 0.0082Epoch 46/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - mse: 0.0087 ��━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0087 - mse: 0.008\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━���━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0152 - mse: 0.0152Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178 - mse: 0.01781 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0095 - mse: 0.0095 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mse: 0.00850\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0148 - mse: 0.0148  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172 - mse: 0.0172 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0095 - mse: 0.00956\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0244 - mse: 0.0244 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0099 - mse: 0.00997━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - mse: 0.013\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0251 - mse: 0.02517\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0110 - mse: 0.0110\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0168 - mse: 0.0168Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0090 - mse: 0.0090\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0261 - mse: 0.0261Epoch 34/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0270 - mse: 0.02707 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120�━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.006\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mse: 0.0094\n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.0261 Epoch 50/50\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0174 - mse: 0.0174Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0175 - mse: 0.0175  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - mse: 0.0264  ━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0269 - mse: 0.02\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "\u001b[1m 2/53\u001b[0m \u001b[37m━━━━━━━━━━━━━���━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 383ms/stepEpoch 33/50loss: 0.0151 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - mse: 0.0090\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 36/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step p - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0096 - mse: 0.0096[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.031 total time=  40.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0113 - mse: 0.0113 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0114 - mse: 0.0114━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 48/50\n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 178ms/step - loss: 2.3190 - mse: 2.3190[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.043 total time=  39.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 34/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0042 - mse: 0.0042Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0105 - mse: 0.0105\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0246 - mse: 0.0246  Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - mse: 0.025403\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2760 - mse: 1.2760 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/ste━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.4782 - mse: 0.4782\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/stepp - loss: 0.7650 - mse: 0.765\n",
      "Epoch 3/50\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0086 - mse: 0.0086[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.014 total time=  41.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 50/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - mse: 0.01007\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1630 - mse: 0.1637[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5962 - mse: 0.5962\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0240 - mse: 0.0240\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1774 - mse: 0.1774\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0110 - mse: 0.0110\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0270 - mse: 0.02700\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1655 - mse: 0.1655\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - mse: 0.0089 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.007202\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/steptep - loss: 0.0849 - mse: 0.08\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0006 - mse: 1.0006 Epoch 37/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0087 - mse: 0.0087Epoch 40/50\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9978 - mse: 0.9978[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.038 total time=  41.8s\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9375 - mse: 0.9375Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8882 - mse: 0.8882 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1001 - mse: 0.1001\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0883 - mse: 0.08830�━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.006\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0102 - mse: 0.01020\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - mse: 0.00674\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3149 - mse: 0.3149\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1369 - mse: 0.1369\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0601 - mse: 0.0601\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - mse: 0.0078 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0081 - mse: 0.0081 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0262 - mse: 0.0262\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0434 - mse: 0.0434\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0474 - mse: 0.0474Epoch 42/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1526 - mse: 0.1526\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.1626 - mse: 2.1626\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - mse: 0.00747\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0427 - mse: 0.04279\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - mse: 0.00999 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - mse: 0.02432\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - mse: 0.0816\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 0.0185 - mse: 0.018━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4735 - mse: 0.4735\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mse: 0.03351 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1894 - mse: 0.18941\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0322 - mse: 0.0322 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0266 - mse: 0.0266 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0527 - mse: 0.0527 \n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - mse: 0.0085Epoch 6/50\n",
      "Epoch 45/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0914 - mse: 0.091483\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mse: 0.0294\n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0408 - mse: 0.0408Epoch 47/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0271 - mse: 0.0271\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0406 - mse: 0.0406\n",
      "Epoch 46/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0066 - mse: 0.00669 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0316 - mse: 0.0316\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - mse: 0.0229\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mse: 0.0242\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068Epoch 47/50\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - mse: 0.0077Epoch 12/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0634 - mse: 0.0634\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0078 - mse: 0.0078\u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0318 - mse: 0.031\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0247 - mse: 0.0247\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - mse: 0.0306Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0250 - mse: 0.0250\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0234 - mse: 0.0234\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m 58/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mse: 0.0248Epoch 47/50\n",
      "Epoch 14/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━���━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - loss: 0.0140 - mse: 0.0140Epoch 49/50\n",
      "Epoch 45/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0259 - mse: 0.025983\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0273 - mse: 0.02730oss: 0.0083 - mse: 0.008\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mse: 0.0278 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0229 - mse: 0.0229\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.0261 Epoch 50/50\n",
      "Epoch 50/50\n",
      "Epoch 15/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - mse: 0.00771\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0257 - mse: 0.0257\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0259 - mse: 0.0259 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/stepep - loss: 0.0250 - mse: 0.0250\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 11/50\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0222 - mse: 0.0222[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.020 total time=  36.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0238 - mse: 0.0238 \n",
      "Epoch 10/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0043 - mse: 0.0043Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━�━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0403 - mse: 0.040��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0216 - mse: 0.0216\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0262 - mse: 0.0262Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 - mse: 0.0260\n",
      "\u001b[1m29/53\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  Epoch 12/500171 - mse: 0.0171\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/stepp - loss: 0.0059 - mse: 0.0059 \n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.015 total time=  43.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mse: 0.0061e: 0.026\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 15/50\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 - mse: 0.0260Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9247 - mse: 0.9247\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 13/50\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065 Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2646 - mse: 0.26444 - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184 - mse: 0.0184\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4128 - mse: 1.4128\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0073 - mse: 0.0073\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - mse: 0.0258\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2532 - mse: 0.2532Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 12/50\n",
      "Epoch 49/50\n",
      "Epoch 16/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2466 - mse: 0.2466\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.4698 - mse: 0.4698\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 13/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step: 0.0126 - mse: 0.012e: 0.1210 ━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176 - mse: 0.01763\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 50/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.031 total time=  44.6s\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0215 - mse: 0.0215 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1139 - mse: 0.1139\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0244 - mse: 0.0244\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2890 - mse: 0.2890\n",
      "Epoch 18/50\n",
      "Epoch 22/50\n",
      "Epoch 4/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0073 - mse: 0.0073\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mse: 0.0227 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0733 - mse: 0.0733 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 5/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1170 - mse: 0.1170\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 15/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/stepep - loss: 0.0234 - mse: 0.0236   \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - mse: 0.0174\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0870 - mse: 0.0870\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 6/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9865 - mse: 0.9865\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 2/50\n",
      "Epoch 17/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.035 total time=  44.0s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.3166 - mse: 0.3166Epoch 1/50\u001b[1m2s\u001b[0m 20ms/step - loss: 0.0140 - mse: 0.0140\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0217 - mse: 0.0217 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mse: 0.0363\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3025 - mse: 0.3025 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0633 - mse: 0.0633 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0222 - mse: 0.0222 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0220 - mse: 0.0220 \n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1645 - mse: 1.1645Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mse: 0.01523\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mse: 0.028437\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0188 - mse: 1.0188\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━�━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - mse: 0.02275 ��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1470 - mse: 0.1470\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mse: 0.0225 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0196 - mse: 0.0196\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0118 - mse: 0.0118Epoch 23/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0139 - mse: 0.01392\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2763 - mse: 0.2763\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0213 - mse: 0.0213Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0744 - mse: 0.0744\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0556 - mse: 0.0556\n",
      "Epoch 5/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0157 - mse: 0.015712\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1292 - mse: 0.1292\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0709 - mse: 0.0709\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0147 - mse: 0.01474\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 30/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0719 - mse: 0.0719\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0325 - mse: 0.03255  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0153\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0328 - mse: 0.0328Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0451 - mse: 0.0432m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0569 - mse: 0.0569\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0217 - mse: 0.0217\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0325 - mse: 0.0325\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0177 - mse: 0.0177Epoch 12/50\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0174 - mse: 0.0174Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0735 - mse: 0.0735 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176 - mse: 0.01766 0\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0150 - mse: 0.0150s: 0.0248 - mse: 0.024\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0207 - mse: 0.0207\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0348 - mse: 0.0348\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193 - mse: 0.0193\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 13/50\n",
      "Epoch 23/50\n",
      "Epoch 7/50\n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mse: 0.0255Epoch 33/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0256 - mse: 0.0256\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 13/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196�━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.017\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mse: 0.0225\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━���━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 10/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0134 - mse: 0.0134\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0299 - mse: 0.0299Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mse: 0.0200 �━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0253 - mse: 0.025\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0239 - mse: 0.0239Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mse: 0.0227  \n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0244 - mse: 0.0244Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - mse: 0.02379\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━��━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0200 - mse: 0.0200.0165 - mse: 0.01\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0261 - mse: 0.02615\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0137 - mse: 0.0137 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0210 - mse: 0.0210\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183 \n",
      "Epoch 10/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0207 - mse: 0.02078\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166 - mse: 0.01662━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0226 - mse: 0.0226\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 11/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 32/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 12/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 14/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - mse: 0.0228\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0161 - mse: 0.0161Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173 - mse: 0.0173   \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 34/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0159 - mse: 0.0159Epoch 30/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0239 - mse: 0.0239\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 20/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0202 - mse: 0.0202\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0197 - mse: 0.0197Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.01604  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195 - mse: 0.0195\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 41/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204   \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mse: 0.017032m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0165 - mse: 0.0165 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mse: 0.01836 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0131 - mse: 0.0131212\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 22/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0143 - mse: 0.0143 6\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0136 - mse: 0.01369\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188 - mse: 0.0188 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187 - mse: 0.0187\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - mse: 0.0207 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0143 - mse: 0.01439  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163 - mse: 0.016320 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0137 - mse: 0.0137\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0187 - mse: 0.0187Epoch 37/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0216 - mse: 0.0216  \n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 - mse: 0.0170Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0127 - mse: 0.0127260\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164 - mse: 0.01646/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - mse: 0.020\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0156 - mse: 0.0156Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.0170 - mse: 0.0170 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145260━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - mse: 0.014\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0151 - mse: 0.0151\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186 - mse: 0.0186\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169 - mse: 0.0169\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 39/50\n",
      "Epoch 22/50\n",
      "Epoch 39/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0151 - mse: 0.015152m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.02\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.0166Epoch 23/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.01293 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0165 - mse: 0.0165 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 41/50\n",
      "Epoch 41/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0219 - mse: 0.0219\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0151 - mse: 0.0151Epoch 46/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 42/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 557ms/step - loss: 0.0133 - mse: 0.0133Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0153 - mse: 0.0153   \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.015374\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137\n",
      "\u001b[1m30/53\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step Epoch 43/50.0147 - mse: 0.014\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 47/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step: 0.0229 - mse: 0.0220\n",
      "\u001b[1m 23/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0119 - mse: 0.0119   [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.032 total time=  35.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0160 - mse: 0.01602ss: 0.0120 - mse: 0.012\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0141 - mse: 0.0141Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 27/50\n",
      "Epoch 48/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 29/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173 - mse: 0.01735m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.019\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0185 - mse: 0.0185Epoch 45/50\n",
      "Epoch 30/50\n",
      "Epoch 45/50\n",
      "Epoch 28/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173 - mse: 0.01737  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.0116\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 31/50\n",
      "Epoch 46/50\n",
      "Epoch 29/50\n",
      "Epoch 50/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0130 - mse: 0.0130\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0157 - mse: 0.015744\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6217 - mse: 1.6217Epoch 30/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/steptep - loss: 1.4693 - mse: 1.4600\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 1.4477 - mse: 1.4477\n",
      "Epoch 2/50\n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114 [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.052 total time=  37.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━�m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0110�━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - loss: 0.5201 - mse: 0.5201Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184 - mse: 0.0184\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 1/50\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118Epoch 33/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3546 - mse: 0.3546\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.01122  ��━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0154 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 38/50\n",
      "Epoch 32/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1739 - mse: 0.17397 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3937 - mse: 1.39372[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.014\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144Epoch 2/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1190 - mse: 0.119003\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103 ��━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.0142 - mse: 0.0142 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.1010 - mse: 0.1010\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3223 - mse: 0.3223\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━���━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 537ms/step - loss: 0.0118 - mse: 0.0118Epoch 3/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0110 - mse: 0.0110  mse: 0.014\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0691 - mse: 0.0691Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step0.0085 - mse: 0.0056\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0685 - mse: 0.0685\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1397 - mse: 0.1397\n",
      "Epoch 41/50\n",
      "Epoch 7/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0151 - mse: 0.0151Epoch 4/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 541ms/step - loss: 0.0135 - mse: 0.0135[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.021 total time=  38.9s\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.017 total time=  40.1s\n",
      "\u001b[1m 17/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0726 - mse: 0.0726 Epoch 1/50\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0144 - mse: 0.0144 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0590 - mse: 0.05906\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0820 - mse: 0.0820\n",
      "Epoch 5/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0557 - mse: 0.0557\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0539 - mse: 0.0539\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101Epoch 6/50\n",
      "Epoch 9/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.01201\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.5963 - mse: 1.59637━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6937 - mse: 1.6937\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0494 - mse: 0.0494Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.8749 - mse: 0.8749\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0489 - mse: 0.0489 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.0132 - mse: 0.0132Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4195 - mse: 0.41951\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2383 - mse: 0.2383 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0483 - mse: 0.048\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0480 - mse: 0.0480\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110143\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0388 - mse: 0.0388Epoch 39/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 536ms/step - loss: 0.0539 - mse: 0.0539Epoch 11/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - mse: 0.0100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1428 - mse: 0.1428\n",
      "Epoch 41/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1078 - mse: 0.1078\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0144 - mse: 0.0144\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mse: 0.0356 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 46/50\n",
      "Epoch 46/50\n",
      "Epoch 4/50\n",
      "Epoch 9/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0440 - mse: 0.04404\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0994 - mse: 0.0994 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162\u001b[0m 2ms/step - loss: 0.0690 - mse: 0.069\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 47/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.0679 - mse: 0.0679\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0465 - mse: 0.0465\n",
      "Epoch 41/50\n",
      "Epoch 13/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0679 - mse: 0.0679\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 10/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0143 - mse: 0.014317\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 48/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0589 - mse: 0.05890\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mse: 0.0597\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0465 - mse: 0.04650.0285 - mse: 0.028\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0433 - mse: 0.0433\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125Epoch 8/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0523 - mse: 0.0523 : 0.0293 - mse: 0.0293\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 12/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0099 - mse: 0.00998\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0407 - mse: 0.0407 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0145 - mse: 0.0145 \n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0127 - mse: 0.0127Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0494 - mse: 0.0494 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0448 - mse: 0.0448 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0302 - mse: 0.0302 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0165 - mse: 0.0165 \n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mse: 0.0099 Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - mse: 0.01013 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0308 - mse: 0.0308\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0118 - mse: 0.0118\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0449 - mse: 0.0449\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 14/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 17/50\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136Epoch 45/50\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106 Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━�━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mse: 0.0333 �━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0406 - mse: 0.0406\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0351 - mse: 0.03\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 18/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0317 - mse: 0.0317[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.130 total time=  40.1s\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.023 total time=  39.5s\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mse: 0.0353Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mse: 0.03907\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0370 - mse: 0.0370 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7888 - mse: 1.7888\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2073 - mse: 1.2073\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0357 - mse: 0.0357 ━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.2723 - mse: 0.2723\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0375 - mse: 0.0375\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0094 - mse: 0.0094\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0375 - mse: 0.0375\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mse: 0.03813\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3801 - mse: 0.3801 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2130 - mse: 0.2130 .213\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0354 - mse: 0.0354 \n",
      "Epoch 21/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━�━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/steep - loss: 0.1097 - mse: 0.109��━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0326 - mse: 0.0326\n",
      "Epoch 15/50\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.027 total time=  39.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━���━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1039 - mse: 0.1039\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 0.0347 - mse: 0.0347Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1412 - mse: 0.1412\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.011571\n",
      "Epoch 4/50\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0344 - mse: 0.0344 Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mse: 0.03630 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mse: 0.03475\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3544 - mse: 1.3544 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0653 - mse: 0.0653\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0401 - mse: 0.0401Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0368 - mse: 0.0368\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mse: 0.0801Epoch 48/50\n",
      "Epoch 5/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0790 - mse: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125  loss: 0.0617 - mse: 0.06\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3201 - mse: 0.3201\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0264 - mse: 0.0264\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0359 - mse: 0.03590413 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 152ms/step - loss: 0.0757 - mse: 0.0757Epoch 23/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0557 - mse: 0.0557 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0575 - mse: 0.0575\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0296 - mse: 0.02964 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121   \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1737 - mse: 0.1737\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0271 - mse: 0.0271\n",
      "\u001b[1m  3/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0374 - mse: 0.0374Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0287 - mse: 0.0287\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0332 - mse: 0.03329  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0393 - mse: 0.0393\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0110 - mse: 0.0110 p - loss: 0.0249 - mse: 0.0249\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0321 - mse: 0.0321 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0254 - mse: 0.0254 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1126 - mse: 0.1126 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step 0.0411 - mse: 0.041e: 0.0414 \n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.0300 - mse: 0.0300 Epoch 5/50\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0300 - mse: 0.0300  [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.307 total time=  41.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0299 - mse: 0.02998 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mse: 0.03690\n",
      "Epoch 8/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0212 - mse: 0.0212Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0321 - mse: 0.0321 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0362 - mse: 0.0362\n",
      "Epoch 26/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0710 - mse: 0.0710\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0283 - mse: 0.0283 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0286 - mse: 0.0286\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0345 - mse: 0.0345  Epoch 20/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - loss: 1.2674 - mse: 1.2674Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mse: 0.034910\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - loss: 0.0380 - mse: 0.0380Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0310 - mse: 0.0310�━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0390 - mse: 0.0\n",
      "\u001b[1m 12/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - loss: 0.0210 - mse: 0.0210Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0374 - mse: 0.037476ms/step - loss: 0.0331 - mse: 0.03\n",
      "\u001b[1m 13/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.0349 - mse: 0.0349Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.7434 - mse: 0.7434  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0300 - mse: 0.0300\n",
      "\u001b[1m 15/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0390 - mse: 0.0390Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0321 - mse: 0.0321 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1829 - mse: 0.1829 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━��━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - loss: 0.0177 - mse: 0.0177Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0328 - mse: 0.0328 \n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0302 - mse: 0.0302Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0259━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0343 - mse: 0.03\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0285 - mse: 0.0285\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0293 - mse: 0.0293Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0305 - mse: 0.0305  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0309 - mse: 0.0309\n",
      "\u001b[1m 26/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0364 - mse: 0.0364 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0861 - mse: 0.0861\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0360 - mse: 0.0360  ━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0367 - mse: 0.03\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mse: 0.03479\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0237 - mse: 0.0237 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0271 - mse: 0.0271\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0602 - mse: 0.0602 \n",
      "Epoch 25/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0349 - mse: 0.0349\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0281 - mse: 0.0281\n",
      "\u001b[1m 31/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━��━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0653 - mse: 0.0653 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mse: 0.0357 ��━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - mse: 0.0248 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mse: 0.0335\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0499 - mse: 0.0499\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.0296 - mse: 0.0296Epoch 26/50\n",
      "Epoch 6/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mse: 0.0294  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0318 - mse: 0.03186  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0306 - mse: 0.0306 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mse: 0.0331 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0295 - mse: 0.02958\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0243 - mse: 0.0243\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 25/50\n",
      "Epoch 14/50\n",
      "Epoch 27/50\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0266 - mse: 0.0266 Epoch 11/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mse: 0.0284  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0315 - mse: 0.0315 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0318 - mse: 0.03182\u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mse: 0.032\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mse: 0.0233\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0338 - mse: 0.0338 Epoch 26/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0238 - mse: 0.0238\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 15/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.0269 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mse: 0.0322 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0224 - mse: 0.02243\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0303 - mse: 0.0303m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0316 - mse: 0.0316\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mse: 0.0295\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 35/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - mse: 0.02377\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0210 - mse: 0.02106\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0311 - mse: 0.0311 .024\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0234 - mse: 0.0234\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.0270\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206Epoch 30/50\n",
      "Epoch 36/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 29/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0220 - mse: 0.02208\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0277 - mse: 0.0277[0m 2ms/step - loss: 0.0205 - mse: 0.020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mse: 0.0337\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 19/50\n",
      "Epoch 37/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.02050  �\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254 - mse: 0.025\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mse: 0.0266\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - mse: 0.0232\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 12/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 16/50\n",
      "Epoch 21/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 21/50\n",
      "Epoch 33/50\n",
      "Epoch 22/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━��━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0310 - mse: 0.031044\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0290 - mse: 0.0290Epoch 40/50\n",
      "Epoch 14/50\n",
      "Epoch 34/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0226 - mse: 0.0226 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0238 - mse: 0.0238\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mse: 0.0311\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 15/50\n",
      "Epoch 35/50\n",
      "Epoch 24/50\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0315 - mse: 0.0315Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.032042\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0249 - mse: 0.0249\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 35/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 19/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 16/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mse: 0.0296Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0243 - mse: 0.0243 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0269 - mse: 0.0269\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.0181 - mse: 0.0181Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0301 - mse: 0.0301\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 20/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0227 - mse: 0.0227\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - mse: 0.0188 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 0.0332 - mse: 0.0332\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mse: 0.0243Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 38/50\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0294 - mse: 0.0294Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0339 - mse: 0.0339 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0292 - mse: 0.0292 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0238 - mse: 0.0238 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215 - mse: 0.0215 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0212 - mse: 0.0212 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183 - mse: 0.01837\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mse: 0.0284 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0306 - mse: 0.0306 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0291 - mse: 0.0291\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0325 - mse: 0.0325Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mse: 0.019633\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0308 - mse: 0.0308\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - mse: 0.0235\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m���━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0113 - mse: 0.0113Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - mse: 0.0276\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - loss: 0.0231 - mse: 0.023171\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 33/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.014 total time=  44.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0217 - mse: 0.02173\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - mse: 0.02151\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 46/50\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0213 - mse: 0.02130190\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 - mse: 0.01924\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181 9 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.0223 - mse: 0.0223Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - mse: 0.0284\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.021484\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0186 - mse: 0.0186\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0220 - mse: 0.0220Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0219 - mse: 0.0219\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 - mse: 0.0284   \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.0218 - mse: 0.0218\n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9944 - mse: 0.9944Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6670 - mse: 0.6670\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 31/50\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.039 total time=  42.5s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0225 - mse: 0.02\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 41/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0166 - mse: 0.0166[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.033 total time=  39.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1467 - mse: 0.1467\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 1/50\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.01286\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0733 - mse: 0.0733\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mse: 0.0219 8ms/step - loss: 0.0235 - mse: 0.023\n",
      "Epoch 35/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/stepp - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m 26/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - mse: 0.0456 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.013 total time=  40.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0208 - mse: 0.0208 \n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0471 - mse: 0.0471Epoch 43/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0077 - mse: 0.0077Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118   \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0189 - mse: 0.0189 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.01612\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6198 - mse: 1.6198\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.5744 - mse: 1.5744\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.01766\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0291 - mse: 0.0291  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4026 - mse: 0.4026\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3399 - mse: 0.3399\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1644 - mse: 0.1644\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6271 - mse: 0.6271\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1438 - mse: 0.1438\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.01874\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0888 - mse: 0.0888\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.1576 - mse: 0.1576\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1128 - mse: 0.1128\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - mse: 0.0187  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 50/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0921 - mse: 0.0921\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0593 - mse: 0.0593\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0932 - mse: 0.0932\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.01977\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.01520\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0193 - mse: 0.0193 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.012281\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0768 - mse: 0.0768 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.01802\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0678 - mse: 0.0678\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0957 - mse: 0.0903\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step 0.0746 - mse: 0.07\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0225 - mse: 0.0225\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115Epoch 14/50\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0115 - mse: 0.0115[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.031 total time=  37.9s\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.035 total time=  37.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 7/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 406ms/step - loss: 0.0179 - mse: 0.0179Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 133ms/step - loss: 0.0634 - mse: 0.0634\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 133ms/step - loss: 0.0618 - mse: 0.0618\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 78ms/step - loss: 0.0113 - mse: 0.011335\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 134ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - loss: 0.0442 - mse: 0.04420 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.7023 - mse: 1.7023\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 0.8805 - mse: 0.8805\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0629 - mse: 0.0629\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573 - mse: 0.05732\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0426 - mse: 0.0426Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mse: 0.0409 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2227 - mse: 0.2227\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2322 - mse: 0.2322\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mse: 0.0542 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0220 - mse: 0.0220 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0183 - mse: 0.01830\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0598 - mse: 0.0598\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0893 - mse: 0.089399\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1228 - mse: 0.1228\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mse: 0.052469\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0605 - mse: 0.0605 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0926 - mse: 0.0926\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0589 - mse: 0.0589�━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - mse: 0.035\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - mse: 0.0166\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0803 - mse: 0.0803   Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0769 - mse: 0.0769 \n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0481 - mse: 0.0481Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0461 - mse: 0.04611\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0470 - mse: 0.0470\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0273 - mse: 0.0273Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0426 - mse: 0.0426  \n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mse: 0.0463Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0668 - mse: 0.0668  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mse: 0.0456\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0514 - mse: 0.0514\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 15/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 22/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0375 - mse: 0.0375\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mse: 0.03435\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mse: 0.0398\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.01077\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0472 - mse: 0.0472\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0500 - mse: 0.050099 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0397 - mse: 0.0397\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 15/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0484 - mse: 0.0484\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mse: 0.0348\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0550 - mse: 0.0550\n",
      "\u001b[1m 15/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0477 - mse: 0.0477 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.047 total time=  43.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 10/50\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0478 - mse: 0.0478Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepep - loss: 0.0426 - mse: 0.046554\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━��━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0423 - mse: 0.0423[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.018 total time=  47.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0480 - mse: 0.0480\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0504 - mse: 0.0504 Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 16/50\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0397 - mse: 0.0397Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0303 - mse: 0.0303  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0497 - mse: 0.0497\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - loss: 0.0187 - mse: 0.01873\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - loss: 0.0343 - mse: 0.03434\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - loss: 0.0459 - mse: 0.0459 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - loss: 0.0439 - mse: 0.0439 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0418 - mse: 0.0418Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - loss: 0.0312 - mse: 0.0312 56\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0457 - mse: 0.0457 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.8818 - mse: 0.8818 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 1.8188 - mse: 1.8188 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178 - mse: 0.01783\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mse: 0.0397 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0430 - mse: 0.0430 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0681 - mse: 0.0681Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0283 - mse: 0.0283\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 13/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1650 - mse: 0.1650\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1793 - mse: 0.1793\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0419 - mse: 0.0419\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0488 - mse: 0.0488\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0968 - mse: 0.0968Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0882 - mse: 0.0882\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0952 - mse: 0.0952\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0282 - mse: 0.02823\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 15/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0621 - mse: 0.0621 6\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0347 - mse: 0.034747\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0491 - mse: 0.0491 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0305 - mse: 0.0305�━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - mse: 0.030\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0423 - mse: 0.04236\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0161 - mse: 0.01613\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0570 - mse: 0.0570\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0474 - mse: 0.04743\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0359 - mse: 0.0359Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0736 - mse: 0.0736\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0263 - mse: 0.0263 Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0446 - mse: 0.044684 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0385 - mse: 0.0385\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0618 - mse: 0.0618\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0280 - mse: 0.0280  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0476 - mse: 0.0476\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mse: 0.0362\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.0396 - mse: 0.0396\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0385 - mse: 0.03858\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - mse: 0.0482\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 0.0153 - mse: 0.0153 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mse: 0.0413\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.032066\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mse: 0.0409\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.01679 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0487 - mse: 0.048711\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mse: 0.0348Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mse: 0.0339\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.0270Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0293 - mse: 0.0293  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0367 - mse: 0.0367\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0513 - mse: 0.0513Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0380 - mse: 0.0380\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0362 - mse: 0.0362\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mse: 0.0281  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0435 - mse: 0.0435 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mse: 0.0235\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mse: 0.0358Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0290 - mse: 0.0290  ��━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0155 - mse: 0.015\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - mse: 0.02379\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0450 - mse: 0.0450Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - mse: 0.038292\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - mse: 0.0360\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - mse: 0.02894\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0353 - mse: 0.0353\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.0230   \n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0411 - mse: 0.0411Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0413 - mse: 0.0413\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0292 - mse: 0.0292\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0279 - mse: 0.0279Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0391 - mse: 0.0391\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 35/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0343 - mse: 0.0343   \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0221 - mse: 0.0221  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0419 - mse: 0.0419\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mse: 0.037401\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0383 - mse: 0.0383\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0230 - mse: 0.0230\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0438 - mse: 0.0438  Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.0337 - mse: 0.0337\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0263 - mse: 0.0263Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0159 - mse: 0.0159Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - mse: 0.0300   \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mse: 0.0385\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - mse: 0.027445   \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0326 - mse: 0.0326\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0375 - mse: 0.0375\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0373 - mse: 0.0373\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0304 - mse: 0.0304\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0273 - mse: 0.0273\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 40/50\n",
      "Epoch 34/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0399 - mse: 0.0399\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0280 - mse: 0.0280\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mse: 0.0463\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 41/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.0261 - mse: 0.0261\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 0.0177 - mse: 0.0177Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mse: 0.026328 \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.0222 - mse: 0.0222 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mse: 0.0380\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.0297 - mse: 0.0297 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0152 - mse: 0.0152Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mse: 0.02499\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0363 - mse: 0.0363\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 37/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0404 - mse: 0.040479\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0263 - mse: 0.0263\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 43/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0434 - mse: 0.0434 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mse: 0.0341\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0293 - mse: 0.0293\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 45/50\n",
      "Epoch 28/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0420 - mse: 0.042012\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.0320━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.032\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0291 - mse: 0.0291\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mse: 0.0248 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mse: 0.03501  - mse: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/steptep - loss: 0.0228 - mse: 0.02\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0415 - mse: 0.0415\n",
      "Epoch 47/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.033 total time=  54.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 40/50\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mse: 0.0331Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.0335 \u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0341 - mse: 0.0341\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 48/50\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━��━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 42/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mse: 0.0331 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0165 - mse: 0.0165Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0267 - mse: 0.0267Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0267 - mse: 0.02676\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mse: 0.0403\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mse: 0.03226\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/stepep - loss: 0.0188 - mse: 0.018\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0260 - mse: 0.0260\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 35/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.021 total time=  54.7s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/stepp - loss: 0.0357 - mse: 0.03573\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.038 total time=  53.8s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - loss: 0.0141 - mse: 0.0141Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0193 - mse: 0.0193\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0358 - mse: 0.0358Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9011 - mse: 0.9011 \n",
      "Epoch 2/50\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0256 - mse: 0.0256Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0157 - mse: 0.0157[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.055 total time=  55.0s\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0210 - mse: 0.0210 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - loss: 0.1236 - mse: 0.123620\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0322 - mse: 0.0322 3\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0291 - mse: 0.0291\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4394 - mse: 1.4394\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.5163 - mse: 1.5163\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0640 - mse: 0.0640 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 1.4846 - mse: 1.4846\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.0195 - mse: 0.0195Epoch 35/50\n",
      "Epoch 2/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0306 - mse: 0.0306\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0272 - mse: 0.0272Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.3076 - mse: 0.3076\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.1290 - mse: 0.1290\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0513 - mse: 0.0513\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 5/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.1586 - mse: 0.1586\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0160 - mse: 0.0160Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0814 - mse: 0.0814\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0311 - mse: 0.0311\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1082 - mse: 0.1082\n",
      "Epoch 37/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1098 - mse: 0.10987\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0369 - mse: 0.0369\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0271 - mse: 0.02715\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0468 - mse: 0.0468 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0670 - mse: 0.0670\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0913 - mse: 0.0913\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - mse: 0.02777\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 42/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0290 - mse: 0.0290[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.019 total time=  59.9s\n",
      "\u001b[1m38/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step Epoch 1/500.0284 - mse: 0.0284 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0853 - mse: 0.084\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mse: 0.0280[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.051 total time= 1.0min\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mse: 0.0280Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0537 - mse: 0.0537\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0862 - mse: 0.0862\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mse: 0.0384 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mse: 0.0801\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0278 - mse: 0.0278 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0739 - mse: 0.07393  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0328 - mse: 0.0328   \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mse: 0.0225\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0716 - mse: 0.0716Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - mse: 0.02121  \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0713 - mse: 0.0713\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - mse: 0.03525\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.3954 - mse: 2.3954\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - mse: 0.02700\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9794 - mse: 0.97942\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 2/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0417 - mse: 0.0417\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0689 - mse: 0.0689 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3907 - mse: 0.3907\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0465 - mse: 0.0465\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0683 - mse: 0.0683\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2370 - mse: 0.23709\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1160 - mse: 0.1160\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0294 - mse: 0.0294.029\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0406 - mse: 0.0406 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0654 - mse: 0.0654 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0220 - mse: 0.0220\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0998 - mse: 0.0998Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1285 - mse: 0.12850\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0923 - mse: 0.0923\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0687 - mse: 0.0687Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mse: 0.0243   \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0433 - mse: 0.0433\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0837 - mse: 0.0837 Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0212 - mse: 0.0212 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0787 - mse: 0.0787\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0880 - mse: 0.0880\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0398 - mse: 0.0398\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0633 - mse: 0.0633\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0263 - mse: 0.0263\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0399 - mse: 0.0399  \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0712 - mse: 0.0712\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━��━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0571 - mse: 0.0571\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0758 - mse: 0.0758\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0432 - mse: 0.043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0282 - mse: 0.028222\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 16/50\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0768 - mse: 0.0768[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.042 total time=  52.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0758 - mse: 0.0758\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0651 - mse: 0.0651\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657 - mse: 0.065786\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0255 - mse: 0.0255\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0191 - mse: 0.0191Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0635 - mse: 0.0635\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0360 - mse: 0.0360 \n",
      "Epoch 16/50\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0200 - mse: 0.0200   Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0606 - mse: 0.0606\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 18/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0621 - mse: 0.0621\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mse: 0.0630\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0585 - mse: 0.058563\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0364 - mse: 0.0364\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.0172 Epoch 17/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.0261  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0591 - mse: 0.0591\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0585 - mse: 0.0585\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0374 - mse: 0.0374\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.0236 0\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0630 - mse: 0.0630\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0581 - mse: 0.0581 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0595 - mse: 0.0595 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 9/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0563 - mse: 0.0563\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0563 - mse: 0.0563\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 20/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0692 - mse: 0.0696\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0548 - mse: 0.0548\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0546 - mse: 0.0546\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 885ms/step - loss: 0.7354 - mse: 0.7354[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.017 total time=  53.3s\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0175 - mse: 0.01755184\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0570 - mse: 0.0570\n",
      "Epoch 22/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - loss: 0.5338 - mse: 0.53382\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0216 - mse: 0.0216\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0564 - mse: 0.0564 Epoch 21/50\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0533 - mse: 0.0533Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0547 - mse: 0.0547\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0536 - mse: 0.0536\n",
      "Epoch 11/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0567 - mse: 0.0567\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.0176 - mse: 0.0176Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1377 - mse: 0.1377\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.6478 - mse: 0.6478\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0528 - mse: 0.05288\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0564 - mse: 0.0564\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0786 - mse: 0.0786\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 26/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1531 - mse: 0.1531\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 0.0802 - mse: 0.0802\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0541 - mse: 0.0541\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0156 - mse: 0.0156\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0540 - mse: 0.0540\n",
      "Epoch 27/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0468 - mse: 0.0468  \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0671 - mse: 0.0671\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0501 - mse: 0.0501 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0477 - mse: 0.0477\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0572 - mse: 0.0572\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0570 - mse: 0.05702\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0534 - mse: 0.0534\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0546 - mse: 0.0546 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0563 - mse: 0.0563\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0507 - mse: 0.0507\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0349 - mse: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0536 - mse: 0.0536\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0471 - mse: 0.0471\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0578 - mse: 0.0578\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - mse: 0.018638\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 31/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0419 - mse: 0.0419 Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0417 - mse: 0.04178\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0563 - mse: 0.0563\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - mse: 0.0482Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mse: 0.0415   \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0467 - mse: 0.0467 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0484 - mse: 0.0484   \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 627us/step - loss: 0.0373 - mse: 0.0373\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.015048\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0489 - mse: 0.0489\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0441 - mse: 0.0441 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0365 - mse: 0.0365  \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0596 - mse: 0.0596 Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mse: 0.0567 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0398 - mse: 0.03982\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0482 - mse: 0.0482\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mse: 0.01770\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0326 - mse: 0.03268  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0447 - mse: 0.0447\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0391 - mse: 0.0391 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0296 - mse: 0.0296  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0446 - mse: 0.0446\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0346 - mse: 0.0346  \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0193 - mse: 0.0193Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0488 - mse: 0.0488\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mse: 0.037131\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0529 - mse: 0.0529\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mse: 0.0412\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0394 - mse: 0.03943\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0390 - mse: 0.0390\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - mse: 0.0284\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0347 - mse: 0.0347Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153   \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0148 - mse: 0.0148   \n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0286 - mse: 0.0286 Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0531 - mse: 0.0531 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 377ms/step - loss: 0.0507 - mse: 0.0507Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mse: 0.0409   \n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0466 - mse: 0.0466 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0361 - mse: 0.0361  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0360 - mse: 0.0360\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0456 - mse: 0.0456\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mse: 0.0343\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 20/50\n",
      "Epoch 35/50\n",
      "Epoch 30/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0423 - mse: 0.04232\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0387 - mse: 0.0387Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0522 - mse: 0.0522\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - loss: 0.0501 - mse: 0.0501\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 149ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - loss: 0.0467 - mse: 0.0467\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 149ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - loss: 0.0372 - mse: 0.0372\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 21/50\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 149ms/step - loss: 0.0134 - mse: 0.0134\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0276 - mse: 0.0276Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0402 - mse: 0.0402\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0517 - mse: 0.0517\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 44/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0362 - mse: 0.0362\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0477 - mse: 0.0477\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 34/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0368 - mse: 0.0368  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0490 - mse: 0.0490\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0278 - mse: 0.0278  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0489 - mse: 0.0489\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0457 - mse: 0.0457  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0409 - mse: 0.0409\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0352 - mse: 0.0352\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0506 - mse: 0.0506 Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0386 - mse: 0.0386 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0475 - mse: 0.047519\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - mse: 0.0374\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.023673 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 29/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepep - loss: 0.0375 - mse: 0.0371\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 97ms/step - loss: 0.0400 - mse: 0.0400[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.025 total time=  54.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0374 - mse: 0.0374 \n",
      "Epoch 41/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0310 - mse: 0.0310Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - mse: 0.0369\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 43/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0273 - mse: 0.027\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.046 total time=  55.0s\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mse: 0.0259Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0256 - mse: 0.0256\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - mse: 0.0319Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mse: 0.0371 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - mse: 0.0207 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mse: 0.0296   \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8648 - mse: 0.8648\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0349 - mse: 0.0349 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.0230 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1743 - mse: 0.1743\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0235 - mse: 0.02351 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0364 - mse: 0.0364\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mse: 0.033282\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6383 - mse: 0.6383\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0993 - mse: 0.0993\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0318 - mse: 0.0318 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1186 - mse: 0.1186 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0667 - mse: 0.0667   \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━�0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0440 - mse: 0.0440��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0845 - mse: 0.0845\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0322 - mse: 0.0322\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0645 - mse: 0.064588\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.022 total time=  43.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0221 - mse: 0.0221 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━���━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 40/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0644 - mse: 0.0644\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0352 - mse: 0.0352\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0957 - mse: 0.0957Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0240 - mse: 0.0240  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0544 - mse: 0.0544\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.0492 - mse: 0.0492\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0356 - mse: 0.0356Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0298 - mse: 0.0298 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.0294    \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5830 - mse: 0.58303\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0291 - mse: 0.0291  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mse: 0.0233  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0424 - mse: 0.0424\n",
      "Epoch 50/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 943us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774us/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0380 - mse: 0.0380\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1242 - mse: 0.12420\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.02217\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - mse: 0.026139\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0398 - mse: 0.0399 \n",
      "\u001b[1m 62/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mse: 0.0353[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.072 total time=  41.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0397 - mse: 0.0397  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0745 - mse: 0.0745\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0362 - mse: 0.0362\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0393 - mse: 0.0393\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0617 - mse: 0.0617Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0610 - mse: 0.0610\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mse: 0.0243 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mse: 0.0311\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mse: 0.0324 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0494 - mse: 0.0494\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.01381\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0443 - mse: 0.0443 \n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mse: 0.0361Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0362 - mse: 0.036241\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 37/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step 0.0322 - mse: 0.03 mse: 0.0242 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0459 - mse: 0.0459[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.058 total time=  41.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0420 - mse: 0.042043\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - mse: 0.0350 \n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0234 - mse: 0.0234 Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.0428 - mse: 0.0428\n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.0120 - mse: 0.0120Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0233 - mse: 0.023319\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 19/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mse: 0.0338\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.013030\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - mse: 0.0374\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0454 - mse: 0.0454 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0342 - mse: 0.0342\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0342 - mse: 0.03422\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0355 - mse: 0.0355[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.052 total time= 1.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0342 - mse: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0414 - mse: 0.0414\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0353 - mse: 0.0353\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0404 - mse: 0.0404\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0301 - mse: 0.0301\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0396 - mse: 0.0396\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0336 - mse: 0.0336\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 27/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step 0.0560 - mse: 0.056\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0318 - mse: 0.0318[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.037 total time=  56.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0318 - mse: 0.0318  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0287 - mse: 0.0287\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.0309 - mse: 0.0309\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.0300 - mse: 0.0300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.0280 - mse: 0.0280\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 0.0281 - mse: 0.0281Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0284 - mse: 0.0284\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 32/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step 0.0264 - mse: 0.0260\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.075 total time= 1.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0258 - mse: 0.02587\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "1 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node AssignVariableOp_1 defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/joblib/parallel.py\", line 598, in __call__\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 61, in train_step\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/metrics/reduction_metrics.py\", line 150, in update_state\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/common/variables.py\", line 242, in assign_add\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/common/variables.py\", line 238, in assign\n",
      "\n",
      "  File \"/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 63, in _direct_assign\n",
      "\n",
      "Trying to assign to variable with tensor with wrong shape. Expected [] got [0]\n",
      "\t [[{{node AssignVariableOp_1}}]] [Op:__inference_one_step_on_iterator_119095]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [-0.18891503 -0.06088803 -0.11923103         nan -0.0515611  -0.037593\n",
      " -0.05441226 -0.06132182 -0.04144293 -0.0378949  -0.04801496 -0.0425648\n",
      " -0.2073712  -0.19503014 -0.27032308 -0.03383949 -0.02384909 -0.03112803\n",
      " -0.03624016 -0.03397024 -0.02747772 -0.02972836 -0.03171812 -0.02703263\n",
      " -0.0347443  -0.05600788 -0.11899509 -0.02885018 -0.02635018 -0.03244911\n",
      " -0.03808723 -0.03739389 -0.03831955 -0.04583601 -0.05056926 -0.04867342]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.2306 - mse: 0.2306\n",
      "Epoch 2/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 0.0588 - mse: 0.0588\n",
      "Epoch 3/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 4/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 5/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 6/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 7/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 8/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 9/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 10/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 11/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 12/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 13/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 14/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 15/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 16/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146 \n",
      "Epoch 17/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 18/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 19/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 20/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 21/50\n",
      "\u001b[1m103/158\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.0129 - mse: 0.0129Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0245 - mse: 0.02457\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0238 - mse: 0.0238\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 22/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 23/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 24/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 25/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 26/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 27/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 28/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 29/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 30/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 31/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 32/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 33/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 34/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 35/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 36/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 37/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106  \n",
      "Epoch 38/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 39/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 40/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 41/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 42/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 43/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 44/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 45/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 46/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 47/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 48/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 49/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 50/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - loss: 0.0097 - mse: 0.0097\n",
      "Best Parameters: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.2, 'model__layers': 2, 'model__neurons': 32}\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "In-sample R²: 0.8899\n",
      "In-sample RMSE: 0.0858\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213us/step\n",
      "Out-of-sample R²: 0.4619\n",
      "Out-of-sample RMSE: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "och 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 29/50\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - los- mse: 0.01"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Set the seed before training\n",
    "set_seed(42)\n",
    "\n",
    "# Define the model function with variable neurons, layers, and dropout rate\n",
    "def create_model(input_dim, neurons=32, layers=1, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    # Input layer using Input instead of input_dim argument\n",
    "    model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Wrapping the model in KerasRegressor\n",
    "def create_keras_regressor(input_dim):\n",
    "    return KerasRegressor(model=create_model, input_dim=input_dim, verbose=1)  # Set verbose=1 for model fit\n",
    "\n",
    "# Define the parameter grid for trials\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64],    # Number of neurons in each hidden layer\n",
    "    'model__layers': [1,2,3,4],        # Number of hidden layers\n",
    "    'model__dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "    'batch_size': [32],                   # Batch size for training\n",
    "    'epochs': [50],                       # Number of epochs\n",
    "}\n",
    "\n",
    "# param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.5], 'model__layers': [1], 'model__neurons': [16]} # Put\n",
    "# param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [64]} # Call\n",
    "# Function to perform hyperparameter tuning, retrain the model, and test\n",
    "def train_and_evaluate(combined_x, combined_y, test_x, test_y):\n",
    "    # Get input dimension from the training data\n",
    "    input_dim = combined_x.shape[1]\n",
    "    \n",
    "    # Create KerasRegressor with the correct input dimension\n",
    "    model = create_keras_regressor(input_dim)\n",
    "\n",
    "    # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "                               verbose=3,\n",
    "                               cv=3, \n",
    "                               n_jobs=-1)  # Verbose=3 for detailed progress tracking\n",
    "\n",
    "    # Hyperparameter tuning using validation data\n",
    "    print(\"Running hyperparameter tuning with validation data...\")\n",
    "    grid_search.fit(combined_x, combined_y,\n",
    "                    verbose=1)\n",
    "\n",
    "    # Get the best estimator and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    # In-sample evaluation on the combined training and validation set\n",
    "    predictions_combined = best_model.predict(combined_x)\n",
    "\n",
    "    r2_combined = r2_score(combined_y, predictions_combined)\n",
    "    rmse_combined = np.sqrt(mean_squared_error(combined_y, predictions_combined))\n",
    "    \n",
    "    print(f\"In-sample R²: {r2_combined:.4f}\")\n",
    "    print(f\"In-sample RMSE: {rmse_combined:.4f}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions_test = best_model.predict(test_x)\n",
    "\n",
    "    # Out-of-sample evaluation on the test set\n",
    "    r2_test = r2_score(test_y, predictions_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_y, predictions_test))\n",
    "\n",
    "    print(f\"Out-of-sample R²: {r2_test:.4f}\")\n",
    "    print(f\"Out-of-sample RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Call the function for Call options data\n",
    "print(\"\\nEvaluating Call options...\")\n",
    "# best_model_call = train_and_evaluate(train_x_c, train_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c)\n",
    "\n",
    "# # Call the function for Put options data\n",
    "# print(\"\\nEvaluating Put options...\")\n",
    "best_model_put = train_and_evaluate(combined_x_p, combined_y_p, test_x_p, test_y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x317c19260&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=48\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x317c19260&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=48\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=<function create_model at 0x317c19260>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=48\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Call options...\n",
      "Running hyperparameter tuning with validation data...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - loss: 0.5099 - mse: 0.5099 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - loss: 0.4291 - mse: 0.4291\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - loss: 0.2721 - mse: 0.2721\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2646 - mse: 0.2646\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7344 - mse: 0.7344\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - loss: 0.4689 - mse: 0.4689\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.0926 - mse: 0.0926\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 0.4193 - mse: 0.4193\n",
      "\u001b[1m 32/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1135 - mse: 0.1135 Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2657 - mse: 0.2657 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0640 - mse: 0.0640\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0656 - mse: 0.0656\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0721 - mse: 0.0721\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0953 - mse: 0.0953\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0494 - mse: 0.0494  \n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0470 - mse: 0.0470 Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0385 - mse: 0.0385 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0994 - mse: 0.0994\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 3/50\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0403 - mse: 0.0403Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mse: 0.04014\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0262 - mse: 0.0262\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0308 - mse: 0.030889\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0258 - mse: 0.0258 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0212 - mse: 0.021291\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0250 - mse: 0.0250\n",
      "\u001b[1m 23/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mse: 0.0273 Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - mse: 0.02298\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0184 - mse: 0.0184\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0173 - mse: 0.0173Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.0143 - mse: 0.0143\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0211 - mse: 0.0211Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0197 - mse: 0.0197Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - mse: 0.01942\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0124 - mse: 0.0124\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0156 - mse: 0.0156Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mse: 0.0155 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.01615 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0144 - mse: 0.0144Epoch 10/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mse: 0.01306\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.0112 - mse: 0.0112\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 11/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0137 - mse: 0.0137\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102 Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0096 - mse: 0.0096 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - loss: 0.0063 - mse: 0.0063Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0083 - mse: 0.0083 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.009000\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101  \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.011107\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0148 - mse: 0.014820\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 16/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mse: 0.0137  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mse: 0.0102\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.0112Epoch 17/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.00860\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mse: 0.0113 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.00688\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mse: 0.0075 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.010188\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.006588 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102 Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mse: 0.00659\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.0073Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - mse: 0.0098 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.0073  \n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - mse: 0.0094Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mse: 0.0083\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.0083 - mse: 0.0083 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109 - mse: 0.0109  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0044 - mse: 0.0044Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093 \n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.00966\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.00610\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0045 - mse: 0.0045Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.005360\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - mse: 0.0098Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0070 - mse: 0.0070Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mse: 0.0096 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mse: 0.0096  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - mse: 0.005169\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.008305\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mse: 0.0073   \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mse: 0.0076Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0062 - mse: 0.0062Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.00617\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - mse: 0.0088  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0076 - mse: 0.0076Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.00836\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0046 - mse: 0.0046 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079 \n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063\n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049 Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 38/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 38/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.0045 - mse: 0.0045 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0048 - mse: 0.0048\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.0076Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 41/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.00595\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052  \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mse: 0.0046Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.00529\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.007369\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.00874\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0072 - mse: 0.0072Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0083 - mse: 0.0083\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0038 - mse: 0.003\n",
      "\u001b[1m 7/53\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.024 total time=  10.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0055 - mse: 0.005\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 48/50\n",
      "\u001b[1m 1/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 40ms/step[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.059 total time=  10.1s\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0044 - mse: 0.0044Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0054 - mse: 0.0057\n",
      "Epoch 1/50\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.525 total time=  10.2s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/stepep - loss: 0.0045 - mse: 0.004\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 47/50\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - mse: 0.0053[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.068 total time=  10.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 50/50\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052Epoch 1/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0041 - mse: 0.0041Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0043 - mse: 0.00\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.049 total time=  10.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 585ms/step - loss: 1.1184 - mse: 1.1184Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0058 - mse: 0.0060   \n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=32;, score=-0.667 total time=  10.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2035 - mse: 0.2035  \n",
      "Epoch 2/50\n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6497 - mse: 0.6497\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 1s/step - loss: 0.3656 - mse: 0.3656[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.025 total time=  11.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 0.1264 - mse: 0.1264\n",
      "Epoch 2/50\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1840 - mse: 0.1840 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0989 - mse: 0.0989 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0355 - mse: 0.03555\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mse: 0.0328Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 3/50\n",
      "\u001b[1m 13/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - mse: 0.0310 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=16;, score=-0.102 total time=  11.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0236 - mse: 0.0236 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 7/50\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0205 - mse: 0.0205Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mse: 0.0221 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mse: 0.01350 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1703 - mse: 0.1703 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.01621\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.01475\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1641 - mse: 0.1641 6\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0143 - mse: 0.0143\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0235 - mse: 0.0235Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.0294 Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0162 - mse: 0.0162\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 9/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0290 - mse: 0.029054\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1332 - mse: 0.1332\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - mse: 0.0089 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0292 - mse: 0.0292 \n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0107 - mse: 0.0107Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - mse: 0.0152 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1139 - mse: 0.1139\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 7/50\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0326 - mse: 0.0326\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mse: 0.0095  \n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.01311\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077 \n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - mse: 0.0172 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mse: 0.00944\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 10/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0141 - mse: 0.0141\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 6/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.009281 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mse: 0.0086  \n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - mse: 0.0066\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0074 - mse: 0.0074 Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - mse: 0.0061 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0151 - mse: 0.0151Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.00748\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068   \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 15/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.009059\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 13/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 14/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - mse: 0.0085  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071 - mse: 0.0071  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0058 - mse: 0.00588\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mse: 0.00848\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0058 - mse: 0.00584 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mse: 0.0057Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - mse: 0.0064 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.00636\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0118 - mse: 0.0118Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mse: 0.006350\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 19/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - mse: 0.0051 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - mse: 0.0073 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 20/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0065 - mse: 0.0065\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 24/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.004648\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mse: 0.0048 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mse: 0.0070   \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mse: 0.0049\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 22/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044  \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mse: 0.0042   \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045    \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 33/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - mse: 0.0058Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - mse: 0.0045 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - mse: 0.0053Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mse: 0.00539 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0052 - mse: 0.0052Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.005653 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044 \n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034  Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051   \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055 5\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - mse: 0.0033  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\u001b[1m 20/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mse: 0.0054Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mse: 0.0053 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 37/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041  \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 39/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.00495\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 32/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0059 - mse: 0.0059 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037  \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.0045 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 43/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - mse: 0.0060          \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - mse: 0.0033  \n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055 Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.00452\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 39/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - mse: 0.00352\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - mse: 0.00383\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043  \n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.005743\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 49/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0033 - mse: 0.0033\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - mse: 0.0067 [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=-0.206 total time=  14.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 41/50\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 45/50\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0029 - mse: 0.00\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=1, model__neurons=64;, score=-0.134 total time=  15.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0057 - mse: 0.0057   \n",
      "Epoch 50/50\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025Epoch 47/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepep - loss: 0.0036 - mse: 0.00\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 45/50\n",
      "\u001b[1m33/53\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=-0.071 total time=  15.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 47/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0023 - mse: 0.0025\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 44/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=16;, score=-0.024 total time=  16.0s\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027Epoch 1/50\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024   \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0903 - mse: 0.0903\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027   \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1532 - mse: 0.1532\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - mse: 0.0213 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 48/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mse: 0.0026Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0033 - mse: 0.0033\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.0181 - mse: 0.0181\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 4/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.012286 \n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0047 - mse: 0.0047[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.026 total time=  16.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0710 - mse: 0.0710\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0273 - mse: 1.02739  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.0477 - mse: 0.0477\n",
      "Epoch 3/50\n",
      "\u001b[1m  6/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0212 - mse: 0.0212Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.257 total time=  15.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m 29/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0142 - mse: 0.0142Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mse: 0.0278 2\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0019 - mse: 0.001\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0328 - mse: 0.0328[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=32;, score=-0.059 total time=  17.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.00790\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 7/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0079 - mse: 0.0079Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mse: 0.0193  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.008980  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - loss: 0.0942 - mse: 0.0942\n",
      "Epoch 2/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1439 - mse: 0.1439\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.0318 - mse: 0.0318\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0107 - mse: 0.0107[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.017 total time=  16.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mse: 0.0105 \n",
      "Epoch 7/50\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - mse: 0.0214Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - mse: 0.0049  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.01419\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0748 - mse: 0.07487 \n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mse: 0.0122 Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 15/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mse: 0.0095  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - mse: 0.0079 \n",
      "\u001b[1m 10/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2864 - mse: 0.2864 Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mse: 0.0113 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0960 - mse: 0.0960\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.02088\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mse: 0.0087Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mse: 0.0087\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - mse: 0.0069Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - mse: 0.0118   \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.0157\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mse: 0.0096 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.007192\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0032 - mse: 0.0032\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0096 - mse: 0.0096 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0069 - mse: 0.0069Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 14/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089 9\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062  \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054  \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m 46/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0056 - mse: 0.0056Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0068 - mse: 0.0068Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 23/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.005633\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.00495\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 28/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.007755\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.00445\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0018 - mse: 0.0018Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mse: 0.0049 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031   \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.00502\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - mse: 0.0057  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mse: 0.00473\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0048 - mse: 0.0048\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 33/50\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 9.8422e-04 - mse: 9.8422e-04Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0029 - mse: 0.0029       \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.00502\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0015 - mse: 0.0015Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 0.0021 - mse: 0.0021Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mse: 0.0050 Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.0021  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066        \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.00334\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 29/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030  Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0041 - mse: 0.0041Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036  \n",
      "Epoch 39/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mse: 0.0030   \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mse: 0.0028\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0052 - mse: 0.0052Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mse: 0.00345 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mse: 0.0026Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 33/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0058 - mse: 0.0058  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 26/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mse: 0.00410 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mse: 0.0044\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031          \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.00162\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - mse: 0.0029  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.00304\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.0029 - mse: 0.0029\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 29/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.0030 - mse: 0.0030 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043       \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041 \n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - loss: 0.0025 - mse: 0.0025Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mse: 0.00407\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0026 - mse: 0.002667\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mse: 0.0041 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mse: 0.0028  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0057 - mse: 0.0057 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.001529\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - mse: 0.0029Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mse: 0.00397086e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0038 - mse: 0.00385      \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mse: 0.0029 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mse: 0.0056 \n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mse: 0.0038 Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0025 - mse: 0.0025     \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mse: 0.0037 \n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - mse: 0.0022Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0060 - mse: 0.0060\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.035 total time=  13.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepep - loss: 0.0057 - mse: 0.005\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 49/50\n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - mse: 0.0021[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=2, model__neurons=64;, score=-0.239 total time=  14.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 38/50\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.0036Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0055 - mse: 0.0055  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - mse: 0.0023Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - loss: 0.0039 - mse: 0.0039Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0024 - mse: 0.0024  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mse: 0.0027  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.005228\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0034 - mse: 0.0034Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.00243\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 41/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0015 - mse: 0.0031\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mse: 0.0023[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.046 total time=  14.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mse: 0.0034 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 48/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.00345\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023   \n",
      "\u001b[1m 23/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019 Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.00243\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0567 - mse: 0.0567 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0950 - mse: 0.0950\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0024 - mse: 0.0024       \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0036 - mse: 0.0036\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.0147  \n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - mse: 0.0248  Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 50/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0147 - mse: 0.0147Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0018 - mse: 0.0018[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.018 total time=  15.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.017 total time=  14.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 47/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0070 - mse: 0.0015 \n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 6/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0079 - mse: 0.0079[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=16;, score=-0.950 total time=  14.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - mse: 0.00612\n",
      "Epoch 7/50\n",
      "\u001b[1m  7/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - mse: 0.0019   Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1114 - mse: 0.1114\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mse: 0.0017Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022 2\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.0073 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - mse: 0.00215\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 893us/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steposs: 0.0053 - mse: 0.00: 0.0032\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0251 - mse: 0.0251  [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.042 total time=  16.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 11/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0801 - mse: 0.0801\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0259 - mse: 0.0259[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=32;, score=-0.243 total time=  15.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.0034  \n",
      "Epoch 13/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0029 - mse: 0.0029Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1241 - mse: 0.1241\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mse: 0.0248\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0379 - mse: 0.0379\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 13/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - mse: 0.0248  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - mse: 0.0045  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0025 - mse: 0.0025Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.0196 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mse: 0.01167\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mse: 0.00349\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.00393\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1257 - mse: 0.1257\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mse: 0.010533 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0033 - mse: 0.0033 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 11/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030  \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 4/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mse: 0.0087  \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mse: 0.0030  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 23/50\n",
      "Epoch 12/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080 Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.00828\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.00967\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018 Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0080 - mse: 0.0080\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073  Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0065 - mse: 0.0065Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mse: 0.0028 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.002490\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.00238\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 10/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0019 - mse: 0.0019Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0071 - mse: 0.0071Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - loss: 0.0015 - mse: 0.0015Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - mse: 0.0073   \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0051 - mse: 0.0051 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mse: 0.0084  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mse: 0.0026 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.00158\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mse: 0.0057Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067.9910e-0[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mse: 0.006\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0019 - mse: 0.0019      \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.00131\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.00626\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 0.0015 - mse: 0.0015      \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.00431\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 17/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.0052 - mse: 0.0052      \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.00736      \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - mse: 0.0032Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.00572\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0072 - mse: 0.0072     \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012  \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 26/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0019 - mse: 0.0019     \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.003562\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.0042          \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.0012  \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mse: 0.0065  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mse: 0.0044 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018        \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011       \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.00151\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - mse: 0.0039 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mse: 0.00293       \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - mse: 0.0063        \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mse: 0.00361\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.00164\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 44/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0051 - mse: 0.00519836e-\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 38/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0050 - mse: 0.00506958e-\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.0026 - mse: 0.0026     \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mse: 0.0010  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.001540\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0016 - mse: 0.001636e-0\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.00132\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5891e-04 - mse: 9.5891e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.003759\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014       \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 44/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013   \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 41/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0034 - mse: 0.0034     \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 42/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0048 - mse: 0.00482553e-0\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 9.5844e-04 - mse: 9.5844e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mse: 0.0040  52e-0\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.0041Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mse: 0.00427089e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7247e-04 - mse: 9.7247e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mse: 0.00414\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0034 - mse: 0.0034Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 9.0240e-04 - mse: 9.0240e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0040 - mse: 0.0040   \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0032 - mse: 0.0032\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011         Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0043 - mse: 0.0043\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 42/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0055 - mse: 0.0055       \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 0.0043 - mse: 0.0043[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.038 total time=  13.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 0.0012 - mse: 0.0012Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0019 - mse: 0.0019       \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 44/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.021 total time=  14.3s\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mse: 0.0045Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027      \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mse: 0.0010\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mse: 0.00425\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 38/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━���━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0013 - mse: 0.0013Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mse: 0.0034  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mse: 0.0043 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - mse: 0.00340\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - mse: 0.0050 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mse: 0.0027 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020        \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0779 - mse: 0.07792\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - mse: 0.0050 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m 42/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0673 - mse: 0.0673\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/steps: 0.0031 - mse: 0.0048\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0141 - mse: 0.0141[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=3, model__neurons=64;, score=-0.039 total time=  14.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.0023  \n",
      "Epoch 42/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steps: 0.0045 - mse: 0.00 mse: 0.0046\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepstep - loss: 0.0023 - mse: 0.00\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mse: 0.0094 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.041 total time=  14.3s\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mse: 0.0046  [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.082 total time=  14.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 44/50\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mse: 0.0097Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 48/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mse: 0.00452\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mse: 0.0017  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mse: 0.0045\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6577 - mse: 0.6577\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - mse: 0.0015        \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.01686\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2211 - mse: 0.2211\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0063 - mse: 0.0063\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 9/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.1076 - mse: 0.1076\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━��━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1019 - mse: 0.1019[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=16;, score=-0.019 total time=  15.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 9/50\n",
      "\u001b[1m 1/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 50ms/stepEpoch 1/50s: 0.0024 - mse: 0.0024\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0679 - mse: 0.0656  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0665 - mse: 0.0665\n",
      "Epoch 5/50\n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mse: 0.0054[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.047 total time=  12.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 10/50\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0678 - mse: 0.0678Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0053 - mse: 0.0053\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092  Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0021 - mse: 0.0021\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mse: 0.0048  \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mse: 0.0075\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - mse: 0.0041\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0039 - mse: 0.0039Epoch 4/50\n",
      "Epoch 12/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9497 - mse: 0.9497\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 10/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.5691 - mse: 0.5691[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.020 total time=  13.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.00714\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3923 - mse: 0.3923\n",
      "\u001b[1m  8/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0045 - mse: 0.0045Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 14/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mse: 0.0085 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0574 - mse: 1.0574\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2210 - mse: 0.2210  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mse: 0.0034Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2137 - mse: 0.2137\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1040 - mse: 0.1040\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mse: 0.0048�━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0080 - mse: 0.008\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0901 - mse: 0.09015\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0213 - mse: 0.0213�━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - mse: 0.005\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0568 - mse: 0.0568\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7389 - mse: 0.7389\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0562 - mse: 0.056200.0572 - mse: 0.05\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2225 - mse: 0.2225\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0436 - mse: 0.0436 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0176 - mse: 0.0176\u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.003\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.00397\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - mse: 0.0027 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mse: 0.00489\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.003066\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0171 - mse: 0.0171\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 18/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1128 - mse: 0.1128\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mse: 0.0033 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0708 - mse: 0.070884\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 14/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0039 - mse: 0.0039\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0304 - mse: 0.0304Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441us/step - loss: 0.0378 - mse: 0.0378  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.017247 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.01973\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0470 - mse: 0.0470  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.002586 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - mse: 0.0032\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0262 - mse: 0.0262Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - mse: 0.0031 Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.015208\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0152 - mse: 0.0152Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0226 - mse: 0.0226s\u001b[0m 1ms/step - loss: 0.0022 - mse: 0.002\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0258 - mse: 0.0258\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 15/50\n",
      "Epoch 15/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022 - mse: 0.0022 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mse: 0.00191\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mse: 0.0032  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mse: 0.0028  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182 - mse: 0.01820\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.01452\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mse: 0.0021 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 12/50\n",
      "\u001b[1m  6/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - loss: 0.0020 - mse: 0.002105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0022 - mse: 0.0022         \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b7m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - mse: 0.0185[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mse: 0.00202\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - loss: 0.0027 - mse: 0.0027Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.01614\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - mse: 0.0165  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 22/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - loss: 0.0175 - mse: 0.0175\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.0168 - mse: 0.0168 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0024 - mse: 0.0024Epoch 19/50\n",
      "Epoch 15/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - mse: 0.01687        7 - mse: 0.0\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mse: 0.0028 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mse: 0.0028\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0156 - mse: 0.0156Epoch 32/50\n",
      "Epoch 23/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.0173        \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━��━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 30/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 21/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mse: 0.0025  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mse: 0.0019 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mse: 0.0140  m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156  \n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mse: 0.0018Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mse: 0.0157 \n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - mse: 0.0155       \n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.00264\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0019 - mse: 0.0019       \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.01472\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 24/50\n",
      "Epoch 19/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - mse: 0.01801         \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0023 - mse: 0.0023\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167   Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━���━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023 Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mse: 0.0016          loss: 0.0166 - mse: 0.016\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0161 - mse: 0.0161\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step - loss: 0.0161 - mse: 0.0161\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014         Epoch 21/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.00155\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 29/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.00145\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0024 - mse: 0.0024       4 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mse: 0.0152�━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mse: 0.0140\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━��━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0018 - mse: 0.0018 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0154 - mse: 0.0154Epoch 40/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mse: 0.01476  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mse: 0.0016p - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0141 - mse: 0.01419820e-04━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0124 - mse: 0.01\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0135 - mse: 0.01351\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m 26/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0011 - mse: 0.0011        Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mse: 0.0014\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mse: 0.0017\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - loss: 0.0147 - mse: 0.0147\n",
      "\u001b[1m 51/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134 Epoch 32/50\n",
      "Epoch 30/50\n",
      "Epoch 39/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mse: 0.0022        \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.00130m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - mse: 0.001\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0181 - mse: 0.0181\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 - mse: 0.0115\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 30/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - mse: 0.0013Epoch 26/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mse: 0.00135         \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0143 - mse: 0.0143  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mse: 0.0134- mse: 0.0119 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0138 - mse: 0.0138\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mse: 0.0011 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mse: 0.0134        \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[037m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - mse: 0.0024m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0023 - mse: 0.00237\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0147 - mse: 0.0147 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mse: 0.0013\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0100 - mse: 0.010\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mse: 0.0021Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mse: 0.00211\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105 - mse: 0.0105Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0108 - mse: 0.0108  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119   \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mse: 0.001349\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.012e: 0.0126\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - mse: 0.0028Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0013 - mse: 0.0013\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0117 - mse: 0.0117\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 36/50\n",
      "Epoch 32/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - loss: 0.0018 - mse: 0.0018 05\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - mse: 0.001\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149       \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mse: 0.0124\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.0023 - mse: 0.0023 Epoch 36/50\n",
      "Epoch 45/50\n",
      "Epoch 47/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.01068818e-\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.0136 Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mse: 0.0013      \n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - loss: 0.0087 - mse: 0.0087Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.013016471e-04�━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - mse: 0.00\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0103 - mse: 0.01030      \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - mse: 0.0018 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mse: 0.001105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0073 - mse: 0.00\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━��━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mse: 0.0151 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0137 - mse: 0.013772e-04\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0017 - mse: 0.0017Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mse: 0.0105        \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mse: 0.0019\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mse: 0.0011 3\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0122 - mse: 0.01221\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110 \n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0126 - mse: 0.0126Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0117 - mse: 0.0117  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126.8579e-0 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.01215775e-0\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0127 - mse: 0.0127     \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mse: 0.0011Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/stepep - loss: 6.5940e-04 - mse: 6.5940e-0\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - loss: 0.0185 - mse: 0.0185[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=32;, score=-0.097 total time=  24.9s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepep - loss: 0.0112 - mse: 0.0112 3775e-  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - mse: 0.01090619e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 39/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.026 total time=  21.9s\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0038 - mse: 0.0038Epoch 1/5060e-04\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - mse: 0.00117 67e-\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010        \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0116 - mse: 0.01166171e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0098 - mse: 0.0098       \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - mse: 0.0010\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011 \n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084 Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0112 - mse: 0.0112 7211e-0\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━��━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5947 - mse: 0.5947     \n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.0115e-04 - mse: 8.0115e-04Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011.8355e-0\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0111 - mse: 0.0111Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1935e-04 - mse: 9.1935e-04 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115Epoch 45/50\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/steps: 0.0144 - mse: 0.0142\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0132 - mse: 0.0132[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.014 total time=  26.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1395 - mse: 0.1395\n",
      "Epoch 3/50\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mse: 0.0094 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.0136       \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.00112984e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.00997\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - loss: 0.6692 - mse: 0.6692\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 9.5045e-04 - mse: 9.5045e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126 125e-0\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - mse: 0.00987481e-0\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2164 - mse: 0.2164Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.001104\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2130 - mse: 0.21304613e-0\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mse: 0.0103  19e-\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6274e-04 - mse: 8.6274e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0308 - mse: 0.03080\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 8.8507e-04 - mse: 8.8507e-04 Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3782e-04 - mse: 9.3782e-04  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1130 - mse: 0.1130\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132       \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0762 - mse: 0.0762\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6694 - mse: 0.6694\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepstep - loss: 0.0095 - mse: 0.009\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 50/50\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0013 - mse: 0.0013       [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.037 total time=  25.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.1601 - mse: 0.1601\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0492 - mse: 0.0492\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0223 - mse: 0.0223        \n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0804 - mse: 0.0804\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222 - mse: 0.0222 \n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/stepep - loss: 0.0317 - mse: 0.0317 \n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - mse: 0.0180[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.056 total time=  24.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183 - mse: 0.0183 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0534 - mse: 0.0534\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 8/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 48/50\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0468 - mse: 0.0468 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0012 - mse: 0.001255 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.01338\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 1\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steptep - loss: 0.0151 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 13/50\n",
      "\u001b[1m18/53\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0, model__layers=4, model__neurons=64;, score=-0.049 total time=  26.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.4860 - mse: 0.4860\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.1444 - mse: 0.1444: 0.0149 \n",
      "Epoch 1/50\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0245 - mse: 0.0245 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.057 total time=  24.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.01506\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 12/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1690 - mse: 0.1690 Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.1539 - mse: 0.1583    \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1441 - mse: 0.1441\n",
      "Epoch 3/50\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0162 - mse: 0.0162Epoch 1/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=16;, score=-0.658 total time=  25.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3475 - mse: 0.3475\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 2/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0210 - mse: 0.0210\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 15/50\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0694 - mse: 0.0694\n",
      "Epoch 4/50\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0221 - mse: 0.0221Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.1080 - mse: 0.1080\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0318 - mse: 0.03183 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0574 - mse: 0.0574\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mse: 0.0413\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0134 - mse: 0.0134    \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6006 - mse: 1.6006\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6447 - mse: 0.6447\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2114 - mse: 0.21148\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1123 - mse: 0.1123\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0131 - mse: 0.01312 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0679 - mse: 0.06793\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1279 - mse: 0.1279Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1074 - mse: 0.1074\n",
      "\u001b[1m 10/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - mse: 0.0086 Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.0308 - mse: 0.0308\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3667 - mse: 0.3667 Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0746 - mse: 0.07463 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2613 - mse: 0.2613 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.026029\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0834 - mse: 0.0834Epoch 7/50\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0129 - mse: 0.0129Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0830 - mse: 0.0830\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0586 - mse: 0.0586\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0125 - mse: 0.0125\n",
      "\u001b[1m 22/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0591 - mse: 0.0591 Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0563 - mse: 0.0563  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0444 - mse: 0.0444 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0452 - mse: 0.0452 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mse: 0.0375\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 27/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.0366 - mse: 0.0366\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 9/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mse: 0.0327\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.0209 - mse: 0.02099\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0111 - mse: 0.01117 105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0103 - mse: 0.01\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - mse: 0.0097 Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.0105 8 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0175 - mse: 0.0175  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264 - mse: 0.0264\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 15/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.00902\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.0102 - mse: 0.0102\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0084 - mse: 0.0084Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0164 - mse: 0.0164\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0201 - mse: 0.0201Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.0094 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 14/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0240 - mse: 0.0240\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0060 - mse: 0.0060Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0108 - mse: 0.0108Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 0.0089 - mse: 0.0089\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 35/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0178 - mse: 0.017885\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 0.0089 - mse: 0.0089Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.008415\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0080 - mse: 0.0080\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - loss: 0.0141 - mse: 0.0141Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 38/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.016978\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0079 - mse: 0.0079\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0204 - mse: 0.0204\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 0.0094 - mse: 0.0094 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 27/50\n",
      "Epoch 23/50\n",
      "Epoch 42/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0166 - mse: 0.0166Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0146 - mse: 0.0146  \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0195 - mse: 0.0195Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 29/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0195 - mse: 0.0195\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 26/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0068 - mse: 0.0068\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0084 - mse: 0.0084 Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - mse: 0.0090  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076  \n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mse: 0.0126Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mse: 0.0101\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mse: 0.0177Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - mse: 0.0070  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.008498\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0097 - mse: 0.0097\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 50/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mse: 0.0173  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mse: 0.0066Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0157 - mse: 0.0157  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mse: 0.01275\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - mse: 0.008m 6ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 32/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step p - loss: 0.0071 - mse: 0.007\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 27/50\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - mse: 0.0071[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.321 total time=  20.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0071 - mse: 0.0071  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - mse: 0.0101   \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.0120069  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0162 - mse: 0.0162Epoch 48/50\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0147 - mse: 0.0147Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163 - mse: 0.0163  \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0073 - mse: 0.00732\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.01296\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 49/50\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.012930\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - mse: 0.0116 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0162 - mse: 0.01621\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0070 - mse: 0.0070\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepstep - loss: 0.0133 - mse: 0.013\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0034 - mse: 0.0034[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=32;, score=-0.032 total time=  21.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.054 total time=  20.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - loss: 0.8379 - mse: 0.8379\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.0062 - mse: 0.0062\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.0167 - mse: 0.0167Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167  \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 41/50\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.2044 - mse: 0.2044\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065  \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0066 - mse: 0.0066  \n",
      "\u001b[1m 20/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0760 - mse: 0.0760 Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0031 - mse: 0.0031Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0766 - mse: 0.0766\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mse: 0.0058 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 50/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0536 - mse: 0.0536  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0063 - mse: 0.0063\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step: 0.0107 - mse: 0.010se: 0.0120 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 36/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.175 total time=  20.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 6/50\n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1840 - mse: 0.1840Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0058 - mse: 0.0058\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1703 - mse: 0.1703 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3456 - mse: 0.3456\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 2/50\n",
      "Epoch 46/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━��━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 311ms/step - loss: 1.2027 - mse: 1.2027Epoch 37/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0672 - mse: 0.06724\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.3758 - mse: 0.3758\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131  \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0713 - mse: 0.0713\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0877 - mse: 0.0877\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.011098\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0285 - mse: 0.0285\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mse: 0.0329Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mse: 0.0323 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111   \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.015304\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mse: 0.0241\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 6/50\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0235 - mse: 0.0235 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0060 - mse: 0.0060 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0231 - mse: 0.0231 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - mse: 0.0153\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 9/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.0173  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m  6/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0164 - mse: 0.0164Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mse: 0.016241/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0118 - mse: 0.01\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0149 - mse: 0.0149[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=1, model__neurons=64;, score=-0.035 total time=  27.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 45/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0092 - mse: 0.0092Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153  \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 15/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 13/50\n",
      "\u001b[1m25/53\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.038 total time=  26.4s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0074 - mse: 0.0023: 0.0132\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0151 - mse: 0.0151 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.013 total time=  26.5s\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 47/50\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mse: 0.0145Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - mse: 0.01737\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135  \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118 - mse: 0.0118Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0149 - mse: 0.0149  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0164 - mse: 0.01642\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mse: 0.012744\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3073 - mse: 0.3073\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0138 - mse: 0.0138\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0691 - mse: 0.0691\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0148 - mse: 0.01480 \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0358 - mse: 0.0358\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 4/50\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepstep - loss: 0.0119 - mse: 0.01 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 16/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1961 - mse: 0.1961[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=16;, score=-0.067 total time=  27.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1803 - mse: 0.1803\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 21/50\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122  Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0471 - mse: 0.0471\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123 Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.014278\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.4758 - mse: 0.4758\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.0363 - mse: 0.0363\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103 \n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.0208 - mse: 0.0208\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0116 - mse: 0.0116\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0183 - mse: 0.0183Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.1152 - mse: 0.1152\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 129ms/step - loss: 0.9498 - mse: 0.9498 Epoch 6/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 460ms/step - loss: 0.0159 - mse: 0.0159Epoch 18/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0283 - mse: 0.02835 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.3037 - mse: 0.3037\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0176 - mse: 0.0176  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0619 - mse: 0.0619 \n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0637 - mse: 0.0637Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.022600\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0614 - mse: 0.0614 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0488 - mse: 0.0488  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 5/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0147 - mse: 0.0147  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190 - mse: 0.0190\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mse: 0.0463Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0404 - mse: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0432 - mse: 0.043237\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0170 - mse: 0.017090\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.00936\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0327 - mse: 0.0327\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0363 - mse: 0.0363\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.00994\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 25/50\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mse: 0.0097 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - mse: 0.0143 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mse: 0.0102Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 23/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.01230\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 29/50\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - mse: 0.0101  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 27/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0287 - mse: 0.0287\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 10/50\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 8/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0112 - mse: 0.0112 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0102 - mse: 0.0102 ep - loss: 0.0172 - mse: 0.017\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mse: 0.0083 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0120 - mse: 0.012004  \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200 - mse: 0.0200  20\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0273 - mse: 0.0273 \n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mse: 0.00862\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - mse: 0.0091 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - loss: 0.0114 - mse: 0.0114Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.01292\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.01010\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - mse: 0.0290\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 13/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.01971\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.00979\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 17/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0234 - mse: 0.0234  \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090 9 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.009366\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0256 - mse: 0.0256  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.00840\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 20/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.0170 - mse: 0.0170\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0248 - mse: 0.0248\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078Epoch 38/50\n",
      "Epoch 19/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━��━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 204ms/step - loss: 0.0072 - mse: 0.0072Epoch 40/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - mse: 0.0215Epoch 38/50\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - mse: 0.0073Epoch 21/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mse: 0.0086  \n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0077 - mse: 0.0077Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mse: 0.0082  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mse: 0.00947\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.0123 - mse: 0.0123Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mse: 0.0107\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 21/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.01117\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mse: 0.0076 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.00889 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 44/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - mse: 0.0082 2\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 - mse: 0.0203  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0256 - mse: 0.0256   Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m 97/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - mse: 0.0078Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0246 - mse: 0.0246Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0232 - mse: 0.0232 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 46/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0212 - mse: 0.0212Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0109 - mse: 0.01097\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0067 - mse: 0.0067Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.01417\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - mse: 0.0079Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - mse: 0.0076\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m��━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0208 - mse: 0.0208Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0067 - mse: 0.00677\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mse: 0.0210  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 25/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mse: 0.0086 \n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0196 - mse: 0.0196Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0197 - mse: 0.0197 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mse: 0.0098\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.013863\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 32/50\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "Epoch 27/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.013 total time=  31.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.006281\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145006\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mse: 0.00898\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0166 - mse: 0.0166Epoch 33/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 - mse: 0.0199\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - mse: 0.0067 Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mse: 0.0071 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.0147008\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077 9\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 31/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steps: 0.0058 - mse: 0.00se: 0.0073 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0155 - mse: 0.0155[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.015 total time=  28.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.00744 \n",
      "Epoch 35/50\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mse: 0.0085Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0281 - mse: 0.0287\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.031 total time=  30.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 32/50\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133  \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0082 - mse: 0.0082 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2720 - mse: 0.2720\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.2393 - mse: 0.2393\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060 \n",
      "Epoch 41/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/stepep - loss: 0.0708 - mse: 0.070\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.0073 - mse: 0.0073[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.047 total time=  36.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0691 - mse: 0.0691\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140  \n",
      "Epoch 36/50\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - mse: 0.0457Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mse: 0.0391Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0339 - mse: 0.0339   \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mse: 0.0179   \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mse: 0.0322  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - mse: 0.01315\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mse: 0.0246  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 - mse: 0.00592\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mse: 0.0062  \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0310 - mse: 0.03109\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0225 - mse: 0.0225 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0275 - mse: 0.0275  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - mse: 0.0074 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193 - mse: 0.01937\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 10/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0261 - mse: 0.0261  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0118 - mse: 0.0118tep - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0062 - mse: 0.006269\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1392 - mse: 0.13926\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0207 - mse: 0.020e: 0.0506 \n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174 - mse: 0.0174 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.038 total time=  32.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 3/50\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0166 - mse: 0.0166Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mse: 0.0370  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0057 - mse: 0.005775\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165    \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - mse: 0.0191   \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - loss: 0.0267 - mse: 0.0267\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 12/50\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.0170Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.024769\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117 ━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.011\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1908 - mse: 0.1908\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0019 - mse: 0.0019Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━�━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.0057 - mse: 0.005��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.0059 - mse: 0.0059\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0174 - mse: 0.0174\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - mse: 0.0189Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0597 - mse: 0.0597\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0237 - mse: 0.0237\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.0124 - mse: 0.0124Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0445 - mse: 0.0445\n",
      "\u001b[1m 1/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 45ms/step[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=64;, score=-0.024 total time=  33.0s\n",
      "\u001b[1m53/53\u001b[0m \u001b[3232m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0425 - mse: 0.04223m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.014 total time=  33.0s\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.02062\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 50/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0161 - mse: 0.0161Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━��━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mse: 0.0327\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.0140 Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━�━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/ste�━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 22/50\n",
      "\u001b[1m 70/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2205 - mse: 0.2205[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.038 total time=  34.2s\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1866 - mse: 0.1866\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.2358 - mse: 0.2358\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:51\u001b[0m 3s/step - loss: 0.6084 - mse: 0.6084   Epoch 20/50\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0304 - mse: 0.0304520\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.3058 - mse: 0.30580.0121 - mse: 0.0121\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0235 - mse: 0.0235\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0424 - mse: 0.0424Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.01 - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0230 - mse: 0.02353  - mse: 0.0230\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0222 - mse: 0.0222Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0874 - mse: 0.08747\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - mse: 0.02115 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0633 - mse: 0.0633━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.010\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 25/50\n",
      "Epoch 4/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - mse: 0.0231 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0151 - mse: 0.01515\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0224 - mse: 0.0224\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174 - mse: 0.01747\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0218 - mse: 0.0218Epoch 16/50\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0398 - mse: 0.0398 Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201 - mse: 0.02017\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0420 - mse: 0.0420 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mse: 0.01813  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0114 - mse: 0.01146\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0087 - mse: 0.0087Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0430 - mse: 0.04307\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0147 - mse: 0.014718[0m 7ms/step - loss: 0.0188 - mse: 0.018\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0149 - mse: 0.01494\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - mse: 0.0384Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0157 - mse: 0.0157 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0172 - mse: 0.0172━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - mse: 0.017\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━��━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0140 - mse: 0.0140\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━���━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 19/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - mse: 0.0155Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162 - mse: 0.01627 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0361 - mse: 0.0361\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 20/50\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0162 - mse: 0.0162Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188 - mse: 0.0188\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 30/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0109 - mse: 0.0109\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0118 - mse: 0.0118Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0156 - mse: 0.01565 1s\u001b[0m 17ms/step - loss: 0.0297 - mse: 0.02\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193 - mse: 0.0193━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0113 - mse: 0.0113  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0329 - mse: 0.0329 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175 - mse: 0.0175\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0132 - mse: 0.0132\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0138 - mse: 0.0138 Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 16/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0134 - mse: 0.01348\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - mse: 0.012\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122 Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0105 - mse: 0.0105Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.01044\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0332 - mse: 0.0332\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - loss: 0.0143 - mse: 0.0143Epoch 32/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.01373 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mse: 0.0168 mse: 0.009\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0340 - mse: 0.0340\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "\u001b[1m 83/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0162 - mse: 0.0162Epoch 14/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0166 - mse: 0.0166  \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.01201  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0121 - mse: 0.01210\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 34/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175 - mse: 0.0175 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0128 - mse: 0.012880\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0141 - mse: 0.01410  \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mse: 0.0120 ━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0176 - mse: 0.0176Epoch 21/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0111 - mse: 0.0111 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178 - mse: 0.0178\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 36/50\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.0112 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.01305 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.01177 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0290 - mse: 0.02901\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0115 - mse: 0.0115\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - mse: 0.0177 Epoch 18/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - mse: 0.00990\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0129 - mse: 0.0129━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0282 - mse: 0.028\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0280 - mse: 0.02803\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0124 - mse: 0.012420\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - loss: 0.0140 - mse: 0.0140Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.0107 - mse: 0.0107Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - mse: 0.01072 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0102 - mse: 0.0102 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mse: 0.01127105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0118 - mse: 0.011\n",
      "\u001b[1m 90/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - mse: 0.0088Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - mse: 0.00891\n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m���━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - mse: 0.0283Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - mse: 0.0112 ━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mse: 0.00901\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mse: 0.0121Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.0117  m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.01\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0100 - mse: 0.01002\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.01201\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0262 - mse: 0.0262 \n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - mse: 0.0130Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0111 - mse: 0.0111[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - mse: 0.007\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - loss: 0.0052 - mse: 0.0052Epoch 47/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0105 - mse: 0.0105  33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0075 - mse: 0.00\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mse: 0.0113.0082 - mse: 0.00\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0172 - mse: 0.0172\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - mse: 0.0241 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 25/50\n",
      "Epoch 44/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0113 - mse: 0.01130\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0095 - mse: 0.00959\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158 Epoch 37/50\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mse: 0.01065 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - mse: 0.0078 �━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0153 - mse: 0.015\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - mse: 0.0104Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0088 - mse: 0.008━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0123 - mse: 0.0123\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0103 - mse: 0.0103\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0056 - mse: 0.0056Epoch 47/50\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0088 - mse: 0.0088Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0088 - mse: 0.0088  \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0237 - mse: 0.0237 \n",
      "Epoch 28/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/stepep - loss: 0.0082 - mse: 0.008\n",
      "\u001b[1m  9/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0219 - mse: 0.0219 [CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.015 total time=  44.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 39/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0054 - mse: 0.0054Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mse: 0.0100m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0179 - mse: 0.0179\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 29/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0103 - mse: 0.01030 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mse: 0.0073108 - mse: 0.010\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.0072\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0040 - mse: 0.0040Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━���━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0110 - mse: 0.0110\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1536 - mse: 0.1536Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1379 - mse: 0.137987\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0086 - mse: 0.0086\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0235 - mse: 0.0235━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0094 - mse: 0.00\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━��━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0545 - mse: 0.05451\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.039 total time=  48.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 32/50\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0234 - mse: 0.0234Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0403 - mse: 0.0403 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0093 - mse: 0.0093━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0169 - mse: 0.0169 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - mse: 0.0097━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - mse: 0.010\n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075 - mse: 0.0075 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0074 - mse: 0.0074 \n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step ss: 0.0042 - mse: 0.004 0.0245 2\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=16;, score=-0.243 total time=  50.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0247 - mse: 0.1898  mse: 0.0247\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0307 - mse: 0.0307\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━��━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077Epoch 6/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0186 - mse: 0.0186Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1558 - mse: 0.1558 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - mse: 0.00817 \n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0077 - mse: 0.0077  Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0066 - mse: 0.00665\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0252 - mse: 0.0252━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0097 - mse: 0.009\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0069 - mse: 0.0069 0.009\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092 Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0230 - mse: 0.02303\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mse: 0.00856 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2064 - mse: 0.2064\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0275 - mse: 0.0275\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0096 - mse: 0.0096Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0223━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0664 - mse: 0.066━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0075 - mse: 0.00\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0643 - mse: 0.0643\n",
      "\u001b[1m 33/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━��━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0217 - mse: 0.0217Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0379 - mse: 0.0379\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 0.0038 - mse: 0.0038Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0226 - mse: 0.0226��━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0086 - mse: 0.00\n",
      "\u001b[1m 52/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0341 - mse: 0.0341Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0071 - mse: 0.0071\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0493 - mse: 0.0493Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0348 - mse: 0.0348\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 5/50\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0490 - mse: 0.0490\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0096 - mse: 0.0096\n",
      "\u001b[1m 87/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0227 - mse: 0.0227Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - mse: 0.02253  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.0082━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.00\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0065 - mse: 0.0065  Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - mse: 0.00993━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0066 - mse: 0.0066 \n",
      "\u001b[1m 46/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━��\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208   Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - mse: 0.008477m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0329 - mse: 0.0329\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━���━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - mse: 0.0077\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0210 - mse: 0.0210\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mse: 0.0062Epoch 12/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0318 - mse: 0.0318\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - mse: 0.0090 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mse: 0.0085\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━���━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0295 - mse: 0.02951 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 41/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step: 0.0224 - mse: 0.02se: 0.0254 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mse: 0.0075Epoch 46/50\n",
      "\u001b[1m 58/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - mse: 0.0075[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=32;, score=-0.038 total time=  53.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0072 - mse: 0.0072 \n",
      "Epoch 42/50\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - mse: 0.0077Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.0269\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0223 - mse: 0.0223\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 43/50\n",
      "Epoch 42/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0283 - mse: 0.02834\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0062 - mse: 0.0062━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.024\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0229 - mse: 0.02294  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0069 - mse: 0.00696\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187 - mse: 0.0187 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 15/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0062 - mse: 0.00628\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.2140 - mse: 0.2140\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mse: 0.0207\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0075 - mse: 0.0075Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mse: 0.00673 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0248 - mse: 0.0248  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - mse: 0.0088\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mse: 0.0338 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - mse: 0.0186 \n",
      "Epoch 18/50\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0171 - mse: 0.0171[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.014 total time=  53.5s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0247 - mse: 0.02475\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 46/50\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0224 - mse: 0.0224 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━�0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0268 - mse: 0.0260�━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - mse: 0.02322\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mse: 0.0180 Epoch 14/50\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━���━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - mse: 0.0187 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0237 - mse: 0.0237 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 49/50\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0204 - mse: 0.0204Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━��━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1401 - mse: 0.1401\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - mse: 0.0226  ━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - mse: 0.02\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - mse: 0.0067Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0170 - mse: 0.0170\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 15/50\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0503 - mse: 0.05035\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0058 - mse: 0.00581\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0398 - mse: 0.039841\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0165 - mse: 0.0165�━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0237 - mse: 0.02\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0068 - mse: 0.00683\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0219 - mse: 0.0219Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0219 - mse: 0.0219\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step: 0.0184 - mse: 0.01 mse: 0.020\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━���━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 17/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.015 total time=  55.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0304 - mse: 0.03045 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mse: 0.0207m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 9/50\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - mse: 0.0055Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0055 - mse: 0.0055\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175 - mse: 0.0175  \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0068 - mse: 0.0068 �━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 49ms/st\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0258 - mse: 0.0258\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0196 - mse: 0.0181\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2807 - mse: 0.2807Epoch 7/50\n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - mse: 0.0187[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.038 total time=  59.0s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184 - mse: 0.01844\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1948 - mse: 0.1948 ━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0163 - mse: 0.016\n",
      "Epoch 2/50\n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0223 - mse: 0.0223Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0223 - mse: 0.0223\n",
      "\u001b[1m 22/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154 Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - mse: 0.02685\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.01899\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164 - mse: 0.0164 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0570 - mse: 0.0570 \n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/stepe 0.0194 - mse: 0.019\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0258 - mse: 0.0258[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=3, model__neurons=64;, score=-0.042 total time=  59.9s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0175 - mse: 0.0175\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 20/50\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1012 - mse: 0.1012163\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - mse: 0.02549\n",
      "Epoch 9/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0116 - mse: 0.0116Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177 - mse: 0.01777\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0244 - mse: 0.02444\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mse: 0.0277 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182 - mse: 0.01825  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0900 - mse: 0.0900\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "\u001b[1m 66/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0238 - mse: 0.0238Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0236 - mse: 0.02363\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0312 - mse: 0.0312\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0199 - mse: 0.0199 Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0419 - mse: 0.0419 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0163 - mse: 0.0163   \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0208 - mse: 0.0208 \n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0192 - mse: 0.0192Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0200 - mse: 0.0200 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.01966\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mse: 0.01629 \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.02698\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168 Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mse: 0.02424\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - mse: 0.0228 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0185 - mse: 0.0185   \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - mse: 0.020722\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150  \n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158   Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mse: 0.013610\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━���━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155  \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - mse: 0.0168  \n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.01207�━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.011\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158  \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0109 - mse: 0.0109   \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0164 - mse: 0.0164\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 35/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0153 - mse: 0.0153 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mse: 0.01414 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0147 - mse: 0.0147\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 36/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0149 - mse: 0.0149   \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.011130\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125  \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - mse: 0.0189Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0120 - mse: 0.0120Epoch 23/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0147 - mse: 0.014707 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0116 - mse: 0.0116 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0177 - mse: 0.0177\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - loss: 0.0165 - mse: 0.0165Epoch 39/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0091 - mse: 0.009110\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0117 - mse: 0.01179\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0154 - mse: 0.0154\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mse: 0.0130Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0111 - mse: 0.0111 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 47/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mse: 0.0122\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0139 - mse: 0.0139Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mse: 0.013908\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0163 - mse: 0.0163\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 41/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[tep - loss: 0.0137 - mse: 0.01340m 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106   \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.0138  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.00849\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mse: 0.0100 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mse: 0.01382 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0110 - mse: 0.0110 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.012465\n",
      "Epoch 48/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/steps: 0.0096 - mse: 0.00se: 0.0143\n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0104 - mse: 0.0104[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.038 total time=  48.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071 - mse: 0.0071 \n",
      "Epoch 31/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0131 - mse: 0.0131Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━���━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mse: 0.0184 Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - mse: 0.010785\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0172 - mse: 0.01722\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.01111 \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mse: 0.0111   \n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steposs: 0.0100 - mse: 0.010 0.0083 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.4808 - mse: 2.4808\n",
      "Epoch 2/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.015 total time=  44.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 43/50\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - mse: 0.0108Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mse: 0.01050\n",
      "Epoch 34/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0096 - mse: 0.0095\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━��━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0104 - mse: 0.0104[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=16;, score=-0.168 total time=  46.2s\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6662 - mse: 0.6662   Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mse: 0.0109  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5921 - mse: 0.5921\n",
      "Epoch 3/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mse: 0.00726\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.0102 - mse: 0.0102\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:50\u001b[0m 5s/step - loss: 0.0177 - mse: 0.0177Epoch 36/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 401ms/step - loss: 3.4353 - mse: 3.4353Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - loss: 0.2519 - mse: 0.25196\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - loss: 0.0108 - mse: 0.0108\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 2.2574 - mse: 2.2574 Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 2.1014 - mse: 2.1014\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - loss: 1.8058 - mse: 1.8058 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 0.4838 - mse: 0.4838\n",
      "Epoch 3/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mse: 0.0094Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1227 - mse: 0.1227 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mse: 0.0106\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4439 - mse: 0.4439\n",
      "Epoch 46/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mse: 0.00965\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.0739 - mse: 0.0739\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2520 - mse: 0.2520 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mse: 0.007271\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101  \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mse: 0.0093\n",
      "\u001b[1m 67/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mse: 0.0096Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1798 - mse: 0.1798\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1196 - mse: 0.1196\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - mse: 0.0097Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mse: 0.01054\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0961 - mse: 0.0961\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0733 - mse: 0.0733\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 0.0491 - mse: 0.0491\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - mse: 0.0097 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - mse: 0.00927\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mse: 0.0340\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 9/50\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mse: 0.01029\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.009058\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mse: 0.0281  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - mse: 0.0067  \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.0270\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0214 - mse: 0.0214Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - mse: 0.02126\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/steps: 0.0112 - mse: 0.01\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 13/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0064 - mse: 0.0064[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.205 total time=  38.2s\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0170 - mse: 0.0170[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=32;, score=-0.036 total time=  43.0s\n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mse: 0.0101Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mse: 0.00993\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 11/50\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0255 - mse: 0.0255  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - mse: 0.0083  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.01760\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - mse: 0.028395\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mse: 0.0087   \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1175 - mse: 1.11757\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6508 - mse: 1.6508\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0240 - mse: 0.0240\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - mse: 0.02482\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0187 - mse: 0.0187\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 17/50\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.5678 - mse: 0.5678\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.3643 - mse: 0.3643 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0088 - mse: 0.008817\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0239 - mse: 0.0239 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3117 - mse: 0.3117\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1634 - mse: 0.1634\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0253 - mse: 0.02535\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1477 - mse: 0.1477\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.0223 - mse: 0.0223 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0982 - mse: 0.0982\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - mse: 0.0231 Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0240 - mse: 0.0240\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mse: 0.0085  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1163 - mse: 0.1163\n",
      "\u001b[1m 50/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0764 - mse: 0.0764Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━��━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0675 - mse: 0.0675\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 6/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.0838 - mse: 0.0838\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0340 - mse: 0.034055\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0255 - mse: 0.0255  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mse: 0.0061\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mse: 0.0082\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0886 - mse: 0.0886\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/steps: 0.0099 - mse: 0.00se: 0.008\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0637 - mse: 0.0637[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.039 total time=  41.8s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mse: 0.0628\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - mse: 0.0082 \n",
      "Epoch 34/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepep - loss: 0.0244 - mse: 0.0293\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mse: 0.0093[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.013 total time=  43.4s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 24/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0249 - mse: 0.02490\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 35/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0075 - mse: 0.0075Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - mse: 0.02168\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mse: 0.0353\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197 Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0179 - mse: 0.0179  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.017637\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247  \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.2054 - mse: 1.2054\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9265 - mse: 0.9265\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185 - mse: 0.0185     \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mse: 0.0369\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0160 - mse: 0.01601\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3335 - mse: 0.3335\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3123 - mse: 0.3123 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0373 - mse: 0.0373\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1325 - mse: 0.1325\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━���\u001b[0m \u001b[1m1:18\u001b[0m 758ms/step - loss: 0.2366 - mse: 0.2366Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0276 - mse: 0.02768\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0221 - mse: 0.0221 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - loss: 0.0750 - mse: 0.0750  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - loss: 0.1634 - mse: 0.1634\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0218 - mse: 0.0218 Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0730 - mse: 0.0730  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0518 - mse: 0.0518\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0612 - mse: 0.0612   Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0247 - mse: 0.02470\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - mse: 0.00730\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0158 - mse: 0.0158 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0642 - mse: 0.06427\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0250 - mse: 0.02507\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.0089 - mse: 0.0089Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mse: 0.0209  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0267 - mse: 0.0267\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 20/50\n",
      "Epoch 33/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mse: 0.00856 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0242 - mse: 0.0242  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 36/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mse: 0.0073 0\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mse: 0.0216\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 36/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mse: 0.0231 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0153 - mse: 0.0153Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m  3/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0177 - mse: 0.0177Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mse: 0.0242 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 197ms/step - loss: 0.0176 - mse: 0.0176Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mse: 0.0071  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mse: 0.0236 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0254 - mse: 0.02545\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mse: 0.0154 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0216 - mse: 0.0216\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0126 - mse: 0.0126Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0210 - mse: 0.021020\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0192 - mse: 0.0192━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - mse: 0.02\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0221 - mse: 0.0221 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0156 - mse: 0.01564\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - mse: 0.0079\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - mse: 0.0146 Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.0182 - mse: 0.0182\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 43/50\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - mse: 0.0215 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.01850\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mse: 0.02099\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mse: 0.013200\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━��━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 45/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - mse: 0.00693\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - mse: 0.0187 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mse: 0.0141 7 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - loss: 0.0055 - mse: 0.0055Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0204 - mse: 0.0204 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0197 - mse: 0.0197 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mse: 0.012805\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0225 - mse: 0.0225 Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.02303\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 31/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0255 - mse: 0.0266\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0171 - mse: 0.0171[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=4, model__neurons=64;, score=-0.034 total time=  55.6s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0189 - mse: 0.01898\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 19/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0126 - mse: 0.0126Epoch 32/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - loss: 0.0196 - mse: 0.0196Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.0241 - mse: 0.0241\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mse: 0.0155 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "\u001b[1m 62/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0197 - mse: 0.0197Epoch 22/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0205 - mse: 0.0205[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.014 total time=  34.7s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0147 - mse: 0.0147Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 24/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step loss: 0.0143 - mse: 0.0143 \n",
      "\u001b[1m 93/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0143 - mse: 0.0143[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.791 total time=  39.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0181 - mse: 0.01819\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0185 - mse: 0.01850\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 36/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0336 - mse: 0.0336Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.7034 - mse: 0.7034\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.6203 - mse: 0.6203\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.0194 - mse: 0.0194Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.0183 - mse: 0.0183\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:00\u001b[0m 7s/step - loss: 0.0263 - mse: 0.0263Epoch 2/50\n",
      "\u001b[1m 2/53\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 7s/stepEpoch 26/50 0.0299 - mse: 0.029e: 0.019\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.0193 - mse: 0.019379 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0138 - mse: 0.0138 1\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 2.0085 - mse: 2.0085\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2024 - mse: 0.2024\n",
      "Epoch 24/50\n",
      "Epoch 3/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2766 - mse: 0.2766\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0102 - mse: 0.0102Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 39/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.031 total time=  47.1s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mse: 0.01638\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.1168 - mse: 0.1168\n",
      "Epoch 4/50\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0971 - mse: 0.0971\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6034 - mse: 0.60342\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 3/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0820 - mse: 0.0820\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1942 - mse: 0.1942 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0572 - mse: 0.0572\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0402 - mse: 0.0402 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1184 - mse: 0.11841\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0170 - mse: 0.0170  \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0704 - mse: 0.0704\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0352 - mse: 0.0352 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - mse: 0.0193 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0280 - mse: 0.0280 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0564 - mse: 0.056484\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.012531\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0523 - mse: 0.0523 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.01647\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225 Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mse: 0.0124  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0223 - mse: 0.0223  \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0470 - mse: 0.0470\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.8421 - mse: 1.8421\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0175 - mse: 0.0175 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4954 - mse: 0.4954\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 - mse: 0.0168 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0399 - mse: 0.0399 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1498 - mse: 0.1498\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0177 - mse: 0.0177  \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0409 - mse: 0.0409\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0163 - mse: 0.0163  \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1101 - mse: 0.1101\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.01515\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.0161 - mse: 0.0161\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0135 - mse: 0.0135Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0169 - mse: 0.01698\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0179 - mse: 0.0179  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0595 - mse: 0.0595\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - mse: 0.015355\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mse: 0.0150: 0.056\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0144 - mse: 0.01440\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118 - mse: 0.0118 Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - mse: 0.0198\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0119 - mse: 0.0119\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0406 - mse: 0.0406 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145 - mse: 0.0145 2\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0155 - mse: 0.0155  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 0.0142 - mse: 0.0142\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step 0.0522 - mse: 0.052\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mse: 0.0131[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.025 total time=  41.8s\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.012 total time=  41.8s\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0410 - mse: 0.0410\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0334 - mse: 0.0334Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - mse: 0.01722\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0329 - mse: 0.0329\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2194 - mse: 1.2194\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7830 - mse: 1.7830\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2824 - mse: 0.2824\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mse: 0.01203\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - mse: 0.0276\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0988 - mse: 0.0988Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3628 - mse: 0.3628\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.1120 - mse: 0.1120\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0148 - mse: 0.014814\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mse: 0.0110\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2540 - mse: 0.2540\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - loss: 0.0108 - mse: 0.0108Epoch 16/50\n",
      "Epoch 4/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0631 - mse: 0.0631\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0145 - mse: 0.0145 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0332 - mse: 0.0332\n",
      "\u001b[1m 65/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0139 - mse: 0.0139Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.1194 - mse: 0.1194\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0566 - mse: 0.0566\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0333 - mse: 0.03333\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - mse: 0.0149 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 0.0245 - mse: 0.0245\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 0.0296 - mse: 0.0296Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 115ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - loss: 0.0799 - mse: 0.0799\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0161 - mse: 0.0161 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - mse: 0.02401\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0609 - mse: 0.0609Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "\u001b[1m  9/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0379 - mse: 0.0379   Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0594 - mse: 0.0594\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0081 - mse: 0.0081Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.01471\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mse: 0.0128  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0115 - mse: 0.0115   \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0478 - mse: 0.04781\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0239 - mse: 0.0239\n",
      "\u001b[1m 68/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0449 - mse: 0.04494\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mse: 0.0107  \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mse: 0.013911 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0117 - mse: 0.0117\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=32;, score=-0.930 total time=  48.2s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - mse: 0.0226  \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0348 - mse: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 32/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0123 - mse: 0.0123Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/steptep - loss: 0.0119 - mse: 0.013 \n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mse: 0.0118[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.027 total time=  48.3s\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - loss: 0.0341 - mse: 0.0341━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - loss: 0.0117 - mse: 0.011\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 129ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 129ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0204 - mse: 0.02041m0s\u001b[0m 9ms/step - loss: 0.0372 - mse: 0.037\n",
      "Epoch 25/50\n",
      "\u001b[1m 39/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0370 - mse: 0.0370Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 132ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0414 - mse: 0.0414\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0314 - mse: 0.0314━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0099 - mse: 0.00�━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0311 - mse: 0.03\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0102 - mse: 0.0102Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0343 - mse: 0.0343\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0223 - mse: 0.0223Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0388 - mse: 0.0388\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 10/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - loss: 0.0304 - mse: 0.0304 \n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0337 - mse: 0.0337\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125   \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - loss: 0.0319 - mse: 0.0319 \n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0322 - mse: 0.0322Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0115 - mse: 0.0115 \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0395 - mse: 0.039520\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 172ms/step - loss: 0.6984 - mse: 0.6984\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 176ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 27/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 174ms/step - loss: 1.5390 - mse: 1.5390 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - loss: 0.0331 - mse: 0.0331\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 149ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0295 - mse: 0.0295 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mse: 0.0334 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0222 - mse: 0.0222 Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1631 - mse: 0.1631\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3618 - mse: 0.3618\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0336 - mse: 0.0336\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0102 - mse: 0.01027\n",
      "Epoch 37/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0278 - mse: 0.0278 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0221 - mse: 0.0221\n",
      "\u001b[1m 13/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - loss: 0.0266 - mse: 0.0266  Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1728 - mse: 0.17287\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 4/50\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0765 - mse: 0.0765\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0375 - mse: 0.03754\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0985 - mse: 0.0985\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.0100 - mse: 0.0100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0291 - mse: 0.0291\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0121 - mse: 0.0121\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0335 - mse: 0.0335Epoch 39/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0551 - mse: 0.0551Epoch 40/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169 - mse: 0.0169 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mse: 0.0346 \n",
      "Epoch 31/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0308 - mse: 0.0308 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0496 - mse: 0.0496\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0296 - mse: 0.0296\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 20/50\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mse: 0.0353\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 16/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - mse: 0.0100\n",
      "\u001b[1m 82/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 - mse: 0.0362Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0305 - mse: 0.0305 Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0334 - mse: 0.0334 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mse: 0.0100  \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mse: 0.0341  \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0122 - mse: 0.012220\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0292 - mse: 0.0292  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0279 - mse: 0.0279\n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mse: 0.0099Epoch 34/50\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0313 - mse: 0.03131\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0083 - mse: 0.0083Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0313 - mse: 0.0313   \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0292 - mse: 0.0292\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0272 - mse: 0.0272Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0126 - mse: 0.0126\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mse: 0.0295 Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 - mse: 0.0302\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 25/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 47/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.0327 - mse: 0.0327\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mse: 0.0121  \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mse: 0.0095  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244  \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - loss: 0.0091 - mse: 0.0091 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - mse: 0.0248 \n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.0321 - mse: 0.0321 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0279 - mse: 0.027989\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0261 - mse: 0.0261\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0309 - mse: 0.03090 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0310 - mse: 0.03108\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - mse: 0.0245Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━���━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.0301 - mse: 0.0301\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183 - mse: 0.0183ms/step - loss: 0.0228 - mse: 0.02\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mse: 0.00983\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0263 - mse: 0.0263\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - mse: 0.0231 \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0111 - mse: 0.0111\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - mse: 0.02995\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195 - mse: 0.01957\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mse: 0.02844\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mse: 0.0096  \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0244 - mse: 0.0244[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.196 total time= 1.3min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0242 - mse: 0.02420\n",
      "Epoch 17/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - mse: 0.0291\n",
      "\u001b[1m  6/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0239 - mse: 0.0239Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/stepep - loss: 0.0290 - mse: 0.023\n",
      "\u001b[1m 62/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0199 - mse: 0.0199[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=64;, score=-0.029 total time= 1.3min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 18/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0258 - mse: 0.0258Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0325 - mse: 0.0325  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.0236 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━��━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - mse: 0.02821\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - loss: 0.7284 - mse: 0.7284\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mse: 0.0190Epoch 2/50\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - loss: 0.0254 - mse: 0.0254Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.0186 - mse: 0.01865\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 20/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0221 - mse: 0.02219 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - loss: 0.0159 - mse: 0.0159Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.0240 - mse: 0.0240\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1581 - mse: 0.15817\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - loss: 1.1511 - mse: 1.1511\n",
      "\u001b[1m 78/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0182 - mse: 0.0182Epoch 3/50\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0298 - mse: 0.0298 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.0237 - mse: 0.0237 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0728 - mse: 0.07288\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mse: 0.0183  \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2686 - mse: 0.2686\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0294 - mse: 0.029421\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0306 - mse: 0.0306\n",
      "\u001b[1m 31/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0164 - mse: 0.0164 Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 4s/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 4s/step - loss: 0.0391 - mse: 0.03910249\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 4s/step - loss: 0.1087 - mse: 0.1087  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 4s/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 4s/step - loss: 0.0292 - mse: 0.0292\n",
      "\u001b[1m 61/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:36\u001b[0m 8s/step - loss: 0.0189 - mse: 0.0189Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 4s/step - loss: 0.0297 - mse: 0.0297m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0147 - mse: 0.01\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 6s/step - loss: 0.0193 - mse: 0.0193Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 4s/step - loss: 0.0199 - mse: 0.0199s: 0.0214 - mse: 0.02\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0619 - mse: 0.0619\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0342 - mse: 0.0342\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0171 - mse: 0.0171\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0202 - mse: 0.0202Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 19ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0195 - mse: 0.019596\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0269 - mse: 0.0269\n",
      "\u001b[1m 48/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0272 - mse: 0.0272Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mse: 0.0185  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0271 - mse: 0.0271 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0265 - mse: 0.02654 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 25/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0412 - mse: 0.0413 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 40/50\n",
      "\u001b[1m 55/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0179 - mse: 0.0179[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.014 total time= 9.1min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - mse: 0.0176\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0393 - mse: 0.0393\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 8/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - loss: 0.0372 - mse: 0.0372Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - mse: 0.0283  \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mse: 0.0364\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0204 - mse: 0.02041  \n",
      "Epoch 26/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - mse: 0.03147\n",
      "Epoch 39/50\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0201 - mse: 0.0201   [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.054 total time= 9.0min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - mse: 0.02307\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - mse: 0.0174  \n",
      "Epoch 28/50\n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0208 - mse: 0.0208Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0212 - mse: 0.02121\n",
      "\u001b[1m 22/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 432ms/step - loss: 0.0213 - mse: 0.0213 Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 0.0311 - mse: 0.0311\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 136ms/step - loss: 0.0185 - mse: 0.0185\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━��━━━━\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - loss: 0.0249 - mse: 0.0249 Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - loss: 0.5410 - mse: 0.5410\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 133ms/step - loss: 2.8099 - mse: 2.8099\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━��━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0086 - mse: 0.0086Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━���━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0179 - mse: 0.0179 \n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 0.0180 - mse: 0.0180\n",
      "\u001b[1m 54/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1146 - mse: 0.1146\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0218 - mse: 0.0218 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 28/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5006 - mse: 0.5006\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0596 - mse: 0.05961\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - mse: 0.0235 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0164 - mse: 0.01645 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1723 - mse: 0.1723  \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - mse: 0.0244\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 43/50\n",
      "\u001b[1m 81/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0240 - mse: 0.0240Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0397 - mse: 0.0397   \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0235 - mse: 0.0235  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - mse: 0.01964\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - mse: 0.0170Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.01700\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - mse: 0.0296Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0928 - mse: 0.0928  \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━��━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0360 - mse: 0.0360\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0693 - mse: 0.0693 Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0714 - mse: 0.0714\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0304 - mse: 0.03042  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 45/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - mse: 0.0210 \n",
      "\u001b[1m 40/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0277 - mse: 0.0277Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0638 - mse: 0.0638\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0153 - mse: 0.01538  \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0224 - mse: 0.0224 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0330 - mse: 0.033082\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0589 - mse: 0.0589\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - mse: 0.0207 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0236 - mse: 0.0236  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 17/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0558 - mse: 0.0558\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n",
      "Epoch 49/50\n",
      "Epoch 35/50\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0218 - mse: 0.0218[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.014 total time= 9.3min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mse: 0.0153 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 1/50\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0523 - mse: 0.0523\n",
      "\u001b[1m 16/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0172 - mse: 0.0172Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0189 - mse: 0.0189\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0219 - mse: 0.0219Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m 31/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0214 - mse: 0.0214Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0260 - mse: 0.0260  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepep - loss: 0.0575 - mse: 0.0572 \n",
      "\u001b[1m 13/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0189 - mse: 0.0189[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=16;, score=-0.138 total time= 9.3min\n",
      "\u001b[1m 35/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0530 - mse: 0.0530Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0194 - mse: 0.0194\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0178 - mse: 0.0178Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mse: 0.0502\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0165 - mse: 0.01655\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0143 - mse: 0.0143\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 14/50\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0190 - mse: 0.0190 \n",
      "\u001b[1m 77/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.7233 - mse: 0.7233 Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 1.0456 - mse: 1.0456\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 0.6446 - mse: 0.6446\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 0.0192 - mse: 0.0192\n",
      "\u001b[1m  7/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 2s/step - loss: 0.0681 - mse: 0.0681 Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0208 - mse: 0.02088\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0113 - mse: 0.0113Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0199 - mse: 0.01994\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.0154 - mse: 0.0154 \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.1576 - mse: 0.1576\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.2534 - mse: 0.2534\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0209 - mse: 0.0209   \n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m 64/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.0185 - mse: 0.0185Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0814 - mse: 0.0814\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0487 - mse: 0.0487\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0714 - mse: 0.0714\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - mse: 0.0175  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mse: 0.0193\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 26/50\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1049 - mse: 0.1049\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.01302\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0584 - mse: 0.0584\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0613 - mse: 0.0613\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0466 - mse: 0.0466Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154  \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.01584 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0540 - mse: 0.0540\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0483 - mse: 0.0483   \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174 - mse: 0.01746\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0482 - mse: 0.0482 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 20/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0406 - mse: 0.0406\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mse: 0.0137   \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 30/50\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - mse: 0.0154Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mse: 0.0161   \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 - mse: 0.0145\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mse: 0.0201Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mse: 0.0201\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0418 - mse: 0.0418Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.0188 \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0418 - mse: 0.0418 \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.014020\n",
      "\u001b[1m 60/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - mse: 0.0128Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0196 - mse: 0.0196\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - mse: 0.0175Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - mse: 0.0177\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - loss: 0.0164 - mse: 0.0164Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - mse: 0.0182\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mse: 0.03766\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 23/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0320 - mse: 0.0330\n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mse: 0.0134[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.054 total time= 9.1min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 33/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0402 - mse: 0.0402\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - mse: 0.012982\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0158 - mse: 0.0158  \n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0419 - mse: 0.0419\n",
      "\u001b[1m 19/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0126 - mse: 0.0126Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0368 - mse: 0.0368\n",
      "\u001b[1m 24/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0404 - mse: 0.0404Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mse: 0.0453 \n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - mse: 0.0168Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0409 - mse: 0.04094\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177 - mse: 0.0177  \n",
      "Epoch 27/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/stepep - loss: 0.0198 - mse: 0.0196 \n",
      "\u001b[1m 76/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mse: 0.0330[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=32;, score=-0.046 total time= 9.4min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - mse: 0.03278\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 14/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━���━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0457 - mse: 0.04577\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0168 - mse: 0.0168  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0433 - mse: 0.04334\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - mse: 0.0149Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 - mse: 0.01494\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118  \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.5763 - mse: 2.5763\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0433 - mse: 0.0433\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mse: 0.0160Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 - mse: 0.0167\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0417 - mse: 0.0417\n",
      "Epoch 38/50\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 429ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 429ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 432ms/step - loss: 0.4575 - mse: 0.4575\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 430ms/step - loss: 0.0394 - mse: 0.0394\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0336 - mse: 0.0336Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - mse: 0.031256\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 431ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.011858 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 432ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.0639 - mse: 1.0639\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━���\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 432ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1595 - mse: 0.1595 \n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 657ms/step - loss: 0.2321 - mse: 0.2321Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.0399 - mse: 0.03993\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.1927 - mse: 0.192783 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0305 - mse: 0.0305 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0168 - mse: 0.0168\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.0290 - mse: 0.0290\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 40/50\n",
      "Epoch 40/50\n",
      "Epoch 18/50\n",
      "Epoch 18/50\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - loss: 0.0991 - mse: 0.0991\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0418 - mse: 0.0418Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - loss: 0.0371 - mse: 0.0371\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - loss: 0.0908 - mse: 0.0908\n",
      "\u001b[1m 59/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0147 - mse: 0.0147Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0177 - mse: 0.0177  \n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0375 - mse: 0.03755\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0680 - mse: 0.0680 \n",
      "\u001b[1m 74/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - mse: 0.0142Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0643 - mse: 0.0643\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━���━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0145 - mse: 0.01458\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0382 - mse: 0.03826\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0437 - mse: 0.0437  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0711 - mse: 0.0711\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0152 - mse: 0.0152\n",
      "\u001b[1m 10/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - loss: 0.0577 - mse: 0.0577Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0455 - mse: 0.04552\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0158 - mse: 0.0158 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mse: 0.0357 \n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0549 - mse: 0.0549 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0415 - mse: 0.04152 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0489 - mse: 0.0489 \n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0397 - mse: 0.03975\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0308 - mse: 0.0308\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0460 - mse: 0.0460\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 11/50\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0250 - mse: 0.02501\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0148 - mse: 0.0148\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0387 - mse: 0.0387\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - loss: 0.0157 - mse: 0.0157Epoch 46/50\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0414 - mse: 0.0414 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0110 - mse: 0.01101\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0292 - mse: 0.0292\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0422 - mse: 0.0422\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0258 - mse: 0.0258 \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mse: 0.0158 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mse: 0.0373\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 25/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0147 - mse: 0.0147 \n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0370 - mse: 0.0370\n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0388 - mse: 0.0388Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0393 - mse: 0.0393\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0400 - mse: 0.040000\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0266 - mse: 0.026655\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0380 - mse: 0.0380\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0377 - mse: 0.0377\n",
      "\u001b[1m 56/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0116 - mse: 0.0116Epoch 27/50\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0272 - mse: 0.027265\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0113 - mse: 0.0113\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 114ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0351 - mse: 0.03514\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 127ms/step - loss: 0.0142 - mse: 0.014250 \n",
      "\u001b[1m 72/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0360 - mse: 0.0360 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.041 total time=10.0min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0254 - mse: 0.0254\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0120 - mse: 0.0120Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0364 - mse: 0.0364\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0336 - mse: 0.0336Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0154 - mse: 0.0154  \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mse: 0.03694\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0349 - mse: 0.0349Epoch 29/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0349 - mse: 0.0349\n",
      "\u001b[1m 71/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mse: 0.0243Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0156 - mse: 0.0156 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0367 - mse: 0.03672\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mse: 0.038239  \n",
      "Epoch 46/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━��\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.014 total time=10.1min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - mse: 0.0231  \n",
      "Epoch 18/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mse: 0.0407 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mse: 0.0239 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.033551\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0321 - mse: 0.0321  \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0437 - mse: 0.0437  \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0343 - mse: 0.03432\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7239 - mse: 0.7239\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0376 - mse: 0.0376  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mse: 0.0139Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mse: 0.0369\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1713 - mse: 0.17132\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.0352 - mse: 0.0352\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0804 - mse: 0.0804\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8806 - mse: 0.8806\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0136 - mse: 0.0136\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/steps: 0.0837 - mse: 0.083mse: 0.0233 \n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.020 total time= 2.1min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 581ms/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 581ms/step - loss: 0.0669 - mse: 0.0669 \n",
      "Epoch 5/50\n",
      "Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 49ms/stepp - loss: 0.0428 - mse: 0.042\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 605ms/step - loss: 0.0341 - mse: 0.0341\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 664ms/step - loss: 0.0365 - mse: 0.0365Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 607ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 37/50\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 625ms/step - loss: 0.0204 - mse: 0.0204 [CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=2, model__neurons=64;, score=-0.027 total time= 3.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 28ms/step - loss: 0.0265 - mse: 0.0265\n",
      "\u001b[1m 27/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - mse: 0.0316Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 607ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 6/50\n",
      "\u001b[1m 92/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1074 - mse: 0.1074Epoch 1/50\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0251 - mse: 0.02\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1053 - mse: 0.1053\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0322 - mse: 0.0322\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - mse: 0.0253\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1365 - mse: 0.1365Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mse: 0.0396 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337 - mse: 0.0337 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0304 - mse: 0.03040\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0410 - mse: 0.0410\n",
      "\u001b[1m 96/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0221 - mse: 0.0221Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0221 - mse: 0.0221\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.1301 - mse: 0.1301Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0607 - mse: 0.0607 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0334 - mse: 0.033405\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 33/50\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.8063 - mse: 0.8063  \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0349 - mse: 0.0349\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0476 - mse: 0.0476   \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1320 - mse: 0.1320 \n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0419 - mse: 0.04192\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0310 - mse: 0.0310\n",
      "\u001b[1m 43/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0319 - mse: 0.0319Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.0203 \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4564 - mse: 0.4564\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.1159 - mse: 0.1159\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - mse: 0.0332\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214  Epoch 3/50\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0214 - mse: 0.0214Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0239 - mse: 0.0239\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - loss: 0.0219 - mse: 0.0219Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0805 - mse: 0.0805\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.0364 - mse: 0.0364\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0196 - mse: 0.0196\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.0254 - mse: 0.0254Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - loss: 0.0245 - mse: 0.0245 9\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - loss: 0.0258 - mse: 0.0258\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0365 - mse: 0.0365 Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 0.0364 - mse: 0.036451\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 0.0625 - mse: 0.0625\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - loss: 0.0331 - mse: 0.0331 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 0.0322 - mse: 0.0322 \n",
      "\u001b[1m 98/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0468 - mse: 0.0468 Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 0.0466 - mse: 0.0466\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0291 - mse: 0.0291Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0343 - mse: 0.0343\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - loss: 0.0836 - mse: 0.0836Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0354 - mse: 0.0354  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0483 - mse: 0.0483\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0377 - mse: 0.0377   \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0331 - mse: 0.0331\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0327 - mse: 0.03272\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - mse: 0.0236\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0429 - mse: 0.0429  \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mse: 0.0244\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 40/50\n",
      "\u001b[1m 95/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0334 - mse: 0.0334 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0337 - mse: 0.0337\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0268 - mse: 0.0268  \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0315 - mse: 0.0315\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0345 - mse: 0.034526 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0235 - mse: 0.02350\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0256 - mse: 0.02562\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - mse: 0.0210 Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0322 - mse: 0.0322  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0230 - mse: 0.0230318\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0324 - mse: 0.0324\n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - mse: 0.0204 Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - mse: 0.01973 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0239 - mse: 0.0239\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 43/50\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0311 - mse: 0.0311\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 17/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0326 - mse: 0.03261 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217 \n",
      "Epoch 39/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepep - loss: 0.0248 - mse: 0.02427\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 12/50\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0289 - mse: 0.0289[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.036 total time= 3.1min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 18/50\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0219 - mse: 0.0219 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mse: 0.0288\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0270 - mse: 0.0270  \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0292 - mse: 0.0292 \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0210 - mse: 0.0210\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 14/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0278 - mse: 0.0278 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0273 - mse: 0.0273\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0279 - mse: 0.0279  \n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0267 - mse: 0.0267 \n",
      "\u001b[1m 62/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 - mse: 0.0322Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mse: 0.03033\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.0222\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0121 - mse: 0.0121Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0237 - mse: 0.0237\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0207 - mse: 0.0207Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━��━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0285 - mse: 0.0285  \n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mse: 0.02429\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mse: 0.01890\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0236 - mse: 0.0236   \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.4698 - mse: 2.4698\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mse: 0.0195Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0245 - mse: 0.0245  \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - mse: 0.0291\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - mse: 0.0218  \n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - mse: 0.0176   \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 26/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepep - loss: 0.0219 - mse: 0.0219 \n",
      "\u001b[1m 30/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mse: 0.0188 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=16;, score=-0.054 total time= 3.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4251 - mse: 0.42516\n",
      "\u001b[1m 44/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - mse: 0.0292Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0219 - mse: 0.02195\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 27/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0265 - mse: 0.0265Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1867 - mse: 0.1867 \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - mse: 0.0212\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 361ms/step - loss: 0.0595 - mse: 0.0595Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━���━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1359 - mse: 0.1359\n",
      "\u001b[1m 63/105\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0227 - mse: 0.0227Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0186 - mse: 0.0186 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0227 - mse: 0.0227\n",
      "\u001b[1m 21/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0792 - mse: 3.0792 Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - loss: 0.0222 - mse: 0.022272\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 0.0230 - mse: 0.023029\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 23/50\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - loss: 1.7604 - mse: 1.7604\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - loss: 0.1178 - mse: 0.1178 \n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/stepep - loss: 0.0247 - mse: 0.024\n",
      "\u001b[1m 36/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0205 - mse: 0.0205 Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 23/50\n",
      "\u001b[1m  8/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 2s/step - loss: 0.2751 - mse: 0.2751  [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.059 total time= 3.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 0.0249 - mse: 0.0249 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - loss: 0.2174 - mse: 0.2174\n",
      "Epoch 3/50\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 0.0247 - mse: 0.0247Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0830 - mse: 0.08303\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mse: 0.0225 \n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0239 - mse: 0.0239\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1147 - mse: 0.1147\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0221 - mse: 0.0221\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0268 - mse: 0.0268   Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0713 - mse: 0.0713 \n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0265 - mse: 0.0265Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - mse: 0.0215\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 32/50\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepep - loss: 0.0204 - mse: 0.02\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 26/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.015 total time= 3.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1031s\u001b[0m 10s/step - loss: 0.0211 - mse: 0.02111\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 10s/step - loss: 0.0660 - mse: 0.06601\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 10s/step - loss: 0.0173 - mse: 0.017315 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 10s/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 33/50\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m23:27\u001b[0m 23s/step - loss: 0.0430 - mse: 0.0430Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - mse: 0.029922\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1033s\u001b[0m 10s/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0640 - mse: 0.06409\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1033s\u001b[0m 10s/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 27/50\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188 - mse: 0.0188  \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - mse: 0.0195       \n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0730 - mse: 0.0730\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1034s\u001b[0m 2ms/step - loss: 0.7153 - mse: 0.71530228 - mse: 0.022\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - mse: 0.0222  \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0629 - mse: 0.0629\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - mse: 0.0367- loss: 0.0160 - mse: 0.016\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0259 - mse: 0.0259 \n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1680 - mse: 0.1680\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - mse: 0.0200  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━���━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0589 - mse: 0.0589\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0384 - mse: 0.0384  ━━━━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0320 - mse: 0.03\n",
      "\u001b[1m 88/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0235 - mse: 0.0235Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0158 - mse: 0.0158\n",
      "\u001b[1m 28/105\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0189 - mse: 0.0189Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0237 - mse: 0.0237/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0151 - mse: 0.01\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 1.8742 - mse: 1.8742\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0903 - mse: 0.0903\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 7s/step - loss: 0.2051 - mse: 0.205178 \n",
      "\u001b[1m 79/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 10s/step - loss: 0.0184 - mse: 0.0184Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 7s/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 7s/step - loss: 0.0165 - mse: 0.0165\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 7s/step - loss: 0.0251 - mse: 0.0251\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 7s/step - loss: 0.0606 - mse: 0.0606\n",
      "\u001b[1m 49/105\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15:01\u001b[0m 16s/step - loss: 0.0608 - mse: 0.0608Epoch 41/50\n",
      "Epoch 32/50\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 7s/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 7s/step - loss: 0.0367 - mse: 0.03671435\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 7s/step - loss: 0.0629 - mse: 0.06295\n",
      "\u001b[1m 47/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - mse: 0.0216Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.1017 - mse: 0.1017 \n",
      "\u001b[1m100/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0185 - mse: 0.0185Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m 99/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0594 - mse: 0.0594Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0592 - mse: 0.0592\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0360 - mse: 0.0360\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0606 - mse: 0.0606\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0771 - mse: 0.0771Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0252 - mse: 0.02528\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0557 - mse: 0.0557\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0770 - mse: 0.0770\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 5/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0597 - mse: 0.0597 \n",
      "\u001b[1m 80/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0623 - mse: 0.0623Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0613 - mse: 0.0613\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0685 - mse: 0.0685 \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━��━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0520 - mse: 0.05202\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 14/50\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0543 - mse: 0.0543 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0622 - mse: 0.0622    \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0536 - mse: 0.0536\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0453 - mse: 0.0453Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0189 - mse: 0.0189\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0145 - mse: 0.0145Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0575 - mse: 0.0575\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0419 - mse: 0.0419Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "\u001b[1m 32/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0598 - mse: 0.0598 Epoch 46/50\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0476 - mse: 0.0476\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0587 - mse: 0.0587\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - mse: 0.0196 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173 - mse: 0.0173 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0501 - mse: 0.05010\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0315 - mse: 0.031580  \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0188 - mse: 0.018820\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0231 - mse: 0.0231\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - loss: 0.0481 - mse: 0.0481Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0476 - mse: 0.0476\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0482 - mse: 0.0482\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mse: 0.03231\n",
      "\u001b[1m 57/105\u001b[0m \u001b[32m━━━━━━━━━���\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0526 - mse: 0.0526Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━��━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0476 - mse: 0.04769\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0512 - mse: 0.0512  \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0218 - mse: 0.0218 \n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0522 - mse: 0.0522 \n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0206 - mse: 0.0206  \n",
      "\u001b[1m  9/105\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - mse: 0.0239  Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0181 - mse: 0.01818 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0335 - mse: 0.0335\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 21/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0187 - mse: 0.0187  \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - mse: 0.0240 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0484 - mse: 0.0484\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0181 - mse: 0.0181 \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 - mse: 0.013549\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepep - loss: 0.0164 - mse: 0.0164\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 50/50\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0538 - mse: 0.0538[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=32;, score=-0.044 total time=32.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0454 - mse: 0.0454\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0527 - mse: 0.0527\n",
      "\u001b[1m 69/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mse: 0.0167Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0446 - mse: 0.0446\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 43/50\n",
      "\u001b[1m 53/105\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0305 - mse: 0.0305Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - mse: 0.0169  \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - mse: 0.0167  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0128 - mse: 0.01286 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0456 - mse: 0.0456\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0436 - mse: 0.0436 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/steptep - loss: 0.0412 - mse: 0.041\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0412 - mse: 0.0412s: 0.0131 - mse: 0.0131\n",
      "Epoch 19/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.015 total time=32.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0498 - mse: 0.0498\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.0151 - mse: 0.0151Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 47/50\n",
      "\u001b[1m 38/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0479 - mse: 0.0479 Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167 - mse: 0.0167\n",
      "\u001b[1m 25/105\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0316 - mse: 0.0316Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0446 - mse: 0.04465\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0290 - mse: 0.0290   \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413 - mse: 0.0413 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - mse: 0.0412\n",
      "\u001b[1m103/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0475 - mse: 0.0475Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126  \n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0412 - mse: 0.0412\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0294 - mse: 0.029494\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0414 - mse: 0.0414  \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0423 - mse: 0.0423 6\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/stepp - loss: 0.0388 - mse: 0.03861  \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 0.7769 - mse: 0.7769\n",
      "Epoch 2/50\n",
      "\u001b[1m 73/105\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0157 - mse: 0.0157 [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.057 total time=32.3min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0396 - mse: 0.0396 \n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0383 - mse: 0.0383\n",
      "Epoch 24/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0285 - mse: 0.0285Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0160 - mse: 0.0160\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.0449 - mse: 0.0449\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 446ms/step - loss: 11.8098 - mse: 11.8098Epoch 50/50\n",
      "\u001b[1m 94/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:15\u001b[0m 18s/step - loss: 0.7222 - mse: 0.7222Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1656s\u001b[0m 16s/step - loss: 0.6873 - mse: 0.687376 \n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 16s/step - loss: 0.0298 - mse: 0.029894 \n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 16s/step - loss: 0.1280 - mse: 0.1280\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 16s/step - loss: 0.0410 - mse: 0.0410\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 16s/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - mse: 0.015887\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 16s/step - loss: 1.9182 - mse: 1.9182\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1219 - mse: 0.1219\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0763 - mse: 0.0763\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mse: 0.0399\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0781 - mse: 0.0781\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 4/50\n",
      "Epoch 38/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/stepep - loss: 0.0393 - mse: 0.039\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - loss: 0.0312 - mse: 0.0312[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=3, model__neurons=64;, score=-0.030 total time=58.8min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0393 - mse: 0.0393\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1808 - mse: 0.1808\n",
      "Epoch 3/50\n",
      "\u001b[1m  5/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0421 - mse: 0.0421  Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0312 - mse: 0.0312 \n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0364 - mse: 0.0364\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0374 - mse: 0.052- mse: 0.0374\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0424 - mse: 0.0424\n",
      "\u001b[1m 91/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0589 - mse: 0.0589Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0588 - mse: 0.0588 \n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0433 - mse: 0.0433   \n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0901 - mse: 0.0901   \n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mse: 0.0282  p - loss: 0.0348 - mse: 0.034\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0456 - mse: 0.0456\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - mse: 0.0408\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0291 - mse: 0.0291Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0690 - mse: 0.06909\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0270 - mse: 0.027028\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0489 - mse: 0.04898082 - mse: 0.008\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0358 - mse: 0.0358[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0557 - mse: 0.055\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0247 - mse: 0.0247 \n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0559 - mse: 0.0559\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mse: 0.0382  \n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0434 - mse: 0.04342\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0363 - mse: 0.0363\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0451 - mse: 0.045151 \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0259 - mse: 0.02597\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m��━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0384 - mse: 0.03841/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0365 - mse: 0.03\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0422 - mse: 0.0422\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mse: 0.0324\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0466 - mse: 0.0466 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0481 - mse: 0.0481�━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0440 - mse: 0.04\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - loss: 0.7677 - mse: 0.7677\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 2/50\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0346 - mse: 0.034mse: 0.0422━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0373 - mse: 0.0373\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0477 - mse: 0.0477\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0321 - mse: 0.0321\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━��━━━━━━━━━━━━\u001b[0m \u001b[1m6:55\u001b[0m 4s/step - loss: 0.0645 - mse: 0.0645  Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0469 - mse: 0.0469 4 \n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0379 - mse: 0.0379\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 33/50\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0423 - mse: 0.0423\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.1283 - mse: 0.1283\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0316 - mse: 0.0316Epoch 33/50\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0305 - mse: 0.03059 \n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 10s/step - loss: 0.0446 - mse: 0.04466\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 272ms/step - loss: 0.0294 - mse: 0.02\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 10s/step - loss: 0.0462 - mse: 0.0462\n",
      "\u001b[1m 86/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:00\u001b[0m 13s/step - loss: 0.0629 - mse: 0.0629Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 10s/step - loss: 0.0349 - mse: 0.0349\n",
      "\u001b[1m 14/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - loss: 0.0249 - mse: 0.0249Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 10s/step - loss: 0.0339 - mse: 0.0339\n",
      "\u001b[1m 84/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:32\u001b[0m 13s/step - loss: 0.0261 - mse: 0.0261Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1076s\u001b[0m 10s/step - loss: 0.0616 - mse: 0.0616\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1076s\u001b[0m 10s/step - loss: 0.0263 - mse: 0.0263\n",
      "\u001b[1m 34/105\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0265 - mse: 0.0265Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - loss: 0.0402 - mse: 0.04021\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1311s\u001b[0m 13s/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1311s\u001b[0m 2s/step - loss: 0.0273 - mse: 0.0273\n",
      "\u001b[1m 75/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 3s/step - loss: 0.0481 - mse: 0.0481Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - loss: 0.0385 - mse: 0.0385\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━��━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 47/50\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0392 - mse: 0.0392\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0264 - mse: 0.0264\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 14/50\n",
      "Epoch 36/50\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0360 - mse: 0.0360\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0369 - mse: 0.0369\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0264 - mse: 0.0264 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.0351 - mse: 0.0351\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mse: 0.0337\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.0151 - mse: 0.0151Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mse: 0.0379\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0325 - mse: 0.0325  \n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0273 - mse: 0.02731\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0286 - mse: 0.02860  ━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0349 - mse: 0.03\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0425 - mse: 0.0425\n",
      "\u001b[1m 37/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.0367 - mse: 0.0367Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0355 - mse: 0.0355\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0253 - mse: 0.0253 \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0363 - mse: 0.0363\n",
      "\u001b[1m 20/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0220 - mse: 0.0220Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - loss: 0.0399 - mse: 0.0399/step - loss: 0.0320 - mse: 0.03\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0364 - mse: 0.0364\n",
      "\u001b[1m 89/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0248 - mse: 0.0248Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0249 - mse: 0.0249\n",
      "\u001b[1m 15/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.0231 - mse: 0.0231Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0281 - mse: 0.0281 \n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0410 - mse: 0.0410\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0340 - mse: 0.0340\n",
      "\u001b[1m 45/105\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0243 - mse: 0.0243Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0282 - mse: 0.0282 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 40/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0350 - mse: 0.0350[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.026 total time=80.9min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 18/50\n",
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0315 - mse: 0.0315\n",
      "\u001b[1m 11/105\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0209 - mse: 0.0209 Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mse: 0.0375\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mse: 0.0348 \n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mse: 0.024769\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0366 - mse: 0.0366\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0335 - mse: 0.0335\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0398 - mse: 0.0398\n",
      "Epoch 43/50\n",
      "\u001b[1m 85/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0314 - mse: 0.0314Epoch 43/50\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0257 - mse: 0.0257\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0253 - mse: 0.02537 \n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mse: 0.0349\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mse: 0.0320\n",
      "\u001b[1m101/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.9659 - mse: 0.9659Epoch 44/50\n",
      "Epoch 44/50\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mse: 0.0341\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━��━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0321 - mse: 0.0321\n",
      "\u001b[1m102/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.9613 - mse: 0.9613Epoch 21/50\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 0.9437 - mse: 0.9437\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0324 - mse: 0.0320242 \n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.069 total time=81.0min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - loss: 0.0244 - mse: 0.0244 \n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0318 - mse: 0.0318\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mse: 0.0240\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0337 - mse: 0.0337 \n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - mse: 0.024838\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mse: 0.023638\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0312 - mse: 0.0312\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.0403 - mse: 0.0403Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 17/50\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0338 - mse: 0.0338\n",
      "\u001b[1m 41/105\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0376 - mse: 0.0376 Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0395 - mse: 0.0395\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0292 - mse: 0.0292 \n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mse: 0.02261\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━���━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mse: 0.0349\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mse: 0.0217\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0149 - mse: 0.0149Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - mse: 0.022213\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0313 - mse: 0.0313  \n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 21/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - loss: 0.0419 - mse: 0.041\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━��\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0242 - mse: 0.0242[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=16;, score=-0.075 total time=80.7min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300 - mse: 0.0300\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mse: 0.02093\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0232 - mse: 0.0232 6\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0223 - mse: 0.02236\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0231 - mse: 0.023169\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.0196 - mse: 0.0196Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - mse: 0.020351\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mse: 0.0191 2\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 26/50\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216 - mse: 0.02167\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mse: 0.0230 \n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0317 - mse: 0.03175\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260 8\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mse: 0.027569\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0206 - mse: 0.0206\n",
      "\u001b[1m 17/105\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0251 - mse: 0.0251Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - mse: 0.02022\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mse: 0.0216 5 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mse: 0.0295\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264 - mse: 0.0264 \n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0261 - mse: 0.0261 \n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0204 - mse: 0.0204 \n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━���━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mse: 0.0349\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0281 - mse: 0.0281 \n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0333 - mse: 0.0333\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 45/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/steposs: 0.0119 - mse: 0.01: 0.0227\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 47/50\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.020 total time=80.8min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - mse: 0.0284  \n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - mse: 0.0268 \n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - mse: 0.0240 \n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0284 - mse: 0.0284\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.0195 - mse: 0.0195\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0260 - mse: 0.0260\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0265 - mse: 0.0265\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step\n",
      "Epoch 49/50\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:54\u001b[0m 3s/step - loss: 0.1208 - mse: 0.1208  [CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.064 total time=50.5min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - loss: 0.1367 - mse: 0.1367\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0638 - mse: 0.0638\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0251 - mse: 0.0251\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.0501 - mse: 0.0501\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.0491 - mse: 0.0491\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 46/50\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=32;, score=-0.054 total time=50.5min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 0.0416 - mse: 0.0416\n",
      "\u001b[1m  2/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:26\u001b[0m 22s/step - loss: 0.0256 - mse: 0.0256Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/stepep - loss: 0.0171 - mse: 0.01  \n",
      "\u001b[1m 58/105\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0418 - mse: 0.0418[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=64;, score=-0.019 total time=50.7min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 217ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.0365 - mse: 0.0365\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mse: 0.0338\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0151 - mse: 0.0151\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 13/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step 0.0168 - mse: 0.016\n",
      "[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=64;, score=-0.065 total time=23.2min\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mse: 0.0303\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.0287 - mse: 0.0287\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0272 - mse: 0.0272 \n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0233 - mse: 0.0233\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━��━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mse: 0.0201 \n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 0.0229 - mse: 0.0229\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 49/50\n",
      "\u001b[1m  1/105\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0313 - mse: 0.0313Epoch 1/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.2057 - mse: 0.2057\n",
      "Epoch 2/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0484 - mse: 0.0484\n",
      "Epoch 3/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0312 - mse: 0.0312\n",
      "Epoch 4/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 5/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 6/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 7/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 8/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 9/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 10/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 11/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 12/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 13/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 14/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 15/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 16/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 17/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 18/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 20/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 21/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 22/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 23/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 24/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 25/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 26/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 27/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 28/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 29/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 30/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 31/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 32/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 33/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 34/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 35/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 36/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 37/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 38/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 39/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 40/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 41/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 42/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 43/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 44/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 46/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 47/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 48/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 49/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 50/50\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.0067 - mse: 0.0067\n",
      "Best Parameters: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.2, 'model__layers': 2, 'model__neurons': 64}\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step\n",
      "In-sample R²: 0.9170\n",
      "In-sample RMSE: 0.0680\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209us/step\n",
      "Out-of-sample R²: 0.4134\n",
      "Out-of-sample RMSE: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.0202 - mse: 0.0202\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=4, model__neurons=64;, score=-0.032 total time=  54.3s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Set the seed before training\n",
    "set_seed(42)\n",
    "\n",
    "# Define the model function with variable neurons, layers, and dropout rate\n",
    "def create_model(input_dim, neurons=32, layers=1, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    # Input layer using Input instead of input_dim argument\n",
    "    model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Wrapping the model in KerasRegressor\n",
    "def create_keras_regressor(input_dim):\n",
    "    return KerasRegressor(model=create_model, input_dim=input_dim, verbose=1)  # Set verbose=1 for model fit\n",
    "\n",
    "# Define the parameter grid for trials\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64],    # Number of neurons in each hidden layer\n",
    "    'model__layers': [1,2,3,4],        # Number of hidden layers\n",
    "    'model__dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "    'batch_size': [32],                   # Batch size for training\n",
    "    'epochs': [50],                       # Number of epochs\n",
    "}\n",
    "\n",
    "# param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.5], 'model__layers': [1], 'model__neurons': [16]} # Put\n",
    "# param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [64]} # Call\n",
    "# Function to perform hyperparameter tuning, retrain the model, and test\n",
    "def train_and_evaluate( combined_x, combined_y, test_x, test_y):\n",
    "    # Get input dimension from the training data\n",
    "    input_dim = combined_x.shape[1]\n",
    "    \n",
    "    # Create KerasRegressor with the correct input dimension\n",
    "    model = create_keras_regressor(input_dim)\n",
    "\n",
    "    # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "                               verbose=3,\n",
    "                               cv=3, \n",
    "                               n_jobs=-1)  # Verbose=3 for detailed progress tracking\n",
    "\n",
    "    # Hyperparameter tuning using validation data\n",
    "    print(\"Running hyperparameter tuning with validation data...\")\n",
    "    grid_search.fit(combined_x, combined_y,\n",
    "                    verbose=1)\n",
    "\n",
    "    # Get the best estimator and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    # In-sample evaluation on the combined training and validation set\n",
    "    predictions_combined = best_model.predict(combined_x)\n",
    "\n",
    "    r2_combined = r2_score(combined_y, predictions_combined)\n",
    "    rmse_combined = np.sqrt(mean_squared_error(combined_y, predictions_combined))\n",
    "    \n",
    "    print(f\"In-sample R²: {r2_combined:.4f}\")\n",
    "    print(f\"In-sample RMSE: {rmse_combined:.4f}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions_test = best_model.predict(test_x)\n",
    "\n",
    "    # Out-of-sample evaluation on the test set\n",
    "    r2_test = r2_score(test_y, predictions_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_y, predictions_test))\n",
    "\n",
    "    print(f\"Out-of-sample R²: {r2_test:.4f}\")\n",
    "    print(f\"Out-of-sample RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Call the function for Call options data\n",
    "print(\"\\nEvaluating Call options...\")\n",
    "best_model_call = train_and_evaluate(combined_x_c, combined_y_c, test_x_c, test_y_c)\n",
    "\n",
    "# # Call the function for Put options data\n",
    "# print(\"\\nEvaluating Put options...\")\n",
    "# best_model_put = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Call options...\n",
      "Running hyperparameter tuning for Call Model...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.6407 - mse: 0.6407 \n",
      "Epoch 2/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 1.6090 - mse: 1.6090\n",
      "Epoch 2/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.9213 - mse: 0.9213\n",
      "Epoch 2/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0611 - mse: 0.0611\n",
      "Epoch 3/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 0.1225 - mse: 0.1225\n",
      "Epoch 3/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0720 - mse: 0.0720\n",
      "Epoch 3/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - loss: 0.0556 - mse: 0.0556\n",
      "Epoch 4/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - loss: 0.0613 - mse: 0.0613\n",
      "Epoch 4/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - loss: 0.0597 - mse: 0.0597\n",
      "Epoch 4/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step - loss: 0.0509 - mse: 0.0509\n",
      "Epoch 5/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380us/step - loss: 0.0563 - mse: 0.0563\n",
      "Epoch 5/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 5/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363us/step - loss: 0.0556 - mse: 0.0556\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - loss: 0.0245 - mse: 0.0245\n",
      "Epoch 6/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387us/step - loss: 0.0557 - mse: 0.0557\n",
      "Epoch 7/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 7/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 7/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 0.0548 - mse: 0.0548\n",
      "Epoch 8/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0513 - mse: 0.0513\n",
      "Epoch 8/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 8/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - loss: 0.0537 - mse: 0.0537\n",
      "Epoch 9/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442us/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 9/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 9/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 10/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 10/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 10/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 11/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 0.0502 - mse: 0.0502\n",
      "Epoch 11/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 11/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 12/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 12/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 12/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0533 - mse: 0.0533\n",
      "Epoch 13/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 13/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 13/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 14/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 14/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 14/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360us/step - loss: 0.0539 - mse: 0.0539\n",
      "Epoch 15/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 15/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 15/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329us/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 16/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 16/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 16/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 0.0516 - mse: 0.0516\n",
      "Epoch 17/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 17/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 17/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 18/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 18/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 18/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.0534 - mse: 0.0534\n",
      "Epoch 19/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 19/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 19/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390us/step - loss: 0.0529 - mse: 0.0529\n",
      "Epoch 20/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 20/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 20/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 21/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0506 - mse: 0.0506\n",
      "Epoch 21/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 21/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 22/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 22/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 22/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 23/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 23/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 23/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 0.0506 - mse: 0.0506\n",
      "Epoch 24/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 24/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 24/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 25/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0498 - mse: 0.0498\n",
      "Epoch 25/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 25/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 26/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 26/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 26/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346us/step - loss: 0.0518 - mse: 0.0518\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 27/50\n",
      "Epoch 27/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 27/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 28/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 28/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 28/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 29/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 29/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 29/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 30/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 0.0507 - mse: 0.0507\n",
      "Epoch 30/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 30/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382us/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 31/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 0.0491 - mse: 0.0491\n",
      "Epoch 31/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 31/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0521 - mse: 0.0521\n",
      "Epoch 32/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 32/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 32/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 33/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 33/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 33/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 34/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 34/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349us/step - loss: 0.0206 - mse: 0.0206 \n",
      "Epoch 34/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 35/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 35/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 35/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 36/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0497 - mse: 0.0497\n",
      "Epoch 36/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 36/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 37/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - loss: 0.0493 - mse: 0.0493\n",
      "Epoch 37/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 37/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 38/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 38/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 38/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 39/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 39/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 39/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 40/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 40/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 40/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 41/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 41/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 41/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 42/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 42/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 42/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 43/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0502 - mse: 0.0502\n",
      "Epoch 43/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 43/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 44/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 44/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 44/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 45/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 45/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0203 - mse: 0.0203\n",
      "\u001b[1m 593/1508\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.0518 - mse: 0.0518Epoch 45/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 46/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 0.0509 - mse: 0.0509\n",
      "Epoch 46/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 46/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0532 - mse: 0.0532\n",
      "Epoch 47/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0497 - mse: 0.0497\n",
      "Epoch 47/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 47/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 48/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 48/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 48/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 49/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382us/step - loss: 0.0502 - mse: 0.0502\n",
      "Epoch 49/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 49/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 50/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - loss: 0.0498 - mse: 0.0498\n",
      "Epoch 50/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 50/50\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0505 - mse: 0.0505\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0504 - mse: 0.0504\n",
      "\u001b[1m1508/1508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0210 - mse: 0.0210\n",
      "\u001b[1m754/754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step\n",
      "\u001b[1m754/754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step\n",
      "\u001b[1m202/754\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 249us/step[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.019 total time=  29.2s\n",
      "\u001b[1m445/754\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 225us/step[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.075 total time=  29.3s\n",
      "\u001b[1m754/754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.116 total time=  29.4s\n",
      "Epoch 1/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304us/step - loss: 0.3798 - mse: 0.3798\n",
      "Epoch 2/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 3/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298us/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 4/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 5/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 6/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 7/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 8/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 9/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 10/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 11/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 12/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 13/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 14/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 15/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 16/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 17/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 18/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 19/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 20/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 21/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 22/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 23/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 24/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 25/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 26/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 27/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 28/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 29/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 30/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 31/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 32/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 33/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 34/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 35/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 36/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 37/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 38/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 39/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308us/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 40/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 41/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 42/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 43/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 44/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 45/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324us/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 46/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 47/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 48/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 49/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 50/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - loss: 0.0430 - mse: 0.0430\n",
      "Best Parameters for Call Model: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.5, 'model__layers': 1, 'model__neurons': 16}\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/wn87d6495j1_vytb8m33q3mm0000gn/T/ipykernel_18772/1964460253.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  nw_std_error = ols_model.bse[0]  # Newey-West standard error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Model Newey-West Standard Error: 0.0010\n",
      "\n",
      "Evaluating Put options...\n",
      "Running hyperparameter tuning for Put Model...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - loss: 0.6656 - mse: 0.6656\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0620 - mse: 0.0620\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - loss: 0.0570 - mse: 0.0570\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - loss: 0.0554 - mse: 0.0554\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329us/step - loss: 0.0573 - mse: 0.0573\n",
      "Epoch 6/50\n",
      "\u001b[1m 336/1521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 300us/step - loss: 0.0541 - mse: 0.0541Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - loss: 0.0535 - mse: 0.0535  \n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - loss: 0.8271 - mse: 0.8271\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - loss: 1.4350 - mse: 1.4350\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 0.1295 - mse: 0.1295\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - loss: 0.0536 - mse: 0.0536\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - loss: 0.0706 - mse: 0.0706\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387us/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - loss: 0.0621 - mse: 0.0621\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 6/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - loss: 0.0602 - mse: 0.0602\n",
      "Epoch 6/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - loss: 0.0580 - mse: 0.0580\n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - loss: 0.0540 - mse: 0.0540\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 0.0576 - mse: 0.0576\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 0.0537 - mse: 0.0537\n",
      "Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - loss: 0.0585 - mse: 0.0585\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 907us/step - loss: 0.0221 - mse: 0.0221\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - loss: 0.0575 - mse: 0.0575\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351us/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - loss: 0.0574 - mse: 0.0574\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - loss: 0.0561 - mse: 0.0561\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - loss: 0.0533 - mse: 0.0533\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - loss: 0.0569 - mse: 0.0569\n",
      "Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0531 - mse: 0.0531\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - loss: 0.0566 - mse: 0.0566\n",
      "Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0572 - mse: 0.0572\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - loss: 0.0536 - mse: 0.0536\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432us/step - loss: 0.0513 - mse: 0.0513\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 0.0541 - mse: 0.0541\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 0.0558 - mse: 0.0558\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 0.0544 - mse: 0.0544\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 0.0565 - mse: 0.0565\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364us/step - loss: 0.0547 - mse: 0.0547\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349us/step - loss: 0.0551 - mse: 0.0551\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358us/step - loss: 0.0546 - mse: 0.0546\n",
      "Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 0.0525 - mse: 0.0525\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - loss: 0.0549 - mse: 0.0549\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380us/step - loss: 0.0547 - mse: 0.0547\n",
      "Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0213 - mse: 0.0213\n",
      "\u001b[1m1228/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.0535 - mse: 0.0535Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - loss: 0.0534 - mse: 0.0534\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - loss: 0.0541 - mse: 0.0541\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - loss: 0.0551 - mse: 0.0551\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - loss: 0.0538 - mse: 0.0538\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0552 - mse: 0.0552\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 0.0525 - mse: 0.0525\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0554 - mse: 0.0554\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0523 - mse: 0.0523\n",
      "\u001b[1m 694/1521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.0531 - mse: 0.0531Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step - loss: 0.0542 - mse: 0.0542\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347us/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 45/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.0549 - mse: 0.0549\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - loss: 0.0534 - mse: 0.0534\n",
      "Epoch 46/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - loss: 0.0546 - mse: 0.0546\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - loss: 0.0562 - mse: 0.0562\n",
      "Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0576 - mse: 0.0576\n",
      "Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358us/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351us/step - loss: 0.0547 - mse: 0.0547\n",
      "Epoch 45/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362us/step - loss: 0.0214 - mse: 0.0214\n",
      "\u001b[1m 267/1521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 0.0572 - mse: 0.0572Epoch 45/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - loss: 0.0507 - mse: 0.0507\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/stepep - loss: 0.0213 - mse: 0.026\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 0.0564 - mse: 0.0564\n",
      "Epoch 46/50\n",
      "\u001b[1m1283/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 0.0212 - mse: 0.0212[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.059 total time=  37.8s\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 46/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - loss: 0.0539 - mse: 0.0539\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - loss: 0.0567 - mse: 0.0567\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - loss: 0.0555 - mse: 0.0555\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 0.0221 - mse: 0.0221\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.017 total time=  37.0s\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.5, model__layers=1, model__neurons=16;, score=-0.090 total time=  37.1s\n",
      "Epoch 1/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - loss: 0.6023 - mse: 0.6023\n",
      "Epoch 2/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 3/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - loss: 0.0473 - mse: 0.0473\n",
      "Epoch 4/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 5/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282us/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 6/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 7/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338us/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 8/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 9/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 10/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 11/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 12/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 13/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 14/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - loss: 0.0448 - mse: 0.0448\n",
      "Epoch 15/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - loss: 0.0446 - mse: 0.0446\n",
      "Epoch 16/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 17/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 18/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 19/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 20/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 0.0447 - mse: 0.0447\n",
      "Epoch 21/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 22/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 23/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351us/step - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 24/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 25/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 26/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - loss: 0.0447 - mse: 0.0447\n",
      "Epoch 27/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 28/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 29/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - loss: 0.0436 - mse: 0.0436\n",
      "Epoch 30/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 31/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 32/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 33/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 34/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 35/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 36/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 37/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 38/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 39/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 40/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 41/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 42/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 43/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 44/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 45/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 46/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0446 - mse: 0.0446\n",
      "Epoch 47/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 48/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 49/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 50/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0439 - mse: 0.0439\n",
      "Best Parameters for Put Model: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.5, 'model__layers': 1, 'model__neurons': 16}\n",
      "\u001b[1m1105/1105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n",
      "Put Model Newey-West Standard Error: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/wn87d6495j1_vytb8m33q3mm0000gn/T/ipykernel_18772/1964460253.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  nw_std_error = ols_model.bse[0]  # Newey-West standard error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test errors and Newey-West statistics saved to /Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Notebooks/performence_evaluation/dm_test_errors_nn.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Set the seed before training\n",
    "set_seed(42)\n",
    "\n",
    "# Function to calculate Newey-West standard error\n",
    "def newey_west_standard_error(errors, lag=1):\n",
    "    \"\"\"\n",
    "    Computes the Newey-West standard error for the series of prediction errors.\n",
    "    \n",
    "    Parameters:\n",
    "    - errors: Array-like of prediction errors\n",
    "    - lag: Maximum lag to use for the Newey-West estimator (default is 1)\n",
    "    \n",
    "    Returns:\n",
    "    - Newey-West standard error of the prediction errors\n",
    "    \"\"\"\n",
    "    X = np.ones(len(errors))  # Constant term for OLS\n",
    "    ols_model = sm.OLS(errors, X).fit(cov_type='HAC', cov_kwds={'maxlags': lag})\n",
    "    nw_std_error = ols_model.bse[0]  # Newey-West standard error\n",
    "    return nw_std_error\n",
    "\n",
    "# Define the model function with variable neurons, layers, and dropout rate\n",
    "def create_model(input_dim, neurons=32, layers=1, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))  # Input layer\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout after the first hidden layer\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))  # Regression output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Wrapping the model in KerasRegressor\n",
    "def create_keras_regressor(input_dim):\n",
    "    return KerasRegressor(model=create_model, input_dim=input_dim, verbose=1)\n",
    "\n",
    "# Function to train the model and calculate Newey-West errors\n",
    "def train_and_evaluate(train_x, train_y, combined_x, combined_y, test_x, test_y, model_name):\n",
    "    # Get input dimension from the training data\n",
    "    input_dim = combined_x.shape[1]\n",
    "    \n",
    "    # Create KerasRegressor\n",
    "    model = create_keras_regressor(input_dim)\n",
    "\n",
    "    # Initialize GridSearchCV with the model and parameter grid\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "                               verbose=3,\n",
    "                               cv=3, \n",
    "                               n_jobs=-1)\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    print(f\"Running hyperparameter tuning for {model_name}...\")\n",
    "    grid_search.fit(combined_x, combined_y, verbose=1)\n",
    "\n",
    "    # Get the best estimator and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best Parameters for {model_name}: {best_params}\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    predictions_test = best_model.predict(test_x)\n",
    "\n",
    "    # Calculate test errors and Newey-West standard error\n",
    "    errors_test = test_y - predictions_test\n",
    "    nw_std_error = newey_west_standard_error(errors_test, lag=1)\n",
    "\n",
    "    print(f\"{model_name} Newey-West Standard Error: {nw_std_error:.4f}\")\n",
    "\n",
    "    return errors_test, nw_std_error\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.5], 'model__layers': [1], 'model__neurons': [16]}\n",
    "\n",
    "# Call the function for Call options data\n",
    "print(\"\\nEvaluating Call options...\")\n",
    "calls_errors, calls_nw_std_error = train_and_evaluate(train_x_c, train_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c, \"Call Model\")\n",
    "\n",
    "# Call the function for Put options data\n",
    "print(\"\\nEvaluating Put options...\")\n",
    "puts_errors, puts_nw_std_error = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p, \"Put Model\")\n",
    "\n",
    "# Pad the shorter error list with zeros to ensure both lists have the same length\n",
    "max_length = max(len(puts_errors), len(calls_errors))\n",
    "\n",
    "puts_errors_padded = np.pad(puts_errors, (0, max_length - len(puts_errors)), 'constant', constant_values=0)\n",
    "calls_errors_padded = np.pad(calls_errors, (0, max_length - len(calls_errors)), 'constant', constant_values=0)\n",
    "\n",
    "# Save the results to a DataFrame and CSV\n",
    "dm_test_data = pd.DataFrame({\n",
    "    'Put Errors': puts_errors_padded,\n",
    "    'Call Errors': calls_errors_padded,\n",
    "    'Put Newey-West Std Error': [puts_nw_std_error] * max_length,  # Constant value for all rows\n",
    "    'Call Newey-West Std Error': [calls_nw_std_error] * max_length  # Constant value for all rows\n",
    "})\n",
    "\n",
    "# Specify the file path for the CSV\n",
    "file_path = '/Users/sbjpipers/Desktop/FinalThesisQF/FinalThesisQF/Notebooks/performence_evaluation/dm_test_errors_nn.csv'\n",
    "\n",
    "# Save the DataFrame to the specified path\n",
    "dm_test_data.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Test errors and Newey-West statistics saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras import regularizers\n",
    "# from keras.layers import Dense, Dropout, Input\n",
    "# from keras.models import Sequential\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from keras.optimizers import RMSprop\n",
    "# import tensorflow as tf\n",
    "# import random\n",
    "\n",
    "# # Set random seeds for reproducibility\n",
    "# def set_seed(seed=42):\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "\n",
    "# # Set the seed before training\n",
    "# set_seed(42)\n",
    "\n",
    "# # Define the model function with variable neurons, layers, and dropout rate\n",
    "# def create_model(input_dim, neurons=32, layers=1, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     # Input layer using Input instead of input_dim argument\n",
    "#     model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "#     # First hidden layer\n",
    "#     model.add(Dense(neurons, activation='relu'))\n",
    "#     model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "#     # Additional hidden layers\n",
    "#     for _ in range(layers - 1):\n",
    "#         model.add(Dense(neurons, activation='relu'))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer\n",
    "#     model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "#                   loss='mean_squared_error',\n",
    "#                   metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "# # Wrapping the model in KerasRegressor\n",
    "# def create_keras_regressor(input_dim):\n",
    "#     return KerasRegressor(model=create_model, input_dim=input_dim, verbose=1)  # Set verbose=1 for model fit\n",
    "\n",
    "# # Define the parameter grid for trials\n",
    "# param_grid = {\n",
    "#     'model__neurons': [16, 32, 64],    # Number of neurons in each hidden layer\n",
    "#     'model__layers': [1,2,3,4],        # Number of hidden layers\n",
    "#     'model__dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "#     'batch_size': [32],                   # Batch size for training\n",
    "#     'epochs': [50],                       # Number of epochs\n",
    "# }\n",
    "\n",
    "# # param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [32]} # Put\n",
    "# # param_grid = {'batch_size': [32], 'epochs': [50], 'model__dropout_rate': [0.2], 'model__layers': [2], 'model__neurons': [32]} # Call\n",
    "\n",
    "# # Function to perform hyperparameter tuning, retrain the model, and test\n",
    "# def train_and_evaluate(train_x, train_y, combined_x, combined_y, test_x, test_y):\n",
    "#     # Get input dimension from the training data\n",
    "#     input_dim = combined_x.shape[1]\n",
    "    \n",
    "#     # Create KerasRegressor with the correct input dimension\n",
    "#     model = create_keras_regressor(input_dim)\n",
    "\n",
    "#     # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "#     grid_search = GridSearchCV(estimator=model,\n",
    "#                                param_grid=param_grid,\n",
    "#                                scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "#                                verbose=3,\n",
    "#                                cv=5, \n",
    "#                                n_jobs=-1)  # Verbose=3 for detailed progress tracking\n",
    "\n",
    "#     # Hyperparameter tuning using validation data\n",
    "#     print(\"Running hyperparameter tuning with validation data...\")\n",
    "#     grid_search.fit(combined_x, combined_y,\n",
    "#                     verbose=1)\n",
    "\n",
    "#     # Get the best estimator and parameters\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "#     # In-sample evaluation on the combined training and validation set\n",
    "#     predictions_combined = best_model.predict(combined_x)\n",
    "\n",
    "#     r2_combined = r2_score(combined_y, predictions_combined)\n",
    "#     rmse_combined = np.sqrt(mean_squared_error(combined_y, predictions_combined))\n",
    "    \n",
    "#     print(f\"In-sample R²: {r2_combined:.4f}\")\n",
    "#     print(f\"In-sample RMSE: {rmse_combined:.4f}\")\n",
    "\n",
    "#     # Make predictions on the test set\n",
    "#     predictions_test = best_model.predict(test_x)\n",
    "\n",
    "#     # Out-of-sample evaluation on the test set\n",
    "#     r2_test = r2_score(test_y, predictions_test)\n",
    "#     rmse_test = np.sqrt(mean_squared_error(test_y, predictions_test))\n",
    "\n",
    "#     print(f\"Out-of-sample R²: {r2_test:.4f}\")\n",
    "#     print(f\"Out-of-sample RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "#     return best_model\n",
    "\n",
    "# # Call the function for Call options data\n",
    "# print(\"\\nEvaluating Call options...\")\n",
    "# best_model_call = train_and_evaluate(train_x_c, train_y_c, combined_x_c, combined_y_c, test_x_c, test_y_c)\n",
    "\n",
    "# # # Call the function for Put options data\n",
    "# # print(\"\\nEvaluating Put options...\")\n",
    "# # best_model_put = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x17532a8e0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=10\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=1\n",
       "\tmodel__neurons=32\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x17532a8e0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=10\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=1\n",
       "\tmodel__neurons=32\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=<function create_model at 0x17532a8e0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=10\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=1\n",
       "\tmodel__neurons=32\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "results_c = permutation_importance(best_model_call, combined_x_c, combined_y_c, n_repeats=1, random_state=42) #NEW\n",
    "    # Get the feature importances and feature names\n",
    "importance = results_c.importances_mean #NEW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x332e80c20&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=30\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function create_model at 0x332e80c20&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=30\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=<function create_model at 0x332e80c20>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tinput_dim=30\n",
       "\tmodel__dropout_rate=0.5\n",
       "\tmodel__layers=2\n",
       "\tmodel__neurons=32\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step\n",
      "Mean Squared Error (MSE): 0.028032797160525903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.756283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.191636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CLOSE_vix</td>\n",
       "      <td>0.170249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.164074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.091177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.064454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LOW_vix</td>\n",
       "      <td>0.053092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.037955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.035771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASK</td>\n",
       "      <td>0.032649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.028910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HIGH_vix</td>\n",
       "      <td>0.023458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume_option</td>\n",
       "      <td>0.022929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRC_actual</td>\n",
       "      <td>0.022223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.017977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.011096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spread_stock</td>\n",
       "      <td>0.010428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spread_option</td>\n",
       "      <td>0.009768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5_day_rolling_return_stock</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RET</td>\n",
       "      <td>0.001572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>daily_return_indicator_stock</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moneyness</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vol_stock</td>\n",
       "      <td>-0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature  importance\n",
       "3                    prev_day_iv    0.756283\n",
       "17                       2Y_bond    0.191636\n",
       "18                     CLOSE_vix    0.170249\n",
       "16                       1Y_bond    0.164074\n",
       "0                              T    0.091177\n",
       "2                   prev2_day_iv    0.064454\n",
       "21                       LOW_vix    0.053092\n",
       "10             cumulative_return    0.037955\n",
       "15                       10Y_RIR    0.035771\n",
       "7                            ASK    0.032649\n",
       "19                       FF_rate    0.028910\n",
       "20                      HIGH_vix    0.023458\n",
       "5                  volume_option    0.022929\n",
       "8                     PRC_actual    0.022223\n",
       "22                      OPEN_vix    0.022017\n",
       "23                    gold_price    0.017977\n",
       "25                    spread_vix    0.011096\n",
       "13                  spread_stock    0.010428\n",
       "4                  spread_option    0.009768\n",
       "12                   hi-lo_stock    0.002408\n",
       "6     5_day_rolling_return_stock    0.002233\n",
       "9                            RET    0.001572\n",
       "24                    reces_indi    0.001191\n",
       "11  daily_return_indicator_stock    0.000870\n",
       "1                      moneyness    0.000804\n",
       "14                     vol_stock   -0.000127"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get predictions\n",
    "pred_y = best_model_call.predict(combined_x_c)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_score = mean_squared_error(combined_y_c, pred_y)\n",
    "\n",
    "# Assuming 'importance' is a list or array of feature importances\n",
    "# Create a DataFrame with feature importance scores\n",
    "feature_importance_networks = pd.DataFrame({\n",
    "    'feature': combined_x_c.columns,  # Assuming feature names come from 'combined_x_p'\n",
    "    'importance': importance  # Assuming 'importance' is a list or array of the same length as the number of features\n",
    "})\n",
    "\n",
    "# Print the MSE score (separately from the feature importances)\n",
    "print(f\"Mean Squared Error (MSE): {mse_score}\")\n",
    "\n",
    "# Sort by 'importance' in descending order\n",
    "sorted_importance_c = feature_importance_networks.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display sorted feature importances\n",
    "(sorted_importance_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance_barplot(sorted_importance, top_n=5):\n",
    "    \"\"\"\n",
    "    Create a horizontal bar plot showing the top N feature importance.\n",
    "\n",
    "    Parameters:\n",
    "    sorted_importance (pd.DataFrame): Sorted feature importance DataFrame.\n",
    "    top_n (int): Number of top features to plot.\n",
    "    \"\"\"\n",
    "    # Select the top N features based on importance\n",
    "    top_features = sorted_importance.head(top_n)\n",
    "\n",
    "    # Sort the top N features by importance for plotting\n",
    "    top_features = top_features.sort_values(by='importance', ascending=True)\n",
    "\n",
    "    # Plot the top N feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = top_features.plot(kind='barh', x='feature', y='importance', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Remove the y-label\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    # Remove the legend\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Add grid and title\n",
    "    plt.grid(True)\n",
    "    ax.set_title('Top N Feature Importance (Put Options)')\n",
    "    \n",
    "    # plt.tight_layout()  # Optional: for better layout\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Plot the top 5 features from Put options data\n",
    "plot_feature_importance_barplot(sorted_importance_c, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 846us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step\n",
      "Mean Squared Error (MSE): 0.02909987179759471\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.767611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.132207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.073404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.055579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.052455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.052418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HIGH_vix</td>\n",
       "      <td>0.044147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LOW_vix</td>\n",
       "      <td>0.041290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.033465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRC_actual</td>\n",
       "      <td>0.031785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.027772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume_option</td>\n",
       "      <td>0.019116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASK</td>\n",
       "      <td>0.018770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.018363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.016358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.016285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CLOSE_vix</td>\n",
       "      <td>0.014797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spread_option</td>\n",
       "      <td>0.008814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spread_stock</td>\n",
       "      <td>0.008096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moneyness</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5_day_rolling_return_stock</td>\n",
       "      <td>0.002382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RET</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>daily_return_indicator_stock</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vol_stock</td>\n",
       "      <td>-0.000118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature  importance\n",
       "3                    prev_day_iv    0.767611\n",
       "17                       2Y_bond    0.132207\n",
       "0                              T    0.073404\n",
       "2                   prev2_day_iv    0.055579\n",
       "15                       10Y_RIR    0.052455\n",
       "10             cumulative_return    0.052418\n",
       "20                      HIGH_vix    0.044147\n",
       "21                       LOW_vix    0.041290\n",
       "22                      OPEN_vix    0.033465\n",
       "8                     PRC_actual    0.031785\n",
       "16                       1Y_bond    0.027772\n",
       "5                  volume_option    0.019116\n",
       "7                            ASK    0.018770\n",
       "23                    gold_price    0.018363\n",
       "19                       FF_rate    0.016358\n",
       "25                    spread_vix    0.016285\n",
       "18                     CLOSE_vix    0.014797\n",
       "4                  spread_option    0.008814\n",
       "13                  spread_stock    0.008096\n",
       "24                    reces_indi    0.005731\n",
       "1                      moneyness    0.003681\n",
       "6     5_day_rolling_return_stock    0.002382\n",
       "9                            RET    0.001929\n",
       "12                   hi-lo_stock    0.001798\n",
       "11  daily_return_indicator_stock    0.001103\n",
       "14                     vol_stock   -0.000118"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_p = permutation_importance(best_model_put, combined_x_p, combined_y_p, n_repeats=1, random_state=42) #NEW\n",
    "    # Get the feature importances and feature names\n",
    "importance_p = results_p.importances_mean #NEW\n",
    "\n",
    "\n",
    "# Get predictions\n",
    "pred_y_p = best_model_put.predict(combined_x_p)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_score = mean_squared_error(combined_y_p, pred_y_p)\n",
    "\n",
    "# Assuming 'importance' is a list or array of feature importances\n",
    "# Create a DataFrame with feature importance scores\n",
    "feature_importance_networks = pd.DataFrame({\n",
    "    'feature': combined_x_p.columns,  # Assuming feature names come from 'combined_x_p'\n",
    "    'importance': importance_p  # Assuming 'importance' is a list or array of the same length as the number of features\n",
    "})\n",
    "\n",
    "# Print the MSE score (separately from the feature importances)\n",
    "print(f\"Mean Squared Error (MSE): {mse_score}\")\n",
    "\n",
    "# Sort by 'importance' in descending order\n",
    "sorted_importance_p = feature_importance_networks.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display sorted feature importances\n",
    "(sorted_importance_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance_barplot(sorted_importance, top_n=5):\n",
    "    \"\"\"\n",
    "    Create a horizontal bar plot showing the top N feature importance.\n",
    "\n",
    "    Parameters:\n",
    "    sorted_importance (pd.DataFrame): Sorted feature importance DataFrame.\n",
    "    top_n (int): Number of top features to plot.\n",
    "    \"\"\"\n",
    "    # Select the top N features based on importance\n",
    "    top_features = sorted_importance.head(top_n)\n",
    "\n",
    "    # Sort the top N features by importance for plotting\n",
    "    top_features = top_features.sort_values(by='importance', ascending=True)\n",
    "\n",
    "    # Plot the top N feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = top_features.plot(kind='barh', x='feature', y='importance', color='blue', alpha=0.55, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Remove the y-label\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    # Remove the legend\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Add grid and title\n",
    "    plt.grid(True)\n",
    "    ax.set_title('Top N Feature Importance (Put Options)')\n",
    "    \n",
    "    # plt.tight_layout()  # Optional: for better layout\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Plot the top 5 features from Put options data\n",
    "plot_feature_importance_barplot(sorted_importance_p, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/wn87d6495j1_vytb8m33q3mm0000gn/T/ipykernel_18772/1963729078.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_10_df['importance_normalized'] = top_10_df['importance'] / top_10_df['importance'].sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.761074</td>\n",
       "      <td>0.600862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.100826</td>\n",
       "      <td>0.079601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HIGH_vix</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>0.062522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.051704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.050018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.037146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.044820</td>\n",
       "      <td>0.035385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.031204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.033716</td>\n",
       "      <td>0.026619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRC_actual</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.024939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance  importance_normalized\n",
       "3         prev_day_iv    0.761074               0.600862\n",
       "18            2Y_bond    0.100826               0.079601\n",
       "21           HIGH_vix    0.079193               0.062522\n",
       "11  cumulative_return    0.065490               0.051704\n",
       "0                   T    0.063354               0.050018\n",
       "16            10Y_RIR    0.047051               0.037146\n",
       "2        prev2_day_iv    0.044820               0.035385\n",
       "23           OPEN_vix    0.039524               0.031204\n",
       "17            1Y_bond    0.033716               0.026619\n",
       "8          PRC_actual    0.031589               0.024939"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted_importance_p\n",
    "\n",
    "# Sort by importance\n",
    "df_sorted = sorted_importance_p.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Get the top 10 entries\n",
    "top_10_df = df_sorted.head(10)\n",
    "\n",
    "# Normalize the importance values to sum to 1 for the top 10 features\n",
    "top_10_df['importance_normalized'] = top_10_df['importance'] / top_10_df['importance'].sum()\n",
    "\n",
    "# Display the normalized DataFrame\n",
    "top_10_df[['feature', 'importance', 'importance_normalized']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/wn87d6495j1_vytb8m33q3mm0000gn/T/ipykernel_18772/3377667362.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_10_df['importance_normalized'] = top_10_df['importance'] / top_10_df['importance'].sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.765249</td>\n",
       "      <td>0.485420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CLOSE_vix</td>\n",
       "      <td>0.287905</td>\n",
       "      <td>0.182627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>0.078046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.094248</td>\n",
       "      <td>0.059784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LOW_vix</td>\n",
       "      <td>0.089782</td>\n",
       "      <td>0.056952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0.076999</td>\n",
       "      <td>0.048843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.029173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.043765</td>\n",
       "      <td>0.027762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>0.016455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>0.014940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance  importance_normalized\n",
       "3         prev_day_iv    0.765249               0.485420\n",
       "19          CLOSE_vix    0.287905               0.182627\n",
       "18            2Y_bond    0.123037               0.078046\n",
       "17            1Y_bond    0.094248               0.059784\n",
       "22            LOW_vix    0.089782               0.056952\n",
       "0                   T    0.076999               0.048843\n",
       "11  cumulative_return    0.045990               0.029173\n",
       "2        prev2_day_iv    0.043765               0.027762\n",
       "16            10Y_RIR    0.025941               0.016455\n",
       "20            FF_rate    0.023552               0.014940"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by importance\n",
    "df_sorted = sorted_importance_c.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Get the top 10 entries\n",
    "top_10_df = df_sorted.head(10)\n",
    "\n",
    "# Normalize the importance values to sum to 1 for the top 10 features\n",
    "top_10_df['importance_normalized'] = top_10_df['importance'] / top_10_df['importance'].sum()\n",
    "\n",
    "# Display the normalized DataFrame\n",
    "top_10_df[['feature', 'importance', 'importance_normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.761074</td>\n",
       "      <td>0.600862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.100826</td>\n",
       "      <td>0.079601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIGH_vix</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>0.062522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.051704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.050017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.037146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.044820</td>\n",
       "      <td>0.035385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.031204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.033716</td>\n",
       "      <td>0.026619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRC_actual</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.024939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance  importance_normalized\n",
       "0        prev_day_iv    0.761074               0.600862\n",
       "1            2Y_bond    0.100826               0.079601\n",
       "2           HIGH_vix    0.079193               0.062522\n",
       "3  cumulative_return    0.065490               0.051704\n",
       "4                  T    0.063354               0.050017\n",
       "5            10Y_RIR    0.047051               0.037146\n",
       "6       prev2_day_iv    0.044820               0.035385\n",
       "7           OPEN_vix    0.039524               0.031204\n",
       "8            1Y_bond    0.033716               0.026619\n",
       "9         PRC_actual    0.031589               0.024939"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data based on your image\n",
    "data = {'feature': ['prev_day_iv', '2Y_bond', 'HIGH_vix', 'cumulative_return', 'T', \n",
    "                    '10Y_RIR', 'prev2_day_iv', 'OPEN_vix', '1Y_bond', 'PRC_actual'\n",
    "                    ],\n",
    "        'importance': [0.761074, 0.100826, 0.079193, 0.065490, 0.063354, 0.047051, 0.044820, \n",
    "                       0.039524, 0.033716, 0.031589]}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize the importance values to sum to 1\n",
    "df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "# Display the normalized DataFrame\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Normalized Feature Importance\", dataframe=df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                     feature  importance\\n                 prev_day_iv    0.769679\\n                           T    0.077878\\n           cumulative_return    0.067786\\n                       BIDLO    0.050018\\n                prev2_day_iv    0.045465\\n                     10Y_RIR    0.043751\\n                         BID    0.041074\\n                  PRC_actual    0.040090\\n                     2Y_bond    0.034504\\n                     1Y_bond    0.031342\\n                    OPEN_vix    0.026933\\n                  gold_price    0.026808\\n                       ASKHI    0.025359\\n                   CLOSE_vix    0.025099\\n                     LOW_vix    0.022857\\n                  spread_vix    0.021125\\n                         ASK    0.019284\\n               volume_option    0.018687\\n                    HIGH_vix    0.015443\\n                        RETX    0.014120\\n                         PRC    0.013984\\n                         RET    0.013494\\n               spread_option    0.009703\\n                 hi-lo_stock    0.009206\\n                spread_stock    0.008067\\n  5_day_rolling_return_stock    0.007816\\n                  reces_indi    0.006974\\n                   vol_stock    0.004508\\n                   moneyness    0.003908\\n                     FF_rate    0.003355\\ndaily_return_indicator_stock    0.001834'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index and remove the old index by setting drop=True\n",
    "sorted_importance_p_cleaned = sorted_importance_p.reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "\n",
    "# Print the DataFrame without showing the index\n",
    "sorted_importance_p= (sorted_importance_p.to_string(index=False))\n",
    "\n",
    "sorted_importance_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.936565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.497470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>0.118749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.101188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.092912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIDLO</td>\n",
       "      <td>0.089504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.079932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.068652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.040914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.013355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0   prev_day_iv    0.936565\n",
       "7    gold_price    0.497470\n",
       "1             T    0.118749\n",
       "8    reces_indi    0.101188\n",
       "2  prev2_day_iv    0.092912\n",
       "3         BIDLO    0.089504\n",
       "4      OPEN_vix    0.079932\n",
       "6       FF_rate    0.068652\n",
       "5   hi-lo_stock    0.040914\n",
       "9    spread_vix    0.013355"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importance_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_combined_feature_importance_barplot(sorted_importance_c, sorted_importance_p, top_n=5):\n",
    "    \"\"\"\n",
    "    Create a horizontal bar plot showing the top N normalized average feature importance from both Call and Put options.\n",
    "\n",
    "    Parameters:\n",
    "    sorted_importance_c (pd.DataFrame): Sorted feature importance DataFrame for Call options.\n",
    "    sorted_importance_p (pd.DataFrame): Sorted feature importance DataFrame for Put options.\n",
    "    top_n (int): Number of top features to plot.\n",
    "    \"\"\"\n",
    "    # Merge Call and Put DataFrames on feature name to get both importance values\n",
    "    combined_importance = pd.concat(\n",
    "        [sorted_importance_c.set_index('feature'), sorted_importance_p.set_index('feature')], \n",
    "        axis=1, keys=[\"importance_call\", \"importance_put\"]\n",
    "    ).fillna(0).reset_index()\n",
    "\n",
    "    # print(combined_importance)\n",
    "    \n",
    "    # Normalize the importance values to sum to 1 for both Call and Put\n",
    "    combined_importance['importance_call'] /= combined_importance['importance_call'].sum()\n",
    "    combined_importance['importance_put'] /= combined_importance['importance_put'].sum()\n",
    "\n",
    "    # Calculate the average normalized importance\n",
    "    combined_importance['average_importance'] = combined_importance[['importance_call', 'importance_put']].mean(axis=1)\n",
    "    \n",
    "    # Sort by the average importance and select the top N features\n",
    "    top_features = combined_importance.sort_values(by='average_importance', ascending=False).head(top_n)\n",
    "\n",
    "    # Plot the top N normalized average feature importance with a larger size\n",
    "    # plt.figure(figsize=((10, 6)))  # Adjust this as needed for the correct aspect ratio\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax = top_features.sort_values(by='average_importance', ascending=True).plot(\n",
    "        kind='barh', \n",
    "        x='feature', \n",
    "        y='average_importance', \n",
    "        color='blue', \n",
    "        alpha=0.55, \n",
    "        edgecolor='black', \n",
    "        linewidth=1,\n",
    "        ax=ax  # Use the ax from fig\n",
    "    )\n",
    "    \n",
    "    # Remove the y-label\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    # Remove the legend\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Add grid and title\n",
    "    plt.grid(True)\n",
    "    ax.set_title('NN (Put and Call)')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return combined_importance\n",
    "\n",
    "# Example usage: Plot the top 5 normalized features from combined Call and Put options data\n",
    "combfeat = plot_combined_feature_importance_barplot(sorted_importance_c, sorted_importance_p, top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_call</th>\n",
       "      <th>importance_put</th>\n",
       "      <th>average_importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>importance</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prev_day_iv</td>\n",
       "      <td>0.426052</td>\n",
       "      <td>0.529666</td>\n",
       "      <td>0.477859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2Y_bond</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.091225</td>\n",
       "      <td>0.099592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Y_bond</td>\n",
       "      <td>0.092431</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.055797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLOSE_vix</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.053060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>0.051365</td>\n",
       "      <td>0.050650</td>\n",
       "      <td>0.051007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prev2_day_iv</td>\n",
       "      <td>0.036310</td>\n",
       "      <td>0.038351</td>\n",
       "      <td>0.037330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOW_vix</td>\n",
       "      <td>0.029910</td>\n",
       "      <td>0.028491</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cumulative_return</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.028776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10Y_RIR</td>\n",
       "      <td>0.020152</td>\n",
       "      <td>0.036195</td>\n",
       "      <td>0.028173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HIGH_vix</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.030462</td>\n",
       "      <td>0.021839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OPEN_vix</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.017747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRC_actual</td>\n",
       "      <td>0.012519</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.017226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASK</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.015672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FF_rate</td>\n",
       "      <td>0.016286</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>0.013787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>volume_option</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.013053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gold_price</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spread_vix</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.008744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spread_option</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spread_stock</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>reces_indi</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>moneyness</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5_day_rolling_return_stock</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hi-lo_stock</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RET</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>daily_return_indicator_stock</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vol_stock</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature importance_call importance_put  \\\n",
       "                                      importance     importance   \n",
       "0                    prev_day_iv        0.426052       0.529666   \n",
       "1                        2Y_bond        0.107958       0.091225   \n",
       "3                        1Y_bond        0.092431       0.019163   \n",
       "2                      CLOSE_vix        0.095909       0.010210   \n",
       "4                              T        0.051365       0.050650   \n",
       "5                   prev2_day_iv        0.036310       0.038351   \n",
       "6                        LOW_vix        0.029910       0.028491   \n",
       "7              cumulative_return        0.021382       0.036170   \n",
       "8                        10Y_RIR        0.020152       0.036195   \n",
       "11                      HIGH_vix        0.013215       0.030462   \n",
       "14                      OPEN_vix        0.012403       0.023092   \n",
       "13                    PRC_actual        0.012519       0.021932   \n",
       "9                            ASK        0.018393       0.012951   \n",
       "10                       FF_rate        0.016286       0.011287   \n",
       "12                 volume_option        0.012917       0.013190   \n",
       "15                    gold_price        0.010127       0.012671   \n",
       "16                    spread_vix        0.006251       0.011237   \n",
       "18                 spread_option        0.005503       0.006082   \n",
       "17                  spread_stock        0.005875       0.005587   \n",
       "22                    reces_indi        0.000671       0.003954   \n",
       "24                     moneyness        0.000453       0.002540   \n",
       "20    5_day_rolling_return_stock        0.001258       0.001643   \n",
       "19                   hi-lo_stock        0.001356       0.001241   \n",
       "21                           RET        0.000886       0.001331   \n",
       "23  daily_return_indicator_stock        0.000490       0.000761   \n",
       "25                     vol_stock       -0.000072      -0.000082   \n",
       "\n",
       "   average_importance  \n",
       "                       \n",
       "0            0.477859  \n",
       "1            0.099592  \n",
       "3            0.055797  \n",
       "2            0.053060  \n",
       "4            0.051007  \n",
       "5            0.037330  \n",
       "6            0.029200  \n",
       "7            0.028776  \n",
       "8            0.028173  \n",
       "11           0.021839  \n",
       "14           0.017747  \n",
       "13           0.017226  \n",
       "9            0.015672  \n",
       "10           0.013787  \n",
       "12           0.013053  \n",
       "15           0.011399  \n",
       "16           0.008744  \n",
       "18           0.005793  \n",
       "17           0.005731  \n",
       "22           0.002313  \n",
       "24           0.001497  \n",
       "20           0.001450  \n",
       "19           0.001299  \n",
       "21           0.001108  \n",
       "23           0.000626  \n",
       "25          -0.000077  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by 'average_importance' in descending order\n",
    "sorted_combfeat = combfeat.sort_values(by=('average_importance', ''), ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_combfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m best_model_put\u001b[38;5;241m.\u001b[39mpredict(combined_x_p)\n\u001b[1;32m      7\u001b[0m feature_importance_networks \u001b[38;5;241m=\u001b[39m [mean_squared_error(combined_y_p, pred_y), importance]\n\u001b[0;32m----> 8\u001b[0m sorted_importance \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_importance_networks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#NEW\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "\n",
    "# # y_oos = best_model_put.predict(test_x_p)\n",
    "\n",
    "\n",
    "# # predictions = [mean_squared_error(combined_y_p, pred_y), y_oos]\n",
    "\n",
    "# pred_y = best_model_put.predict(combined_x_p)\n",
    "# feature_importance_networks = [mean_squared_error(combined_y_p, pred_y), importance]\n",
    "# sorted_importance = feature_importance_networks.sort_values(by='score', ascending=True) #NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter tuning with validation data...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.2765 - mse: 0.2765\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.4559 - mse: 0.4559\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.1565 - mse: 0.1565\n",
      "Epoch 2/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0992 - mse: 0.0992\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.1022 - mse: 0.1022\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 3/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - loss: 0.0734 - mse: 0.0734\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - loss: 0.0744 - mse: 0.0744\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 4/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0609 - mse: 0.0609\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0665 - mse: 0.0665\n",
      "Epoch 5/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0556 - mse: 0.0556\n",
      "Epoch 6/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 6/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0612 - mse: 0.0612\n",
      "Epoch 6/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0579 - mse: 0.0579\n",
      "Epoch 7/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0553 - mse: 0.0553\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 8/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0477 - mse: 0.0477\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0547 - mse: 0.0547\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 9/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 10/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 11/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0488 - mse: 0.0488\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 12/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389us/step - loss: 0.0482 - mse: 0.0482\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 13/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0432 - mse: 0.0432\n",
      "Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0474 - mse: 0.0474\n",
      "Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 0.0155 - mse: 0.0155\n",
      "\u001b[1m 139/1521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.0421 - mse: 0.0421Epoch 14/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step - loss: 0.0471 - mse: 0.0471\n",
      "Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 0.0150 - mse: 0.0150\n",
      "\u001b[1m 144/1521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 0.0417 - mse: 0.0417Epoch 15/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0467 - mse: 0.0467\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 16/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 17/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0419 - mse: 0.0419\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 18/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0433 - mse: 0.0433\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 19/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 20/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451us/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 21/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398us/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 22/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0408 - mse: 0.0408\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 23/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0418 - mse: 0.0418\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0429 - mse: 0.0429\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 24/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0408 - mse: 0.0408\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 25/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 26/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0399 - mse: 0.0399\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 27/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 28/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - loss: 0.0415 - mse: 0.0415\n",
      "Epoch 29/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0413 - mse: 0.0413\n",
      "Epoch 30/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390us/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 31/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 32/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0406 - mse: 0.0406\n",
      "Epoch 33/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - loss: 0.0399 - mse: 0.0399\n",
      "Epoch 34/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0387 - mse: 0.0387\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0410 - mse: 0.0410\n",
      "Epoch 35/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0370 - mse: 0.0370\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 36/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401us/step - loss: 0.0410 - mse: 0.0410\n",
      "Epoch 37/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 38/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 39/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381us/step - loss: 0.0386 - mse: 0.0386\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0402 - mse: 0.0402\n",
      "Epoch 40/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0378 - mse: 0.0378\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 41/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389us/step - loss: 0.0397 - mse: 0.0397\n",
      "\u001b[1m1064/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.0393 - mse: 0.0393Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 42/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0396 - mse: 0.0396\n",
      "Epoch 43/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0384 - mse: 0.0384\n",
      "Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 44/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 45/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376us/step - loss: 0.0401 - mse: 0.0401\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 45/50\n",
      "Epoch 45/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 46/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 46/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398us/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 46/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 47/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384us/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387us/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 48/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 49/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401us/step - loss: 0.0382 - mse: 0.0382\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 50/50\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - loss: 0.0366 - mse: 0.0366\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 0.0378 - mse: 0.0378\n",
      "\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0131 - mse: 0.0131\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "\u001b[1m413/761\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 243us/step[CV 2/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.023 total time=  30.8s\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step\n",
      "[CV 1/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.018 total time=  31.0s\n",
      "[CV 3/3] END batch_size=32, epochs=50, model__dropout_rate=0.2, model__layers=2, model__neurons=32;, score=-0.117 total time=  31.0s\n",
      "Epoch 1/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.2190 - mse: 0.2190\n",
      "Epoch 2/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 3/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - loss: 0.0498 - mse: 0.0498\n",
      "Epoch 4/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0447 - mse: 0.0447\n",
      "Epoch 5/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 6/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 7/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - loss: 0.0398 - mse: 0.0398\n",
      "Epoch 8/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 9/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - loss: 0.0398 - mse: 0.0398\n",
      "Epoch 10/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 11/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 12/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - loss: 0.0365 - mse: 0.0365\n",
      "Epoch 13/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380us/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 14/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0368 - mse: 0.0368\n",
      "Epoch 15/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 16/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 17/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327us/step - loss: 0.0351 - mse: 0.0351\n",
      "Epoch 18/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - loss: 0.0346 - mse: 0.0346\n",
      "Epoch 19/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - loss: 0.0348 - mse: 0.0348\n",
      "Epoch 20/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0343 - mse: 0.0343\n",
      "Epoch 21/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 22/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389us/step - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 23/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 24/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 25/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - loss: 0.0335 - mse: 0.0335\n",
      "Epoch 26/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324us/step - loss: 0.0329 - mse: 0.0329\n",
      "Epoch 27/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - loss: 0.0325 - mse: 0.0325\n",
      "Epoch 28/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 29/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step - loss: 0.0329 - mse: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - loss: 0.0323 - mse: 0.0323\n",
      "Epoch 31/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 32/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 33/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 34/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 35/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 36/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 37/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380us/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 38/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0317 - mse: 0.0317\n",
      "Epoch 39/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 40/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 41/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - loss: 0.0310 - mse: 0.0310\n",
      "Epoch 42/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 43/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 44/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 45/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - loss: 0.0311 - mse: 0.0311\n",
      "Epoch 46/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - loss: 0.0305 - mse: 0.0305\n",
      "Epoch 47/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 48/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 49/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - loss: 0.0308 - mse: 0.0308\n",
      "Epoch 50/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0308 - mse: 0.0308\n",
      "Best Parameters: {'batch_size': 32, 'epochs': 50, 'model__dropout_rate': 0.2, 'model__layers': 2, 'model__neurons': 32}\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231us/step\n",
      "In-sample R²: 0.8239\n",
      "In-sample RMSE: 0.1653\n",
      "\u001b[1m1105/1105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "Out-of-sample R²: 0.6752\n",
      "Out-of-sample RMSE: 0.1406\n"
     ]
    }
   ],
   "source": [
    "best_model_put = train_and_evaluate(train_x_p, train_y_p, combined_x_p, combined_y_p, test_x_p, test_y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess my data \n",
    "# # First standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(train_x_c)\n",
    "# train_x_c = scaler.transform(train_x_c)\n",
    "# test_x_c = scaler.transform(test_x_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - loss: 0.2191 - mse: 0.2191\n",
      "Epoch 2/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 3/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step - loss: 0.0672 - mse: 0.0672\n",
      "Epoch 4/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 5/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 6/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0681 - mse: 0.0681\n",
      "Epoch 7/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 8/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - loss: 0.0689 - mse: 0.0689\n",
      "Epoch 9/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0665 - mse: 0.0665\n",
      "Epoch 10/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 11/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0689 - mse: 0.0689\n",
      "Epoch 12/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0693 - mse: 0.0693\n",
      "Epoch 13/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - loss: 0.0696 - mse: 0.0696\n",
      "Epoch 14/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step - loss: 0.0671 - mse: 0.0671\n",
      "Epoch 15/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 16/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - loss: 0.0689 - mse: 0.0689\n",
      "Epoch 17/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0668 - mse: 0.0668\n",
      "Epoch 18/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - loss: 0.0683 - mse: 0.0683\n",
      "Epoch 19/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 20/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 21/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0692 - mse: 0.0692\n",
      "Epoch 22/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298us/step - loss: 0.0679 - mse: 0.0679\n",
      "Epoch 23/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0698 - mse: 0.0698\n",
      "Epoch 24/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 25/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 0.0664 - mse: 0.0664\n",
      "Epoch 26/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step - loss: 0.0689 - mse: 0.0689\n",
      "Epoch 27/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 28/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0691 - mse: 0.0691\n",
      "Epoch 29/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - loss: 0.0688 - mse: 0.0688\n",
      "Epoch 30/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0684 - mse: 0.0684\n",
      "Epoch 31/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 32/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 33/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 34/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0679 - mse: 0.0679\n",
      "Epoch 35/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 36/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - loss: 0.0697 - mse: 0.0697\n",
      "Epoch 37/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - loss: 0.0675 - mse: 0.0675\n",
      "Epoch 38/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0692 - mse: 0.0692\n",
      "Epoch 39/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 40/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0684 - mse: 0.0684\n",
      "Epoch 41/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 42/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - loss: 0.0678 - mse: 0.0678\n",
      "Epoch 43/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0687 - mse: 0.0687\n",
      "Epoch 44/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 45/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0695 - mse: 0.0695\n",
      "Epoch 46/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 47/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0679 - mse: 0.0679\n",
      "Epoch 48/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0679 - mse: 0.0679\n",
      "Epoch 49/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 50/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 0.0685 - mse: 0.0685\n",
      "\u001b[1m1105/1105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212us/step\n",
      "R²: 0.5814\n",
      "RMSE: 0.1596\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Best Parameters_c: {'batch_size': 32, 'epochs': 50, 'model_dropout_rate': 0, 'modellayers': 1, 'model_neurons': 8}\n",
    "\n",
    "\n",
    "# Define the model function with variable neurons, layers, and dropout rate\n",
    "def create_model(input_dim, neurons, layers, dropout_rate):\n",
    "    model = Sequential()\n",
    "    # Input layer using Input instead of input_dim argument\n",
    "    model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "model_p = create_model(combined_x_p.shape[1], 8, 1, 0.5)\n",
    "\n",
    "# Retrain the model on the combined training and validation set\n",
    "model_p.fit(combined_x_p, combined_y_p, batch_size=32, epochs=50, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_p = model_p.predict(test_x_p)\n",
    "\n",
    "# Calculate R² and RMSE for the best model\n",
    "r2_c = r2_score(test_y_p, predictions_p)\n",
    "rmse_c = np.sqrt(mean_squared_error(test_y_p, predictions_p))\n",
    "\n",
    "# Print the results\n",
    "print(f\"R²: {r2_c:.4f}\")\n",
    "print(f\"RMSE: {rmse_c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Call Options Model:\n",
      "Epoch 1/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 0.0913 - mse: 0.0913\n",
      "Epoch 2/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 3/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 4/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 5/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 6/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 7/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0470 - mse: 0.0470\n",
      "Epoch 8/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 9/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 10/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 11/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 0.0467 - mse: 0.0467\n",
      "Epoch 12/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 13/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 14/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 15/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389us/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 16/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 17/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364us/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 18/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 19/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 20/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 21/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324us/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 22/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 23/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 24/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347us/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 25/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 26/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327us/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 27/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 28/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 29/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - loss: 0.0451 - mse: 0.0451\n",
      "Epoch 30/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0454 - mse: 0.0454\n",
      "Epoch 31/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 32/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 33/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327us/step - loss: 0.0472 - mse: 0.0472\n",
      "Epoch 34/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351us/step - loss: 0.0454 - mse: 0.0454\n",
      "Epoch 35/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327us/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 36/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - loss: 0.0454 - mse: 0.0454\n",
      "Epoch 37/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 38/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 39/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 40/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 41/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 42/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317us/step - loss: 0.0447 - mse: 0.0447\n",
      "Epoch 43/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437us/step - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 44/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 45/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 46/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 47/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 48/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 49/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317us/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 50/50\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - loss: 0.0466 - mse: 0.0466\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "R²: -7.3745\n",
      "RMSE: 0.6904\n",
      "Evaluating Put Options Model:\n",
      "Epoch 1/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302us/step - loss: 0.1217 - mse: 0.1217\n",
      "Epoch 2/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900us/step - loss: 0.0659 - mse: 0.0659\n",
      "Epoch 3/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307us/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 4/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 0.0636 - mse: 0.0636\n",
      "Epoch 5/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - loss: 0.0655 - mse: 0.0655\n",
      "Epoch 6/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - loss: 0.0648 - mse: 0.0648\n",
      "Epoch 7/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0664 - mse: 0.0664\n",
      "Epoch 8/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 0.0669 - mse: 0.0669\n",
      "Epoch 9/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - loss: 0.0644 - mse: 0.0644\n",
      "Epoch 10/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - loss: 0.0657 - mse: 0.0657\n",
      "Epoch 11/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step - loss: 0.0664 - mse: 0.0664\n",
      "Epoch 12/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0646 - mse: 0.0646\n",
      "Epoch 13/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step - loss: 0.0660 - mse: 0.0660\n",
      "Epoch 14/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - loss: 0.0649 - mse: 0.0649\n",
      "Epoch 15/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step - loss: 0.0638 - mse: 0.0638\n",
      "Epoch 16/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - loss: 0.0646 - mse: 0.0646\n",
      "Epoch 17/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 18/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0645 - mse: 0.0645\n",
      "Epoch 19/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0645 - mse: 0.0645\n",
      "Epoch 20/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - loss: 0.0651 - mse: 0.0651\n",
      "Epoch 21/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step - loss: 0.0651 - mse: 0.0651\n",
      "Epoch 22/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0657 - mse: 0.0657\n",
      "Epoch 23/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 24/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 25/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - loss: 0.0646 - mse: 0.0646\n",
      "Epoch 26/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step - loss: 0.0656 - mse: 0.0656\n",
      "Epoch 27/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268us/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 28/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 29/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0632 - mse: 0.0632\n",
      "Epoch 30/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 31/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step - loss: 0.0642 - mse: 0.0642\n",
      "Epoch 32/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 33/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 34/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 35/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 36/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0658 - mse: 0.0658\n",
      "Epoch 37/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - loss: 0.0664 - mse: 0.0664\n",
      "Epoch 38/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - loss: 0.0670 - mse: 0.0670\n",
      "Epoch 39/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - loss: 0.0641 - mse: 0.0641\n",
      "Epoch 40/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - loss: 0.0648 - mse: 0.0648\n",
      "Epoch 41/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step - loss: 0.0658 - mse: 0.0658\n",
      "Epoch 42/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - loss: 0.0656 - mse: 0.0656\n",
      "Epoch 43/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302us/step - loss: 0.0668 - mse: 0.0668\n",
      "Epoch 44/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - loss: 0.0650 - mse: 0.0650\n",
      "Epoch 45/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 46/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - loss: 0.0659 - mse: 0.0659\n",
      "Epoch 47/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - loss: 0.0661 - mse: 0.0661\n",
      "Epoch 48/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - loss: 0.0660 - mse: 0.0660\n",
      "Epoch 49/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 50/50\n",
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - loss: 0.0672 - mse: 0.0672\n",
      "\u001b[1m1105/1105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step\n",
      "R²: 0.1916\n",
      "RMSE: 0.2218\n"
     ]
    }
   ],
   "source": [
    "import numpy as nq\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Define the model function with variable neurons, layers, and dropout rate\n",
    "def create_model(input_dim, neurons, layers, dropout_rate):\n",
    "    model = Sequential()\n",
    "    # Input layer using Input instead of input_dim argument\n",
    "    model.add(Input(shape=(input_dim,)))  # Define the input shape explicitly\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, combined_x, combined_y, test_x, test_y, batch_size, epochs):\n",
    "    # Retrain the model on the combined training and validation set\n",
    "    model.fit(combined_x, combined_y, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(test_x)\n",
    "\n",
    "    # Calculate R² and RMSE for the best model\n",
    "    r2 = r2_score(test_y, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"R²: {r2:.,f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Example usage for call options\n",
    "# print(\"Evaluating Call Options Model:\")\n",
    "# model_c = create_model(combined_x_c.shape[1], neurons=8, layers=3, dropout_rate=0.2)\n",
    "# evaluate_model(model_c, combined_x_c, combined_y_c, test_x_c, test_y_c, batch_size=32, epochs=50)\n",
    "\n",
    "# Example usage for put options\n",
    "print(\"Evaluating Put Options Model:\")\n",
    "model_p = create_model(combined_x_p.shape[1], neurons=8, layers=1, dropout_rate=0.5)\n",
    "evaluate_model(model_p, combined_x_p, combined_y_p, test_x_p, test_y_p, batch_size=32, epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>prev2_day_iv</th>\n",
       "      <th>prev_day_iv</th>\n",
       "      <th>5_day_rolling_return_stock</th>\n",
       "      <th>ASK</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>BID</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>PRC</th>\n",
       "      <th>...</th>\n",
       "      <th>1Y_bond</th>\n",
       "      <th>2Y_bond</th>\n",
       "      <th>CLOSE_vix</th>\n",
       "      <th>FF_rate</th>\n",
       "      <th>HIGH_vix</th>\n",
       "      <th>LOW_vix</th>\n",
       "      <th>OPEN_vix</th>\n",
       "      <th>gold_price</th>\n",
       "      <th>reces_indi</th>\n",
       "      <th>spread_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862489</td>\n",
       "      <td>-1.599060</td>\n",
       "      <td>-1.565542</td>\n",
       "      <td>-0.215265</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.56898</td>\n",
       "      <td>-0.56926</td>\n",
       "      <td>-0.56901</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>-0.568991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.469739</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>1.12461</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.133918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.862489</td>\n",
       "      <td>-1.348787</td>\n",
       "      <td>-1.565542</td>\n",
       "      <td>-0.243882</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.56898</td>\n",
       "      <td>-0.56926</td>\n",
       "      <td>-0.56901</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>-0.568991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.469739</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>1.12461</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.133918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.862489</td>\n",
       "      <td>-1.099920</td>\n",
       "      <td>-1.565542</td>\n",
       "      <td>-0.272954</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.56898</td>\n",
       "      <td>-0.56926</td>\n",
       "      <td>-0.56901</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>-0.568991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.469739</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>1.12461</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.133918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.862489</td>\n",
       "      <td>-0.853865</td>\n",
       "      <td>-1.565542</td>\n",
       "      <td>-0.301999</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.56898</td>\n",
       "      <td>-0.56926</td>\n",
       "      <td>-0.56901</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>-0.568991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.469739</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>1.12461</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.133918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.862489</td>\n",
       "      <td>-0.242243</td>\n",
       "      <td>-1.565542</td>\n",
       "      <td>-0.349271</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>-0.56898</td>\n",
       "      <td>-0.56926</td>\n",
       "      <td>-0.56901</td>\n",
       "      <td>-0.567166</td>\n",
       "      <td>-0.568991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371916</td>\n",
       "      <td>1.469739</td>\n",
       "      <td>0.476238</td>\n",
       "      <td>1.12461</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>-1.353864</td>\n",
       "      <td>-0.709827</td>\n",
       "      <td>-0.133918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          T  moneyness  prev2_day_iv  prev_day_iv  5_day_rolling_return_stock  \\\n",
       "0 -0.862489  -1.599060     -1.565542    -0.215265                   -0.286276   \n",
       "1 -0.862489  -1.348787     -1.565542    -0.243882                   -0.286276   \n",
       "2 -0.862489  -1.099920     -1.565542    -0.272954                   -0.286276   \n",
       "3 -0.862489  -0.853865     -1.565542    -0.301999                   -0.286276   \n",
       "4 -0.862489  -0.242243     -1.565542    -0.349271                   -0.286276   \n",
       "\n",
       "       ASK    ASKHI      BID     BIDLO       PRC  ...   1Y_bond   2Y_bond  \\\n",
       "0 -0.56898 -0.56926 -0.56901 -0.567166 -0.568991  ...  1.371916  1.469739   \n",
       "1 -0.56898 -0.56926 -0.56901 -0.567166 -0.568991  ...  1.371916  1.469739   \n",
       "2 -0.56898 -0.56926 -0.56901 -0.567166 -0.568991  ...  1.371916  1.469739   \n",
       "3 -0.56898 -0.56926 -0.56901 -0.567166 -0.568991  ...  1.371916  1.469739   \n",
       "4 -0.56898 -0.56926 -0.56901 -0.567166 -0.568991  ...  1.371916  1.469739   \n",
       "\n",
       "   CLOSE_vix  FF_rate  HIGH_vix   LOW_vix  OPEN_vix  gold_price  reces_indi  \\\n",
       "0   0.476238  1.12461  0.475155  0.662651  0.674867   -1.353864   -0.709827   \n",
       "1   0.476238  1.12461  0.475155  0.662651  0.674867   -1.353864   -0.709827   \n",
       "2   0.476238  1.12461  0.475155  0.662651  0.674867   -1.353864   -0.709827   \n",
       "3   0.476238  1.12461  0.475155  0.662651  0.674867   -1.353864   -0.709827   \n",
       "4   0.476238  1.12461  0.475155  0.662651  0.674867   -1.353864   -0.709827   \n",
       "\n",
       "   spread_vix  \n",
       "0   -0.133918  \n",
       "1   -0.133918  \n",
       "2   -0.133918  \n",
       "3   -0.133918  \n",
       "4   -0.133918  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_x_p.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6547025 ],\n",
       "       [-0.6540263 ],\n",
       "       [-0.64889556],\n",
       "       ...,\n",
       "       [ 0.829493  ],\n",
       "       [ 0.90898424],\n",
       "       [ 0.98446095]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# from keras import regularizers\n",
    "# from tensorflow import keras\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import Sequential, load_model\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # define the model\n",
    "# def create_model(bias, activity):\n",
    "#   model = Sequential()\n",
    "#   model.add(Dense(units=32,\n",
    "#                   activation='relu',\n",
    "#                   input_dim= train_x.shape[1],\n",
    "#                   # # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-5),\n",
    "#                   bias_regularizer= regularizers.L2(bias),\n",
    "#                   activity_regularizer= regularizers.L2(activity)\n",
    "#                   ))\n",
    "#   model.add(Dense(units=32, activation= 'relu',\n",
    "#                   bias_regularizer=regularizers.L2(bias),\n",
    "#                   activity_regularizer=regularizers.L2(activity) #activation\n",
    "#                   ))\n",
    "#   model.add(Dense(units=1, activation= 'linear')) #miss linear\n",
    "\n",
    "#   # compile the model\n",
    "#   model.compile(optimizer= RMSprop(learning_rate=0.01), #'rmsprop',#Optimizer_trial,\n",
    "#                 loss= 'mean_squared_error',\n",
    "#                 metrics=['mse'])\n",
    "#   return model\n",
    "\n",
    "# # Wrapping the model in KerasRegressor\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # Define the parameter grid for trials\n",
    "# param_grid = {\n",
    "#     'neurons': [8, 16, 32, 64],   # Number of neurons in each hidden layer\n",
    "#     'layers': [1, 2, 3, 4],       # Number of hidden layers\n",
    "#     'dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "#     'batch_size': [32, 64],       # Batch size for training\n",
    "#     'epochs': [50, 100],          # Number of epochs\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras.backend as K\n",
    "# from keras import regularizers\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.models import Sequential\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# # Define the model function with variable neurons, layers, and dropout rate\n",
    "# def create_model(neurons=32, layers=1, dropout_rate=0.0, bias=0.01, activity=0.01):\n",
    "#     model = Sequential()\n",
    "#     # Input layer (first hidden layer)\n",
    "#     model.add(Dense(neurons, activation='relu', input_dim=train_x.shape[1],\n",
    "#                     bias_regularizer=regularizers.L2(bias),\n",
    "#                     activity_regularizer=regularizers.L2(activity)))\n",
    "#     model.add(Dropout(dropout_rate))  # Dropout layer after the first hidden layer\n",
    "\n",
    "#     # Additional hidden layers\n",
    "#     for _ in range(layers - 1):\n",
    "#         model.add(Dense(neurons, activation='relu',\n",
    "#                         bias_regularizer=regularizers.L2(bias),\n",
    "#                         activity_regularizer=regularizers.L2(activity)))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer\n",
    "#     model.add(Dense(1, activation='linear'))  # Output layer for regression (linear)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "#                   loss='mean_squared_error',\n",
    "#                   metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "# # Wrapping the model in KerasRegressor\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # Define the parameter grid for trials\n",
    "# param_grid = {\n",
    "#     'neurons': [8, 16, 32, 64],   # Number of neurons in each hidden layer\n",
    "#     'layers': [1, 2, 3, 4],       # Number of hidden layers\n",
    "#     'dropout_rate': [0, 0.2, 0.5], # Dropout rate\n",
    "#     'batch_size': [32, 64],       # Batch size for training\n",
    "#     'epochs': [50, 100],          # Number of epochs\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV with the model, parameter grid, and scoring\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                            param_grid=param_grid,\n",
    "#                            scoring='neg_mean_squared_error',  # Scoring based on MSE\n",
    "#                            cv=3,  # 3-fold cross-validation\n",
    "#                            verbose=1)  # Verbose for tracking progress\n",
    "\n",
    "# # Run the grid search\n",
    "# grid_search.fit(train_x, train_y)\n",
    "\n",
    "# # Get the best estimator and parameters\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # Make predictions using the best model\n",
    "# predictions = best_model.predict(test_x)\n",
    "\n",
    "# # Calculate R² and RMSE for the best model\n",
    "# r2 = r2_score(test_y, predictions)\n",
    "# rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# print(f\"R²: {r2:.4f}\")\n",
    "# print(f\"RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# import time\n",
    "# import itertools\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from keras_tuner import KerasRegressor\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# # from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# # from keras_tuner import KerasRegressor\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# def create_model(hidden_layers=1, units=64, activation='relu', learning_rate=0.001):\n",
    "#     \"\"\"\n",
    "#     Function to create a Keras Sequential model with the given hyperparameters.\n",
    "#     \"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=units, activation=activation, input_dim=X_train.shape[1]))\n",
    "    \n",
    "#     for _ in range(hidden_layers - 1):\n",
    "#         model.add(Dense(units=units, activation=activation))\n",
    "        \n",
    "#     model.add(Dense(1))  # Output layer\n",
    "\n",
    "#     optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def prepare_data_with_gridsearch_nn(train_data, validate_data, test_data, option_type, verbose=True):\n",
    "#     \"\"\"\n",
    "#     Prepare the data, perform hyperparameter tuning using Year 1 (train) and Year 2 (validation),\n",
    "#     retrain the model on Year 1 + Year 2, and evaluate on Year 3 (test) for Neural Networks.\n",
    "    \n",
    "#     Parameters:\n",
    "#     train_data (pd.DataFrame): The training dataset (Year 1).\n",
    "#     validate_data (pd.DataFrame): The validation dataset (Year 2).\n",
    "#     test_data (pd.DataFrame): The testing dataset (Year 3).\n",
    "#     option_type (str): Call or Put option type for labeling the print output.\n",
    "#     verbose (bool): If True, prints progress information for hyperparameter tuning.\n",
    "#     \"\"\"\n",
    "#     # Prepare the train, validation, and test data\n",
    "#     X_train = train_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Training features (Year 1)\n",
    "#     y_train = train_data['impl_volatility']  # Training target (Year 1)\n",
    "\n",
    "#     X_validate = validate_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Validation features (Year 2)\n",
    "#     y_validate = validate_data['impl_volatility']  # Validation target (Year 2)\n",
    "    \n",
    "#     X_test = test_data.drop(columns=['impl_volatility', 'date', 'Ticker', 'cp_flag'])  # Test features (Year 3)\n",
    "#     y_test = test_data['impl_volatility']  # Test target (Year 3)\n",
    "\n",
    "#     # Define the hyperparameter grid for NN\n",
    "#     param_grid = {\n",
    "#         'hidden_layers': [1, 2, 3],                # Number of hidden layers\n",
    "#         'units': [32, 64, 128],                    # Number of units per layer\n",
    "#         'activation': ['relu', 'tanh'],            # Activation function\n",
    "#         'learning_rate': [0.001, 0.01],            # Learning rate for Adam optimizer\n",
    "#         'batch_size': [32, 64],                    # Batch size\n",
    "#         'epochs': [50, 100],                       # Number of epochs\n",
    "#     }\n",
    "\n",
    "#     # Generate all combinations of hyperparameters\n",
    "#     param_combinations = list(itertools.product(\n",
    "#         param_grid['hidden_layers'], \n",
    "#         param_grid['units'], \n",
    "#         param_grid['activation'], \n",
    "#         param_grid['learning_rate'], \n",
    "#         param_grid['batch_size'], \n",
    "#         param_grid['epochs']\n",
    "#     ))\n",
    "\n",
    "#     total_combinations = len(param_combinations)\n",
    "    \n",
    "#     # Initialize variables to store the best model and best score\n",
    "#     best_rmse_val = np.inf\n",
    "#     best_params = None\n",
    "#     best_nn_model = None\n",
    "\n",
    "#     print(f\"Running manual hyperparameter tuning for {option_type} Options with Neural Networks...\")\n",
    "    \n",
    "#     # Iterate over all hyperparameter combinations with progress tracking\n",
    "#     for i, (hidden_layers, units, activation, learning_rate, batch_size, epochs) in enumerate(param_combinations):\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         # Create the Keras model with the current set of hyperparameters\n",
    "#         model = create_model(hidden_layers=hidden_layers, units=units, activation=activation, learning_rate=learning_rate)\n",
    "\n",
    "#         # Early stopping to prevent overfitting\n",
    "#         early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "#         # Train the model on the training data (Year 1)\n",
    "#         history = model.fit(X_train, y_train, \n",
    "#                             validation_data=(X_validate, y_validate),\n",
    "#                             batch_size=batch_size, \n",
    "#                             epochs=epochs, \n",
    "#                             verbose=0, \n",
    "#                             callbacks=[early_stopping])\n",
    "\n",
    "#         # Validate the model on the validation data (Year 2)\n",
    "#         y_val_pred = model.predict(X_validate)\n",
    "#         rmse_val = np.sqrt(mean_squared_error(y_validate, y_val_pred))\n",
    "\n",
    "#         # Track the best performing hyperparameters based on validation RMSE\n",
    "#         if rmse_val < best_rmse_val:\n",
    "#             best_rmse_val = rmse_val\n",
    "#             best_params = {\n",
    "#                 'hidden_layers': hidden_layers,\n",
    "#                 'units': units,\n",
    "#                 'activation': activation,\n",
    "#                 'learning_rate': learning_rate,\n",
    "#                 'batch_size': batch_size,\n",
    "#                 'epochs': epochs\n",
    "#             }\n",
    "#             best_nn_model = model\n",
    "\n",
    "#         # Verbose output to track progress\n",
    "#         if verbose:\n",
    "#             elapsed_time = time.time() - start_time\n",
    "#             print(f\"Combination {i + 1}/{total_combinations} completed in {elapsed_time:.2f} seconds.\")\n",
    "#             print(f\"Current RMSE (Validation): {rmse_val:.4f}\")\n",
    "#             print(f\"Best RMSE so far: {best_rmse_val:.4f}\")\n",
    "    \n",
    "#     print(f\"\\nBest Parameters for {option_type} Options with Neural Networks: {best_params}\")\n",
    "    \n",
    "#     # Retrain the model on combined Year 1 (train) and Year 2 (validation)\n",
    "#     print(\"Retraining the model on Year 1 and Year 2 combined...\")\n",
    "#     X_combined = pd.concat([X_train, X_validate])\n",
    "#     y_combined = pd.concat([y_train, y_validate])\n",
    "#     best_nn_model.fit(X_combined, y_combined, batch_size=best_params['batch_size'], epochs=best_params['epochs'], verbose=0)\n",
    "\n",
    "#     # In-sample (combined Year 1 + Year 2) predictions\n",
    "#     y_combined_pred = best_nn_model.predict(X_combined)\n",
    "\n",
    "#     # Evaluate In-Sample Performance (on combined Year 1 + Year 2)\n",
    "#     rmse_combined = np.sqrt(mean_squared_error(y_combined, y_combined_pred))\n",
    "#     r2_combined = r2_score(y_combined, y_combined_pred)\n",
    "    \n",
    "#     print(f\"\\nIn-Sample Performance for {option_type} Options (Year 1 + Year 2):\")\n",
    "#     print(f\"RMSE (Training + Validation): {rmse_combined:.4f}\")\n",
    "#     print(f\"R² (Training + Validation): {r2_combined:.4f}\")\n",
    "\n",
    "#     # After retraining, evaluate performance on the test data (Year 3)\n",
    "#     y_test_pred = best_nn_model.predict(X_test)\n",
    "\n",
    "#     # Evaluate Out-of-Sample Performance (on Test Data)\n",
    "#     rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "#     r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "#     # Print the final results\n",
    "#     print(f\"\\nPerformance on Test Data (Year 3) for {option_type} Options:\")\n",
    "#     print(f\"Out-of-Sample RMSE (Test): {rmse_test:.4f}\")\n",
    "#     print(f\"Out-of-Sample R² (Test): {r2_test:.4f}\")\n",
    "\n",
    "\n",
    "# # Call the function for Call options data\n",
    "# prepare_data_with_gridsearch_nn(data_train_c, data_validate_c, data_test_c, 'Call')\n",
    "\n",
    "# # Call the function for Put options data\n",
    "# prepare_data_with_gridsearch_nn(data_train_p, data_validate_p, data_test_p, 'Put')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
