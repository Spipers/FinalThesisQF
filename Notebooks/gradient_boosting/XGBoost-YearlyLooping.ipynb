{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1155,"status":"ok","timestamp":1688815550096,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"},"user_tz":-120},"id":"pbibvvcrYDnn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","\n","from numpy import mean\n","from numpy import std\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112902,"status":"ok","timestamp":1688815662985,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"},"user_tz":-120},"id":"sbsRE6MTUdKd","outputId":"077aae1a-69f2-4a5a-b8ab-91e3de271ac1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# link to drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"elapsed":28985,"status":"ok","timestamp":1688815691939,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"},"user_tz":-120},"id":"03-xISFM2Ffj","outputId":"6c565150-a88c-4a85-e7f2-cae0068fd589"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             secid       -80       -50       -20     level     slope  \\\n","date                                                                   \n","1996-01-31  100862  0.307688  0.315627  0.358095  0.315627  0.042468   \n","1996-01-31  100871  0.705411  0.615432  0.651160  0.615432  0.035728   \n","1996-01-31  100892  0.270090  0.216768  0.216508  0.216768 -0.000260   \n","1996-01-31  100896  0.430796  0.436291  0.429517  0.436291 -0.006774   \n","1996-01-31  100903  0.262405  0.252683  0.373839  0.252683  0.121156   \n","\n","               curve  permno      beta    betasq  ...      cash   cinvest  \\\n","date                                              ...                       \n","1996-01-31  0.017264   54594 -0.502126 -0.886445  ... -0.868511  0.071798   \n","1996-01-31  0.062854   50906  0.551365  0.193703  ... -0.738289  0.080067   \n","1996-01-31  0.026531   57904 -0.536730 -0.902575  ... -0.958006  0.066337   \n","1996-01-31 -0.006135   77520  0.349363 -0.101800  ... -0.968644  0.060739   \n","1996-01-31  0.065439   80303 -0.186662 -0.682642  ... -0.584473  0.077826   \n","\n","                roaq    roavol    ms  baspread    maxret    retvol  \\\n","date                                                                 \n","1996-01-31  0.396279 -0.953113  0.00 -0.689049 -0.662673 -0.619551   \n","1996-01-31  0.538981 -0.900059  0.75 -0.112575 -0.390130 -0.223204   \n","1996-01-31  0.367446 -0.998951  0.25 -0.786859 -0.947305 -0.877289   \n","1996-01-31  0.459243 -0.859083 -0.25 -0.747736 -0.649524 -0.703492   \n","1996-01-31  0.605842 -0.875346 -0.50 -0.807682 -0.825541 -0.737079   \n","\n","            std_dolvol  std_turn  \n","date                              \n","1996-01-31    0.327234 -0.936622  \n","1996-01-31   -0.342296 -0.748948  \n","1996-01-31   -0.536138 -0.955821  \n","1996-01-31   -0.331142 -0.818216  \n","1996-01-31   -0.400503 -0.866238  \n","\n","[5 rows x 38 columns]"],"text/html":["\n","  <div id=\"df-b43c810d-12a9-41c5-83fb-80e317d63874\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>secid</th>\n","      <th>-80</th>\n","      <th>-50</th>\n","      <th>-20</th>\n","      <th>level</th>\n","      <th>slope</th>\n","      <th>curve</th>\n","      <th>permno</th>\n","      <th>beta</th>\n","      <th>betasq</th>\n","      <th>...</th>\n","      <th>cash</th>\n","      <th>cinvest</th>\n","      <th>roaq</th>\n","      <th>roavol</th>\n","      <th>ms</th>\n","      <th>baspread</th>\n","      <th>maxret</th>\n","      <th>retvol</th>\n","      <th>std_dolvol</th>\n","      <th>std_turn</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1996-01-31</th>\n","      <td>100862</td>\n","      <td>0.307688</td>\n","      <td>0.315627</td>\n","      <td>0.358095</td>\n","      <td>0.315627</td>\n","      <td>0.042468</td>\n","      <td>0.017264</td>\n","      <td>54594</td>\n","      <td>-0.502126</td>\n","      <td>-0.886445</td>\n","      <td>...</td>\n","      <td>-0.868511</td>\n","      <td>0.071798</td>\n","      <td>0.396279</td>\n","      <td>-0.953113</td>\n","      <td>0.00</td>\n","      <td>-0.689049</td>\n","      <td>-0.662673</td>\n","      <td>-0.619551</td>\n","      <td>0.327234</td>\n","      <td>-0.936622</td>\n","    </tr>\n","    <tr>\n","      <th>1996-01-31</th>\n","      <td>100871</td>\n","      <td>0.705411</td>\n","      <td>0.615432</td>\n","      <td>0.651160</td>\n","      <td>0.615432</td>\n","      <td>0.035728</td>\n","      <td>0.062854</td>\n","      <td>50906</td>\n","      <td>0.551365</td>\n","      <td>0.193703</td>\n","      <td>...</td>\n","      <td>-0.738289</td>\n","      <td>0.080067</td>\n","      <td>0.538981</td>\n","      <td>-0.900059</td>\n","      <td>0.75</td>\n","      <td>-0.112575</td>\n","      <td>-0.390130</td>\n","      <td>-0.223204</td>\n","      <td>-0.342296</td>\n","      <td>-0.748948</td>\n","    </tr>\n","    <tr>\n","      <th>1996-01-31</th>\n","      <td>100892</td>\n","      <td>0.270090</td>\n","      <td>0.216768</td>\n","      <td>0.216508</td>\n","      <td>0.216768</td>\n","      <td>-0.000260</td>\n","      <td>0.026531</td>\n","      <td>57904</td>\n","      <td>-0.536730</td>\n","      <td>-0.902575</td>\n","      <td>...</td>\n","      <td>-0.958006</td>\n","      <td>0.066337</td>\n","      <td>0.367446</td>\n","      <td>-0.998951</td>\n","      <td>0.25</td>\n","      <td>-0.786859</td>\n","      <td>-0.947305</td>\n","      <td>-0.877289</td>\n","      <td>-0.536138</td>\n","      <td>-0.955821</td>\n","    </tr>\n","    <tr>\n","      <th>1996-01-31</th>\n","      <td>100896</td>\n","      <td>0.430796</td>\n","      <td>0.436291</td>\n","      <td>0.429517</td>\n","      <td>0.436291</td>\n","      <td>-0.006774</td>\n","      <td>-0.006135</td>\n","      <td>77520</td>\n","      <td>0.349363</td>\n","      <td>-0.101800</td>\n","      <td>...</td>\n","      <td>-0.968644</td>\n","      <td>0.060739</td>\n","      <td>0.459243</td>\n","      <td>-0.859083</td>\n","      <td>-0.25</td>\n","      <td>-0.747736</td>\n","      <td>-0.649524</td>\n","      <td>-0.703492</td>\n","      <td>-0.331142</td>\n","      <td>-0.818216</td>\n","    </tr>\n","    <tr>\n","      <th>1996-01-31</th>\n","      <td>100903</td>\n","      <td>0.262405</td>\n","      <td>0.252683</td>\n","      <td>0.373839</td>\n","      <td>0.252683</td>\n","      <td>0.121156</td>\n","      <td>0.065439</td>\n","      <td>80303</td>\n","      <td>-0.186662</td>\n","      <td>-0.682642</td>\n","      <td>...</td>\n","      <td>-0.584473</td>\n","      <td>0.077826</td>\n","      <td>0.605842</td>\n","      <td>-0.875346</td>\n","      <td>-0.50</td>\n","      <td>-0.807682</td>\n","      <td>-0.825541</td>\n","      <td>-0.737079</td>\n","      <td>-0.400503</td>\n","      <td>-0.866238</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 38 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b43c810d-12a9-41c5-83fb-80e317d63874')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b43c810d-12a9-41c5-83fb-80e317d63874 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b43c810d-12a9-41c5-83fb-80e317d63874');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["def initialise(data):\n","  data.index = data[\"date\"]\n","  data.index = pd.to_datetime(data.index)\n","  data.drop(columns=[\"date\"], inplace=True)\n","  return data\n","\n","data_level = initialise(pd.read_csv('/content/drive/MyDrive/Msc Thesis/code/data/Low resolution/data_level_mapped_selection10.csv'))\n","data_slope = initialise(pd.read_csv('/content/drive/MyDrive/Msc Thesis/code/data/Low resolution/data_slope_mapped_selection10.csv'))\n","data_curve = initialise(pd.read_csv('/content/drive/MyDrive/Msc Thesis/code/data/Low resolution/data_curve_mapped_selection10.csv'))\n","\n","data_level.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1688815691942,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"},"user_tz":-120},"id":"JuLc1x7FHA7N"},"outputs":[],"source":["def samplesplitting(data,train,validate,oos,i):\n","    train_data    = data[(data.index.year >= 1996 )         & (data.index.year < i - validate)]\n","    validate_data = data[(data.index.year >= i - validate)  & (data.index.year < i)]\n","    total_train   = data[(data.index.year >= 1996 )         & (data.index.year < i)]\n","    oos_data      = data[(data.index.year == i)]\n","    pred_data     = data[(data.index.year >= 1996 + train + validate) & (data.index.year <= i)]\n","\n","    print('train=%d, validate=%d, oos=%d' % (len(train_data), len(validate_data), len(oos_data)))\n","    return train_data, validate_data, oos_data, total_train, pred_data\n","\n","def split_xy(data, kind):\n","  data_x = data.iloc[:,8:]\n","  data_y = data[kind]\n","  return data_x, data_y"]},{"cell_type":"markdown","metadata":{"id":"26NgyfqbGr5g"},"source":["# Level old"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Um7r1u-AYbiw","outputId":"c13cf5ea-1a2c-4e9e-edd7-49532398f40c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration:  0\n","train=288000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  500\n","Learning rate:  0.1\n","Yearly: 0.45448851551540614\n","Total: 0.45448851551540614\n","Iteration:  1\n","train=324000, validate=180000, oos=36000\n","Max Depth:  4\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.47187150033721803\n","Total: 0.46304039071576153\n","Iteration:  2\n","train=360000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  500\n","Learning rate:  0.1\n","Yearly: 0.31483574693169425\n","Total: 0.4224497651822653\n","Iteration:  3\n","train=396000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.4826565564755215\n","Total: 0.44018061377868245\n","Iteration:  4\n","train=432000, validate=180000, oos=36000\n","Max Depth:  4\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.2561241094930582\n","Total: 0.4076957406586599\n","Iteration:  5\n","train=468000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.5016001924670601\n","Total: 0.4234775238951639\n","Iteration:  6\n","train=504000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.5244154515644078\n","Total: 0.4445399360571237\n","Iteration:  7\n","train=540000, validate=180000, oos=36000\n","Max Depth:  4\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.48992298260148837\n","Total: 0.4508043921257979\n","Iteration:  8\n","train=576000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.5203452975450187\n","Total: 0.45992500570027184\n","Iteration:  9\n","train=612000, validate=180000, oos=36000\n","Max Depth:  6\n","Nr of trees:  200\n","Learning rate:  0.1\n","Yearly: 0.5233559134365031\n","Total: 0.46707301766514786\n","Iteration:  10\n","train=648000, validate=180000, oos=36000\n"]}],"source":["# Complete number of observations is 982285\n","# We take the initial train, validate and oos sample to be 8, 5 and 13 years respectively (Ratios similar to Gu Kelly Xiu)\n","# On average one month contains 3000 options, therefore we loop over 12 * 3000 options, which is similar to looping over a year\n","trainsize = 8 * 3000 * 12\n","validatesize = 5 * 3000 * 12\n","oossize = 3000 * 12\n","\n","# Initialise predictionstring\n","IV = 'level'\n","oos_pred_level = pd.DataFrame()\n","\n","# Hyperparameters\n","max_depth = [4, 6]\n","n_estimators = [200, 500]\n","eta = [0.1]\n","# subsample = [0.7]\n","# colsample_bytree = [0.8]\n","# reg_alpha = 0 #0.1\n","# reg_lambda = 1\n","\n","for window in range (0,13):\n","  print('Iteration: ', window)\n","  best = float(\"inf\")\n","\n","  # Optimisation method 1 expanding window\n","\n","  # Sample splitting\n","  train, validate, oos, total_train, total_oos = samplesplitting(data_level, trainsize, validatesize, oossize, window)\n","  train_x, train_y              = split_xy(train,IV)\n","  validate_x, validate_y        = split_xy(validate,IV)\n","  oos_x, oos_y                  = split_xy(oos,IV)\n","  total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","  # Tuning\n","  for i in range(len(max_depth)):\n","    for j in range(len(n_estimators)):\n","      for k in range(len(eta)):\n","        model = XGBRegressor(max_depth = max_depth[i], n_estimators=n_estimators[j], eta=eta[k])\n","        model.fit(train_x, train_y)\n","        pred_val= model.predict(validate_x)\n","        error = np.sqrt(((pred_val - validate_y) ** 2).mean())\n","        if error < best:\n","          best = error\n","          max_depth_final = max_depth[i]\n","          n_estimators_final = n_estimators[j]\n","          eta_final = eta[k]\n","\n","          y_hat = pd.DataFrame(model.predict(oos_x))\n","\n","  # Fit model\n","  print('Max Depth: ', max_depth_final)\n","  print('Nr of trees: ', n_estimators_final)\n","  print('Learning rate: ', eta_final)\n","  # model_final = XGBRegressor(max_depth = max_depth_final,\n","  #                            n_estimators = n_estimators_final,\n","  #                            eta = eta_final)\n","  # model_final.fit(total_train_x, total_train_y)\n","  # y_hat = pd.DataFrame(model_final.predict(oos_x))\n","  print('Yearly:',r2_score(oos_y, y_hat))\n","  oos_pred_level = pd.concat([oos_pred_level, y_hat], ignore_index=True)\n","  print('Total:',r2_score(total_oos[IV], oos_pred_level))\n","\n","oos_pred_level.to_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/level_predictions_xgb.csv', index=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9agI1A18tjp_"},"outputs":[],"source":["oos_pred_level.to_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/level_predictions_xgb.csv', index=True)"]},{"cell_type":"markdown","metadata":{"id":"YUt7WBrX8D30"},"source":["# Level New"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qdis8OHdqwp","outputId":"5efdb23a-bed6-4e9a-9c25-f51b9d2a945a"},"outputs":[{"output_type":"stream","name":"stdout","text":["train=504261, validate=148707, oos=27899\n","Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 700}\n","Iteration:  2012\n","train=210839, validate=158189, oos=33864\n","Yearly: 0.3627130588183748\n","Total: 0.3627130588183748\n","Iteration:  2013\n","train=241135, validate=161757, oos=34182\n","Yearly: 0.4282467236085986\n","Total: 0.40204854512250676\n","Iteration:  2014\n","train=272284, validate=164790, oos=34113\n","Yearly: 0.44183377672856483\n","Total: 0.4167397064215309\n","Iteration:  2015\n","train=303150, validate=168037, oos=33074\n","Yearly: 0.4263864764075437\n","Total: 0.41965766449878716\n","Iteration:  2016\n","train=335237, validate=169024, oos=31906\n","Yearly: 0.3855759281768646\n","Total: 0.413355960730607\n","Iteration:  2017\n","train=369028, validate=167139, oos=30972\n","Yearly: 0.42138351973931887\n","Total: 0.41745325724023774\n","Iteration:  2018\n","train=402892, validate=164247, oos=30002\n","Yearly: 0.4946783964209196\n","Total: 0.4278037029040015\n","Iteration:  2019\n","train=437074, validate=160067, oos=28538\n","Yearly: 0.5707166661319294\n","Total: 0.4440414362504732\n","Iteration:  2020\n","train=471187, validate=154492, oos=27289\n","Yearly: 0.2069770081978617\n","Total: 0.4340806206299833\n","Iteration:  2021\n","train=504261, validate=148707, oos=27899\n"]}],"source":["# Complete number of observations is 982285\n","# We take the initial train, validate and oos sample to be 8, 5 and 13 years respectively (Ratios similar to Gu Kelly Xiu)\n","# On average one month contains 3000 options, therefore we loop over 12 * 3000 options, which is similar to looping over a year\n","# trainsize = 8 * 3000 * 12\n","# validatesize = 5 * 3000 * 12\n","# oossize = 3000 * 12\n","trainsize = 11\n","validatesize = 5\n","oossize = 1\n","\n","# Initialise predictionstring\n","IV = 'level'\n","oos_pred_level = pd.DataFrame()\n","\n","# # Hyperparameters\n","# param_grid = {\n","#     'max_depth': [11, 13] ,# [9, 11], #[7, 9],\n","#     'n_estimators': [600], # [400, 600], #[200, 500],\n","#     'learning_rate': [0.01], #[0.01, 0.001] # was (0.1, 0.01)\n","      # 'n_jobs': [-1]\n","# }\n","\n","window = 2021\n","train, validate, oos, total_train, total_oos = samplesplitting(data_level, trainsize, validatesize, oossize, window)\n","total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","# model = XGBRegressor()\n","# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2,  verbose=10)\n","# grid_search.fit(total_train_x, total_train_y)\n","# best_params = grid_search.best_params_\n","best_params = {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 700} #{'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n","print(\"Best Hyperparameters:\", best_params)\n","best_model = XGBRegressor(**best_params)\n","\n","feature_importance = np.zeros(total_train_x.shape[1])\n","\n","for window in range(2012, 2021+1):\n","  print('Iteration: ', window)\n","  best = float(\"inf\")\n","\n","  # Sample splitting\n","  train, validate, oos, total_train, total_oos = samplesplitting(data_level, trainsize, validatesize, oossize, window)\n","  train_x, train_y              = split_xy(train,IV)\n","  validate_x, validate_y        = split_xy(validate,IV)\n","  oos_x, oos_y                  = split_xy(oos,IV)\n","  total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","  best_model.fit(total_train_x, total_train_y)\n","  y_hat = pd.DataFrame(best_model.predict(oos_x))\n","\n","  # Obtain feature importance\n","  feature_importance += best_model.feature_importances_\n","\n","  print('Yearly:',r2_score(oos_y, y_hat))\n","  oos_pred_level = pd.concat([oos_pred_level, y_hat], ignore_index=True)\n","  print('Total:',r2_score(total_oos[IV], oos_pred_level))\n","\n","feature_importance_mean = feature_importance / 10\n","np.savetxt('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/feature_importance_mean_level_yearly.csv', feature_importance_mean, delimiter=',')\n","oos_pred_level.to_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/level_predictions_xgb_yearly.csv', index=True)"]},{"cell_type":"markdown","metadata":{"id":"urhPkYV9GuHb"},"source":["# Slope"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"m3xvmjf323k7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688822018512,"user_tz":-120,"elapsed":6301192,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"}},"outputId":"e330c1bd-a5ad-41dd-e5b4-d93f8b534a25"},"outputs":[{"output_type":"stream","name":"stdout","text":["train=504261, validate=148707, oos=27899\n","Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n","Iteration:  2012\n","train=210839, validate=158189, oos=33864\n","Yearly: 0.015355886662705931\n","Total: 0.015355886662705931\n","Iteration:  2013\n","train=241135, validate=161757, oos=34182\n","Yearly: 0.0184076803595129\n","Total: 0.020900566089374295\n","Iteration:  2014\n","train=272284, validate=164790, oos=34113\n","Yearly: 0.004076872452754343\n","Total: 0.022126578447140943\n","Iteration:  2015\n","train=303150, validate=168037, oos=33074\n","Yearly: 0.03352052558502916\n","Total: 0.029962517412287504\n","Iteration:  2016\n","train=335237, validate=169024, oos=31906\n","Yearly: 0.028498141860209825\n","Total: 0.030637592673746994\n","Iteration:  2017\n","train=369028, validate=167139, oos=30972\n","Yearly: 0.028327150353237518\n","Total: 0.031094321867793595\n","Iteration:  2018\n","train=402892, validate=164247, oos=30002\n","Yearly: 0.03123784259434692\n","Total: 0.031209560886287013\n","Iteration:  2019\n","train=437074, validate=160067, oos=28538\n","Yearly: 0.04330764421892863\n","Total: 0.03281967816137321\n","Iteration:  2020\n","train=471187, validate=154492, oos=27289\n","Yearly: 0.0004201088035283851\n","Total: 0.035569004841780494\n","Iteration:  2021\n","train=504261, validate=148707, oos=27899\n","Yearly: 0.027703439327143364\n","Total: 0.04122631133465282\n"]}],"source":["trainsize = 11\n","validatesize = 5\n","oossize = 1\n","\n","# Initialise predictionstring\n","IV = 'slope'\n","oos_pred_slope = pd.DataFrame()\n","\n","# # Hyperparameters\n","# param_grid = {\n","#     'max_depth': [3],#[3,5,7],#[7, 11] ,\n","#     'n_estimators': [700],#[400, 600],\n","#     'learning_rate': [0.01],\n","      # 'n_jobs': [-1]\n","# }\n","\n","window = 2021\n","train, validate, oos, total_train, total_oos = samplesplitting(data_slope, trainsize, validatesize, oossize, window)\n","total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","# model = XGBRegressor()\n","# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2,  verbose=10)\n","# grid_search.fit(total_train_x, total_train_y)\n","# best_params = grid_search.best_params_\n","best_params = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700} #{'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500, 'n_jobs': -1}\n","print(\"Best Hyperparameters:\", best_params)\n","best_model = XGBRegressor(**best_params)\n","\n","feature_importance = np.zeros(total_train_x.shape[1])\n","\n","for window in range(2012, 2021+1):\n","  print('Iteration: ', window)\n","  best = float(\"inf\")\n","\n","  # Sample splitting\n","  train, validate, oos, total_train, total_oos = samplesplitting(data_slope, trainsize, validatesize, oossize, window)\n","  train_x, train_y              = split_xy(train,IV)\n","  validate_x, validate_y        = split_xy(validate,IV)\n","  oos_x, oos_y                  = split_xy(oos,IV)\n","  total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","  best_model.fit(total_train_x, total_train_y)\n","  y_hat = pd.DataFrame(best_model.predict(oos_x))\n","\n","  # Obtain feature importance\n","  feature_importance += best_model.feature_importances_\n","\n","  print('Yearly:',r2_score(oos_y, y_hat))\n","  oos_pred_slope = pd.concat([oos_pred_slope, y_hat], ignore_index=True)\n","  print('Total:',r2_score(total_oos[IV], oos_pred_slope))\n","\n","feature_importance_mean = feature_importance / 10\n","np.savetxt('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/feature_importance_mean_slope_yearly.csv', feature_importance_mean, delimiter=',')\n","oos_pred_slope.to_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/slope_predictions_xgb_yearly.csv', index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ngve80dc6oS"},"outputs":[],"source":["oos_pred_slope = pd.read_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/slope_predictions_xgb3.csv')\n","oos_pred_slope.head()"]},{"cell_type":"markdown","metadata":{"id":"eoc2Dp86Gw5F"},"source":["# **Curvature**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBaYw2tb3RA1","outputId":"61e00860-6ccd-4234-c28d-fe868afdfe53","executionInfo":{"status":"ok","timestamp":1688829314710,"user_tz":-120,"elapsed":5494166,"user":{"displayName":"Maud van lent","userId":"14567433046769998042"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["train=504261, validate=148707, oos=27899\n","Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'n_jobs': -1}\n","Iteration:  2012\n","train=210839, validate=158189, oos=33864\n","Yearly: 0.007089884374277378\n","Total: 0.007089884374277378\n","Iteration:  2013\n","train=241135, validate=161757, oos=34182\n","Yearly: 0.014025113209116702\n","Total: 0.012948931821928134\n","Iteration:  2014\n","train=272284, validate=164790, oos=34113\n","Yearly: -0.004883966210775137\n","Total: 0.01364079971403065\n","Iteration:  2015\n","train=303150, validate=168037, oos=33074\n","Yearly: 0.017577853772373087\n","Total: 0.018803884125296655\n","Iteration:  2016\n","train=335237, validate=169024, oos=31906\n","Yearly: -0.04291795289815381\n","Total: 0.014532207448196055\n","Iteration:  2017\n","train=369028, validate=167139, oos=30972\n","Yearly: -0.0018721598262165795\n","Total: 0.012222619890702502\n","Iteration:  2018\n","train=402892, validate=164247, oos=30002\n","Yearly: 0.012050310164516742\n","Total: 0.012570054181704537\n","Iteration:  2019\n","train=437074, validate=160067, oos=28538\n","Yearly: 0.038577077261015114\n","Total: 0.015985986745657765\n","Iteration:  2020\n","train=471187, validate=154492, oos=27289\n","Yearly: 0.0022994635722164425\n","Total: 0.01721261961660825\n","Iteration:  2021\n","train=504261, validate=148707, oos=27899\n","Yearly: 0.032244333344130016\n","Total: 0.021473254141441855\n"]}],"source":["trainsize = 11\n","validatesize = 5\n","oossize = 1\n","\n","# Initialise predictionstring\n","IV = 'curve'\n","oos_pred_curve = pd.DataFrame()\n","\n","# Hyperparameters\n","# param_grid = {\n","#     'max_depth': [5], #[3,5,7],#\n","#     'n_estimators': [300, 500],# [500]\n","#     'learning_rate': [0.01, 0.1], #[0.01],\n","#     'n_jobs': [-1]\n","# }\n","\n","window = 2021\n","train, validate, oos, total_train, total_oos = samplesplitting(data_curve, trainsize, validatesize, oossize, window)\n","total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","# model = XGBRegressor()\n","# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2,  verbose=10)\n","# grid_search.fit(total_train_x, total_train_y)\n","# best_params = grid_search.best_params_\n","best_params = {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'n_jobs': -1}\n","print(\"Best Hyperparameters:\", best_params)\n","best_model = XGBRegressor(**best_params)\n","\n","feature_importance = np.zeros(total_train_x.shape[1])\n","\n","for window in range(2012, 2021+1):\n","  print('Iteration: ', window)\n","  best = float(\"inf\")\n","\n","  # Sample splitting\n","  train, validate, oos, total_train, total_oos = samplesplitting(data_curve, trainsize, validatesize, oossize, window)\n","  train_x, train_y              = split_xy(train,IV)\n","  validate_x, validate_y        = split_xy(validate,IV)\n","  oos_x, oos_y                  = split_xy(oos,IV)\n","  total_train_x, total_train_y  = split_xy(total_train,IV)\n","\n","  best_model.fit(total_train_x, total_train_y)\n","  y_hat = pd.DataFrame(best_model.predict(oos_x))\n","\n","  # Obtain feature importance\n","  feature_importance += best_model.feature_importances_\n","\n","  print('Yearly:',r2_score(oos_y, y_hat))\n","  oos_pred_curve = pd.concat([oos_pred_curve, y_hat], ignore_index=True)\n","  print('Total:',r2_score(total_oos[IV], oos_pred_curve))\n","\n","feature_importance_mean = feature_importance / 10\n","np.savetxt('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/feature_importance_mean_curve_yearly.csv', feature_importance_mean, delimiter=',')\n","oos_pred_curve.to_csv('/content/drive/MyDrive/Msc Thesis/code/Results/XGBoosting/curve_predictions_xgb_yearly.csv', index=True)"]},{"cell_type":"markdown","metadata":{"id":"Vh4l5KyilmwC"},"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["26NgyfqbGr5g"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}